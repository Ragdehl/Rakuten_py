{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DEEPLEARNING IMAGES FUNCTIONAL EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import os #Miscellaneous operating system interfaces\n",
    "#https://docs.python.org/3/library/os.html\n",
    "#get current working directory\n",
    "path = os.getcwd() + '\\\\images\\\\image_train'\n",
    "path\n",
    "\n",
    "classes = {'10':' Livres, Couvertures de livres ','40':' Jeux videos, CDs + mais aussi equipements, cables, etc. ','50':' Jeux Vidéos, Equipements ','60':' Consoles, Manettes, croix, boutons, ecrans ','1140':' Figurines, Personnages et objets, parfois dans des boites ','1160':' Cartes, Rectangles, beaucoup de couleurs ','1180':' Figurines et boites ','1280':' Jouets, poupées nounours, equipements enfants','1281':' Jeux enfants, Boites et autres, couleurs flashy','1300':' Jeux techniques, Equipement, petites machines ','1301':' Habits bébés, petites photos ','1302':' Equipements, Habits, outils, jouets, objets sur fond blanc','1320':' Matériel et meubles bébé poussettes, habits','1560':' Meubles, matelas canapés lampes, chaises','1920':' Oreillers, coussins, draps','1940':' Alimentations, conserves boites d gateaux','2060':' Décorations','2220':' Equipements divers pour animaux','2280':' Livres et revues anciennes','2403':' Livres et revues de collection','2462':' Equipement jeux, play stations','2522':' Cahiers, carnets, marque pages','2582':' Matériel, meubles et outils pour le jardin','2583':' Equipements technique pour la maison et exterieur (piscines), produits','2585':' Idem 2583:  Equipements technique pour la maison et exterieur (piscines), produits','2705':' Livres','2905':' Jeux vidéos'}\n",
    "\n",
    "model_type = 'Functional'\n",
    "existing_model = 'EffNetB1'\n",
    "version = 'v3'\n",
    "filename = existing_model + '_' +  version\n",
    "model_path = 'models_output\\\\' + existing_model + '\\\\' + version + '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de mots par texte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperer les données images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_1263597046_product_3804725264.jpg\n",
      "C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_train\\image_1263597046_product_3804725264.jpg\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('X_train_update.csv',index_col=0)\n",
    "y = pd.read_csv('Y_train_CVw08PX.csv',index_col=0).squeeze().map(str)\n",
    "\n",
    "#Create a column with the name of the picture\n",
    "X['image_name'] = 'image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
    "X['image_path'] = path + r'\\image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
    "print(X['image_name'].loc[0])\n",
    "print(X['image_path'].loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatener X_train et les labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>image_1263597046_product_3804725264.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>image_1008141237_product_436067568.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>image_938777978_product_201115110.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>image_457047496_product_50418756.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>image_1077757786_product_278535884.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84911</th>\n",
       "      <td>The Sims [ Import Anglais ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206719094</td>\n",
       "      <td>941495734</td>\n",
       "      <td>image_941495734_product_206719094.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84912</th>\n",
       "      <td>Kit piscine acier NEVADA déco pierre Ø 3.50m x...</td>\n",
       "      <td>&lt;b&gt;Description complète :&lt;/b&gt;&lt;br /&gt;Kit piscine...</td>\n",
       "      <td>3065095706</td>\n",
       "      <td>1188462883</td>\n",
       "      <td>image_1188462883_product_3065095706.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84913</th>\n",
       "      <td>Journal Officiel De La Republique Francaise N°...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440707564</td>\n",
       "      <td>1009325617</td>\n",
       "      <td>image_1009325617_product_440707564.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84914</th>\n",
       "      <td>Table Basse Bois De Récupération Massif Base B...</td>\n",
       "      <td>&lt;p&gt;Cette table basse a un design unique et con...</td>\n",
       "      <td>3942400296</td>\n",
       "      <td>1267353403</td>\n",
       "      <td>image_1267353403_product_3942400296.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84915</th>\n",
       "      <td>Gomme De Collection 2 Gommes Pinguin Glace Ver...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57203227</td>\n",
       "      <td>684671297</td>\n",
       "      <td>image_684671297_product_57203227.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84916 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             designation  \\\n",
       "0      Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1      Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2      Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3      Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                                   La Guerre Des Tuques   \n",
       "...                                                  ...   \n",
       "84911                        The Sims [ Import Anglais ]   \n",
       "84912  Kit piscine acier NEVADA déco pierre Ø 3.50m x...   \n",
       "84913  Journal Officiel De La Republique Francaise N°...   \n",
       "84914  Table Basse Bois De Récupération Massif Base B...   \n",
       "84915  Gomme De Collection 2 Gommes Pinguin Glace Ver...   \n",
       "\n",
       "                                             description   productid  \\\n",
       "0                                                    NaN  3804725264   \n",
       "1                                                    NaN   436067568   \n",
       "2      PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   \n",
       "3                                                    NaN    50418756   \n",
       "4      Luc a des id&eacute;es de grandeur. Il veut or...   278535884   \n",
       "...                                                  ...         ...   \n",
       "84911                                                NaN   206719094   \n",
       "84912  <b>Description complète :</b><br />Kit piscine...  3065095706   \n",
       "84913                                                NaN   440707564   \n",
       "84914  <p>Cette table basse a un design unique et con...  3942400296   \n",
       "84915                                                NaN    57203227   \n",
       "\n",
       "          imageid                               image_name  \\\n",
       "0      1263597046  image_1263597046_product_3804725264.jpg   \n",
       "1      1008141237   image_1008141237_product_436067568.jpg   \n",
       "2       938777978    image_938777978_product_201115110.jpg   \n",
       "3       457047496     image_457047496_product_50418756.jpg   \n",
       "4      1077757786   image_1077757786_product_278535884.jpg   \n",
       "...           ...                                      ...   \n",
       "84911   941495734    image_941495734_product_206719094.jpg   \n",
       "84912  1188462883  image_1188462883_product_3065095706.jpg   \n",
       "84913  1009325617   image_1009325617_product_440707564.jpg   \n",
       "84914  1267353403  image_1267353403_product_3942400296.jpg   \n",
       "84915   684671297     image_684671297_product_57203227.jpg   \n",
       "\n",
       "                                              image_path prdtypecode  \n",
       "0      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...          10  \n",
       "1      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2280  \n",
       "2      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...          50  \n",
       "3      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        1280  \n",
       "4      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2705  \n",
       "...                                                  ...         ...  \n",
       "84911  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...          40  \n",
       "84912  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2583  \n",
       "84913  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2280  \n",
       "84914  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        1560  \n",
       "84915  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2522  \n",
       "\n",
       "[84916 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,y],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois nous avons un dataset de la taille desirée on peut le séparer en train et test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, y_train, y_test = train_test_split(X[['image_name','prdtypecode']], X.prdtypecode, test_size=0.2, random_state=42)\n",
    "#X_train_path, X_test_path, y_train, y_test = train_test_split(X.image_path, X.label, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60735</th>\n",
       "      <td>image_1208783386_product_2825941333.jpg</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>image_856119038_product_89102802.jpg</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55855</th>\n",
       "      <td>image_936925976_product_197015072.jpg</td>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42138</th>\n",
       "      <td>image_1166755995_product_2824252365.jpg</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>image_1017775450_product_418466190.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>image_938718607_product_183256510.jpg</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>image_1289079205_product_4086048240.jpg</td>\n",
       "      <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>image_1273354395_product_3992621069.jpg</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>image_1323296971_product_4231695757.jpg</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>image_885908975_product_131689220.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_name prdtypecode\n",
       "60735  image_1208783386_product_2825941333.jpg        1320\n",
       "9118      image_856119038_product_89102802.jpg        1281\n",
       "55855    image_936925976_product_197015072.jpg        2403\n",
       "42138  image_1166755995_product_2824252365.jpg        1302\n",
       "10948   image_1017775450_product_418466190.jpg          10\n",
       "...                                        ...         ...\n",
       "6265     image_938718607_product_183256510.jpg        1940\n",
       "54886  image_1289079205_product_4086048240.jpg        2060\n",
       "76820  image_1273354395_product_3992621069.jpg        1920\n",
       "860    image_1323296971_product_4231695757.jpg        1302\n",
       "15795    image_885908975_product_131689220.jpg          10\n",
       "\n",
       "[67932 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60735</th>\n",
       "      <td>image_1208783386_product_2825941333.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>image_856119038_product_89102802.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55855</th>\n",
       "      <td>image_936925976_product_197015072.jpg</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42138</th>\n",
       "      <td>image_1166755995_product_2824252365.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>image_1017775450_product_418466190.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>image_938718607_product_183256510.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>image_1289079205_product_4086048240.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>image_1273354395_product_3992621069.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>image_1323296971_product_4231695757.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>image_885908975_product_131689220.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_name  prdtypecode\n",
       "60735  image_1208783386_product_2825941333.jpg            9\n",
       "9118      image_856119038_product_89102802.jpg            5\n",
       "55855    image_936925976_product_197015072.jpg           16\n",
       "42138  image_1166755995_product_2824252365.jpg            8\n",
       "10948   image_1017775450_product_418466190.jpg            0\n",
       "...                                        ...          ...\n",
       "6265     image_938718607_product_183256510.jpg           12\n",
       "54886  image_1289079205_product_4086048240.jpg           13\n",
       "76820  image_1273354395_product_3992621069.jpg           11\n",
       "860    image_1323296971_product_4231695757.jpg            8\n",
       "15795    image_885908975_product_131689220.jpg            0\n",
       "\n",
       "[67932 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open('classes.json') as f:\n",
    "    categories = json.load(f)\n",
    "\n",
    "i = 0\n",
    "y_dict = {}\n",
    "for category in categories:\n",
    "    X_train_img['prdtypecode'] = X_train_img['prdtypecode'].replace(category,categories[category])\n",
    "    X_test_img['prdtypecode'] = X_test_img.replace(category,categories[category])\n",
    "    y_dict[i] = category\n",
    "    i+=1\n",
    "\n",
    "X_train_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67932 validated image filenames.\n",
      "Found 16984 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#APPLY SOME TRANSFORMATIONS TO DATA\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "batch = 32\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(#rescale = 1./255,\n",
    "                                preprocessing_function = preprocess_input,\n",
    "                                   shear_range = 0.5,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                    brightness_range = [0.9,1.1],\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(#rescale = 1./255,\n",
    "                                                              preprocessing_function = preprocess_input\n",
    "                                                              )\n",
    "\n",
    "train_set = train_datagen.flow_from_dataframe(dataframe=X_train_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image_name\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                              class_mode =\"raw\",\n",
    "                                              target_size = (224, 224),\n",
    "                                              batch_size = batch)\n",
    "\n",
    "test_set = test_datagen.flow_from_dataframe(dataframe=X_test_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image_name\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                            class_mode =\"raw\",\n",
    "                                              target_size = (224, 224),\n",
    "                                              batch_size = batch,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELE POUR CLASSIFICATION D'IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB1(weights='imagenet',input_shape=(224, 224, 3),include_top=False)\n",
    "\n",
    "input_ = Input(shape=(224, 224, 3), name= 'input_' + filename)\n",
    "x = base_model(input_)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu',name= 'dense_' + filename)(x)\n",
    "#x = BatchNormalization(trainable = True,axis=1,name= 'batchnorm' + model_name)(x)\n",
    "x = Dropout(0.5,name= 'dropout_' + filename)(x)\n",
    "x = Dense(512, activation='relu',name= 'dense_2_' + filename)(x)\n",
    "x = Dropout(0.2,name= 'dropout_2_' + filename)(x)\n",
    "#x = Flatten()(x) \n",
    "output = Dense(27, activation='softmax',name= 'output_' + filename)(x)\n",
    "\n",
    "model = Model(input_, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block7b_dwconv\n",
      "block7b_bn\n",
      "block7b_activation\n",
      "block7b_se_squeeze\n",
      "block7b_se_reshape\n",
      "block7b_se_reduce\n",
      "block7b_se_expand\n",
      "block7b_se_excite\n",
      "block7b_project_conv\n",
      "block7b_project_bn\n",
      "block7b_drop\n",
      "block7b_add\n",
      "top_conv\n",
      "top_bn\n",
      "top_activation\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_EffNetB1_v3 (InputLaye [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb1 (Functional)  (None, 7, 7, 1280)        6575239   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_EffNetB1_v3 (Dense)    (None, 1024)              1311744   \n",
      "_________________________________________________________________\n",
      "dropout_EffNetB1_v3 (Dropout (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2_EffNetB1_v3 (Dense)  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2_EffNetB1_v3 (Dropo (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_EffNetB1_v3 (Dense)   (None, 27)                13851     \n",
      "=================================================================\n",
      "Total params: 8,425,634\n",
      "Trainable params: 3,207,915\n",
      "Non-trainable params: 5,217,719\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unfreezed_layers = 15 #Nombre de couches a décongeler pour aplique le finetuning: Voir livre Deep Learning with python\n",
    "\n",
    "# Freezer les couches du modele de base\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "\n",
    "# DeFreezer les quelques couches du modele de base\n",
    "for layer in base_model.layers[-unfreezed_layers:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x1c8572e1400>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(model_path + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                         patience=3,\n",
    "                                         mode='max',\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath= model_path + filename + '.hdf5', \n",
    "                                       monitor='val_accuracy',\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='max',\n",
    "                                       save_freq='epoch')\n",
    "\n",
    "red_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                             patience=2, \n",
    "                                             factor=0.1,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2122/2122 [==============================] - ETA: 0s - loss: 1.8318 - accuracy: 0.4683"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sparse_categorical_crossentropy/Cast (defined at <ipython-input-32-4ce73195c1dd>:5) ]] [Op:__inference_test_function_27180]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4ce73195c1dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#model.load_weights(model_path + filename + '.hdf5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mred_on_plateau\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1214\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    954\u001b[0m               *args, **kwds)\n\u001b[0;32m    955\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[0;32m    957\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sparse_categorical_crossentropy/Cast (defined at <ipython-input-32-4ce73195c1dd>:5) ]] [Op:__inference_test_function_27180]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "#model.fit_generator(gen, steps_per_epoch=int(len(y_train.values)/16), validation_data = gentest, validation_steps = int(len(y_test.values)/16),epochs=10, workers=-1,callbacks=[early_stopping, checkpoint])\n",
    "#model.fit_generator(train_set, steps_per_epoch=int(len(y_train.values)/32), validation_data = test_set, validation_steps = int(len(y_test.values)/32),epochs=10, workers=1)\n",
    "\n",
    "#model.load_weights(model_path + filename + '.hdf5')\n",
    "history = model.fit(train_set, steps_per_epoch=int(len(y_train.values)/batch), validation_data = test_set, validation_steps = int(len(y_test.values)/batch),epochs=30, workers=-1,callbacks=[early_stopping, checkpoint,red_on_plateau])\n",
    "\n",
    "#https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/\n",
    "#So, we have learned the difference between Keras.fit and Keras.fit_generator functions used to train a deep learning neural network\n",
    "#.fit is used when the entire training dataset can fit into the memory and no data augmentation is applied.\n",
    "#.fit_generator is used when either we have a huge dataset to fit into our memory or when data augmentation needs to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(model_path + filename)\n",
    "saved_model = tf.keras.models.load_model(model_path + filename)\n",
    "saved_model.load_weights(model_path + filename + '.hdf5')\n",
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "#saved_model.__dict__\n",
    "\n",
    "for layer in saved_model.layers:\n",
    "    print(layer.name)\n",
    "    \n",
    "#layer.__dict__\n",
    "#vars(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model acc by epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#with open('classes.json', 'w') as f:\n",
    "#    json.dump(test_set.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.json') as f:\n",
    "    classes = json.load(f)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path + filename + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_labels = dict((v,k) for k,v in (train_set.class_indices).items())\n",
    "\n",
    "y_pred = [fit_labels[i] for i in np.argmax(y_pred_prob, axis=1)]\n",
    "\n",
    "y_test_ = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "import itertools # Pour créer des iterateurs\n",
    "\n",
    "y_organised = ['10','2280','2403','2705','2522',\n",
    "               '40','50','2905','2462','60',\n",
    "               '1280','1281','1300','1180','1140','1160',\n",
    "               '1320','1560',\n",
    "               '2582','2583','2585','1302','2220',\n",
    "               '1920','2060',\n",
    "               '1301','1940'\n",
    "              ]\n",
    "\n",
    "def conf_matx(y_test,y_pred):\n",
    "    #Réponse valable:\n",
    "    #cnf_matrix = metrics.confusion_matrix(y_test,y_pred,labels=list(set(y_pred)))\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test,y_pred,labels=y_organised)\n",
    "    y_organised\n",
    "\n",
    "    pond_matrix = []\n",
    "    for line in cnf_matrix:\n",
    "        pond_line = []\n",
    "        for cell in line:\n",
    "            pond_line.append(round(cell/sum(line),2))\n",
    "        pond_matrix.append(pond_line)\n",
    "        #print(sum(line))\n",
    "        #print(sum(pond_line))\n",
    "    cnf_matrix = np.array(pond_matrix)\n",
    "\n",
    "    ###Optionnel: Afficher une matrice de confusion sous forme de tableau coloré\n",
    "    #classes = set(y_pred)\n",
    "    classes = y_organised\n",
    "\n",
    "    plt.figure(figsize=(17,17))\n",
    "\n",
    "    plt.imshow(cnf_matrix, interpolation='nearest',cmap='Blues')\n",
    "    plt.title(\"Matrice de confusion\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    #tick_marks = set(y_test)\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > ( cnf_matrix.max() / 2) else \"black\")\n",
    "\n",
    "    plt.ylabel('Vrais labels')\n",
    "    plt.xlabel('Labels prédits')\n",
    "    plt.show()\n",
    "    \n",
    "conf_matx(y_test_,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montrer erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #import OpenCV\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "import matplotlib.pyplot as plt # Pour l'affichage d'images\n",
    "from matplotlib import cm # Pour importer de nouvelles cartes de couleur\n",
    "%matplotlib inline\n",
    "\n",
    "error_indexes = []\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] != y_test[i]):\n",
    "        error_indexes += [i]\n",
    "\n",
    "images = 8\n",
    "        \n",
    "j = 1\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "#plt.subplot(10,5,1)\n",
    "plt.axis('off')\n",
    "\n",
    "for i in np.random.choice(error_indexes, size = images):\n",
    "    img = cv2.imread(path + '\\\\' + X_test_img.iloc[i]['image_name'])\n",
    "    img = cv2.resize(img, (240, 240), interpolation=cv2.INTER_CUBIC)\n",
    "    #img = cv2.imread(path + '\\\\' + X_test_img.iloc[0]['image_name'], cv2.IMREAD_COLOR)\n",
    "    #img = img.reshape(28, 28)\n",
    "    \n",
    "    #plt.figure(figsize=(5,10))\n",
    "    \n",
    "    plt.subplot(4,2,j)\n",
    "    \n",
    "    #plt.subplot(5, 5, j)\n",
    "    j = j + 1\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=cm.binary, interpolation='None')\n",
    "    plt.title('True Label: ' + classes[str(y_test[i])] \\\n",
    "              + '\\n' + 'Prediction: '+ classes[str(y_pred[i])] \\\n",
    "              + '\\n' + 'Confidence: '+ str(round(np.max(y_pred_prob, axis=1)[i],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_csv = pd.read_csv('predictions.csv',index_col=0)\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['RNN_v3 & RNN_v4'] = df_csv.apply(lambda cell: int(cell['real']) if ((cell['RNN_v3'] == cell['real']) or (cell['RNN_v4'] == cell['real'])) else cell['RNN_v4'],axis=1)\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['RNN_v3 & RNN_v4 & EffNetB1_v2'] = df_csv.apply(lambda cell: int(cell['real']) if ((cell['RNN_v3 & RNN_v4'] == cell['real']) or (cell['EffNetB1_v2'] == cell['real'])) else cell['EffNetB1_v2'],axis=1)\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_csv.dropna(subset=['RNN_v3'])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "print(classification_report(df_final['real'].map(int).to_list(),df_final['RNN_v3 & RNN_v4 & EffNetB1_v2'].map(int).to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "intermediate_layer_model = Model(model.input, model.layers[2].output)\n",
    "\n",
    "X_train_features = intermediate_layer_model.predict(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = intermediate_layer_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=100)\n",
    "\n",
    "svm.fit(X_train_features, data_train[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(X_test_features,data_test[\"class\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
