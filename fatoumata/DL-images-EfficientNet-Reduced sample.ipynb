{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie sur les images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif à dépasser : weighted F1-score = 0.5534 (Resnet)\n",
    "avec CNN/Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\barry\\\\OneDrive - CSTBGroup\\\\image_ds\\\\images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer les données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_train_update.csv',index_col=0)\n",
    "y = pd.read_csv('Y_train_CVw08PX.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\barry\\\\OneDrive - CSTBGroup\\\\image_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Miscellaneous operating system interfaces\n",
    "#https://docs.python.org/3/library/os.html\n",
    "\n",
    "#get current working directory\n",
    "current_path = os.getcwd() \n",
    "\n",
    "#Training images path\n",
    "images_path = current_path + r'/images/image_train/'\n",
    "\n",
    "#List with the name of all training images\n",
    "images_list = os.listdir(images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Géneration nom des images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        image_1263597046_product_3804725264.jpg\n",
       "1         image_1008141237_product_436067568.jpg\n",
       "2          image_938777978_product_201115110.jpg\n",
       "3           image_457047496_product_50418756.jpg\n",
       "4         image_1077757786_product_278535884.jpg\n",
       "                          ...                   \n",
       "84911      image_941495734_product_206719094.jpg\n",
       "84912    image_1188462883_product_3065095706.jpg\n",
       "84913     image_1009325617_product_440707564.jpg\n",
       "84914    image_1267353403_product_3942400296.jpg\n",
       "84915       image_684671297_product_57203227.jpg\n",
       "Name: image name, Length: 84916, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a column with the name of the picture\n",
    "X['image name'] = 'image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
    "X['image name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition des images dans les échantillons train, validation et test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
    "\n",
    "X_val = X_train.iloc[:1600,:]\n",
    "y_val = y_train.iloc[:1600,:]\n",
    "\n",
    "X_train = X_train.iloc[:14400,:]\n",
    "y_train = y_train.iloc[:14400:,:]\n",
    "\n",
    "X_test = X_test.iloc[:4000,:]\n",
    "y_test = y_test.iloc[:4000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité de la répartitioon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "trainy = pd.DataFrame(y_train.value_counts(), columns = ['Nombre_images_train'])\n",
    "testy = pd.DataFrame(y_test.value_counts(), columns = ['Nombre_images_test'])\n",
    "train_test = trainy.merge(testy, right_index = True, left_index = True)\n",
    "train_test['y'] = train_test.index\n",
    "yval = []\n",
    "for i in train_test['y']:\n",
    "    yval.append(i[0])\n",
    "train_test['y'] = yval\n",
    "train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"class\"] = y_train\n",
    "X_test[\"class\"] = y_test\n",
    "X_val[\"class\"] = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generator :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating objects for image augmentations\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rescale = 1./255,  \n",
    "        rotation_range = 10,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        zoom_range = 1.1,\n",
    "        horizontal_flip = True\n",
    "        )\n",
    "\n",
    "val_data_generator = ImageDataGenerator(rescale = 1./255,\n",
    "        rotation_range = 10,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        zoom_range = 1.1,\n",
    "        horizontal_flip = True\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14400 validated image filenames belonging to 27 classes.\n",
      "Found 1600 validated image filenames belonging to 27 classes.\n",
      "Found 4000 validated image filenames belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "path = os.chdir('C:\\\\Users\\\\barry\\\\OneDrive - CSTBGroup\\\\image_ds\\\\images\\\\image_train')\n",
    "X_train[\"class\"] = X_train[\"class\"].astype(str)\n",
    "X_test[\"class\"] = X_test[\"class\"].astype(str)\n",
    "X_val[\"class\"] = X_val[\"class\"].astype(str)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=X_train,\n",
    "                                                          directory=path,\n",
    "                                                           x_col = \"image name\",\n",
    "                                                           y_col = \"class\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (224, 224), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "\n",
    "val_generator = val_data_generator.flow_from_dataframe(dataframe=X_val,\n",
    "                                                          directory=path,\n",
    "                                                           x_col = \"image name\",\n",
    "                                                           y_col = \"class\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (224, 224), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=X_test,\n",
    "                                                          directory=path,\n",
    "                                                           x_col = \"image name\",\n",
    "                                                           y_col = \"class\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (224, 224), \n",
    "                                                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model creation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image in c:\\users\\barry\\anaconda3\\lib\\site-packages (from efficientnet) (0.17.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\barry\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (2.5)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (2020.10.1)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from scikit-image->efficientnet) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\barry\\anaconda3\\lib\\site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in c:\\users\\barry\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
      "Installing collected packages: keras-applications, efficientnet\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout,Dense, Flatten, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              64226304  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 27)                27675     \n",
      "=================================================================\n",
      "Total params: 68,303,543\n",
      "Trainable params: 68,261,527\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "n_class = 27\n",
    " \n",
    "model = Sequential()\n",
    "model.add(efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_class, activation=\"sigmoid\"))\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    \n",
    "# Compiling the model\n",
    "model.compile(RMSprop(lr=0.0001, decay=1e-6),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barry\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "450/450 [==============================] - 2903s 6s/step - loss: 3.2824 - accuracy: 0.1920 - val_loss: 2.3432 - val_accuracy: 0.3331\n",
      "Epoch 2/2\n",
      "209/450 [============>.................] - ETA: 24:39 - loss: 2.5095 - accuracy: 0.3062"
     ]
    }
   ],
   "source": [
    "# We will try to train the last stage of ResNet50\n",
    "\n",
    "\n",
    "# Training the model for 10 epochs\n",
    "model.fit_generator(train_generator, \n",
    "                                epochs = 2,\n",
    "                                steps_per_epoch = len(X_train)//batch_size,\n",
    "                                validation_data = val_generator,\n",
    "                                validation_steps = len(X_val)//batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement 4 derniers layers freezed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "tl_2_defreeze = model.fit_generator(generator=train_generator, \n",
    "                                epochs = 2,\n",
    "                                steps_per_epoch = len(X_train)//batch_size,\n",
    "                                validation_data=test_generator,\n",
    "                                validation_steps=len(X_val)//batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tl_pred_2 = model.predict_generator(test_generator, verbose = 1)\n",
    "y_tl_pred_2 = y_tl_pred_2.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_generator.classes, y_tl_pred_2 , average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(pd.DataFrame(confusion_matrix( test_generator.classes, y_tl_pred_2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
