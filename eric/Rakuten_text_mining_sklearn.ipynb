{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-collapse",
   "metadata": {},
   "source": [
    "# Projet RAKUTEN - Text Mining\n",
    "\n",
    "\n",
    "## 1. Presentation\n",
    "\n",
    "L'objectif est d'obtenir le meilleur score possible ([weighted F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html?highlight=f1%20score#sklearn.metrics.f1_score)) par des méthodes de machine learning de la librairie [scikit-learn](https://scikit-learn.org/stable/).\n",
    "\n",
    "A chaque échantillon du jeu de données est associé un texte qui est la concatenation des champs **designation** et **description** (ce dernier pouvant être vide). Le texte est ensuite vectorisé à l'aide de la fonction [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidfvectorizer#sklearn.feature_extraction.text.TfidfVectorizer). La matrice np.array obtenue est ensuite passée en entrée d'un classificateur au travers d'un pipe ([pipeline](https://scikit-learn.org/stable/modules/classes.html?highlight=pipe#module-sklearn.pipeline)) et le score obtenu est comparé à celui des autres classificateurs.\n",
    "\n",
    "## 2. Sélection initiale des classificateurs\n",
    "Les premiers essais ont été effectués avec un jeu de données réduit aux 20000 premiers échantillons (16000 pour l'entrainement et 4000 pour le test), afin de raccourcir les temps d'exécution. Plusieurs classificateurs ont été testés afin d'identifier les plus prometteurs.  \n",
    "  Durant cette étape, très peu de tuning a été effectué sur le tokenizer et la fonction TfidfVectorizer. \n",
    "  La fonction [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV) a permis de faire une sélection de base des paramètres de chacun de ces classificateurs.\n",
    "\n",
    "|  score | Classificateur      | Principaux paramètres             |\n",
    "|--------|:--------------------|:----------------------------------|\n",
    "| 0.7777 | SVC                 | C=10 kernel=linear                |\n",
    "| 0.7665 | LinearSVC           | dual=False penalty=l2             |\n",
    "| 0.7578 | LogisticRegression  | class_weight=balanced max_iter=200|\n",
    "| 0.7442 | SGDClassifier       | penaly=l2                         |\n",
    "| 0.7378 | MLPClassier         | hidden_layer_sizes=10 max_iter=40 |\n",
    "| 0.6344 | GaussianNB          | var_smoothing=1e-08               |\n",
    "| 0.6032 | KNeighborClassifier | metric=minkowski n_neighbors=4    |\n",
    "| 0.5476 | BernoulliNB         | alpha=0.3                         |\n",
    "| 0.1702 | RandomForest        | criterion=entropy max_depth=5     |\n",
    "\n",
    "\n",
    "## 3. Essais sur les classificateurs retenus\n",
    "\n",
    "Des essais supplémentaires ont été faits avec les classificateurs identifiés comme les meilleurs, en changeant les paramètres des classificateurs eux-mêmes mais aussi de tfidfVectorizer. Le tokenizer utilisé étant toujours celui de [Spacy](https://spacy.io/).\n",
    "\n",
    "|  score | Durée(s) | Classifier          | Principaux paramètres                      |\n",
    "|--------|:---------|:--------------------|:-------------------------------------------|\n",
    "| 0.7929 |  184     | SVC                 | kernel=linear decision_function_shape=ovo  |\n",
    "| 0.7863 |   10     | LinearSVC           | penalty=l1 dual=False \n",
    "| 0.7792 | 1466     | MLPClassifier       | layer_sizes=40, max_iter=40                |\n",
    "| 0.7708 |  109     | LogisticRegression  | class_weight=balanced max_iter=200         |\n",
    "| 0.6459 |    4     | KNeighborClassifier | n_neighbors=5  metric=minkowski            |                            \n",
    "\n",
    "Quelques essais ont été faits avec des méthodes ensemble. L'utilisation de AdaBoostClassifier ne donne rien (peut être une mauvaise manip), le XGBoost n'a pas été essayé.\n",
    "\n",
    "|  score | Durée(s) | Classifier       | Principaux paramètres                                       |\n",
    "|--------|:----------|:----------------|:------------------------------------------------------------|\n",
    "| 0.7885 | 295      | VotingClassifier | estimator=(knn, lr, svc) voting=hard weights=(1,2,2)        |\n",
    "| 0.7835 | 308      | VotingClassifier | estimator=(knn, lr, svc) voting=hard weights=None           |\n",
    "| 0.7628 | 1630     | StackingClassifer| estimator=(knn, lr, svc) final_estimator=LogisticRegression |  \n",
    "\n",
    "\n",
    "Au final, le MLP semble interessant mais il est trop lent sur un PC de base. SVC(linear) et [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) qui sont similaires donnent les meilleurs scores, le dernier est plus interessant car beaucoup plus rapide, sans doute en raison de son implémentaion dans scikit-learn.\n",
    "\n",
    "La fonction python **evaluate_model()** définie dans ce notebook a été utilisée pour évaluer les modèles et afficher leurs performances. \n",
    "\n",
    "\n",
    "## 4. Tuning sur LinearSVC\n",
    "\n",
    "Dans cette phase, du réglage itératif a été fait sur les différents éléments suivants:\n",
    "  * Le **tokenizer**: utilisation de Spacy ou du tokenizer par défault de scikit-learn, utilisation du lemmatizer, passage ou non en minuscule, suppression ou non des accents, suppression ou non des balises html (qu'on observe dans plusieurs échantillons), etc.\n",
    "  * **tfidfVectorizer**: strip_accents, stop_words, max_df, min_df, ngram_range, use_idf, smooth_idf, sublinear_tf, binary\n",
    "  * **LinearSVC**: penalty, C, dual, tol, max_depth\n",
    "\n",
    "Afin d'optimiser le temps des tests, la fonction python **evaluate_tfclf_step_by_step()** a été utilisée. Cette fonction définie ci-dessous évalue le modèle en commençant par une taille de 4000 et en augmentant le nombre d'échantillons par pas de 5000. Ainsi, on peut laisser le test se dérouler tant qu'on observe une amélioration par rapport à un test précédent ou bien l'interrompre; les résultats sont stockés dans un fichier [pickle](https://docs.python.org/3/library/pickle.html) au fur et à mesure, ainsi si le programe est interrompu, il repart de là où il était: Il faut penser à effacer ce fichier cache avant d erelancer untest depuis le début.\n",
    "\n",
    "\n",
    "## 5. Code commun\n",
    "\n",
    "Ci dessous les fonctions utilisées dans ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "composite-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier,NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "def f1_score_w(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Score utilisé par Rakuten\n",
    "    \"\"\"\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "def read_X(X_file):\n",
    "    \"\"\"\n",
    "    Lecture d'un fichier de données (dataframe) X et petit nettoyage\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(X_file)\n",
    "    # La première colonne est un doublon:\n",
    "    #          df[\"Unnamed: 0\"] == df.index \n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    # Les colonnes designation et description sont à l'origine de type objet\n",
    "    #          df.info()\n",
    "    df.designation = df.designation.astype('string')\n",
    "    df.description = df.description.astype('string')\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_accents(text):\n",
    "    \"\"\"\n",
    "    Supprime les accents du texte <text>\n",
    "    \"\"\"\n",
    "    accents = { 'a': ['à', 'ã', 'á', 'â'],\n",
    "                'e': ['é', 'è', 'ê', 'ë'],\n",
    "                'i': ['î', 'ï'],\n",
    "                'u': ['ù', 'ü', 'û'],\n",
    "                'o': ['ô', 'ö'] }\n",
    "    for ch in accents:\n",
    "        for chacc in accents[ch]:\n",
    "            text = text.replace(chacc, ch)\n",
    "    return text\n",
    "\n",
    "\n",
    "#reclean = re.compile(r\"(\\<.*?\\>|\\&\\#\\d+\\;)\")\n",
    "def X_text(X):\n",
    "    \"\"\"\n",
    "    A partir d'un dataframe X retourne une liste de textes (un par échantillon\n",
    "    du dataframe X)\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    for desc, desi in zip(X.description, X.designation):\n",
    "        descstr = desc if type(desc) == str else ''\n",
    "        desistr = desi if type(desi) == str else ''\n",
    "        sep = ' ' if type(desc) == str and type(desi) == str else ''\n",
    "        s = descstr + sep + desistr\n",
    "        #s = reclean.sub(' ', s)\n",
    "        #s = html.unescape(s)\n",
    "        #s = re.sub(r\"(\\<)\", \" \\1\",s)\n",
    "        #s = re.sub(r\"(\\>)\", \"\\1 \",s)\n",
    "        s = s.lower() + ' ' + re.sub(r\"([^A-Z0-9°\\+\\*\\=]+)\",\"\",s).lower()\n",
    "        lst.append(s)\n",
    "    return lst\n",
    "\n",
    "\n",
    "spacynlp = None\n",
    "spacyre = re.compile(r\"(<.*?>|&#\\d+;|\\'|\\:|\\.|\\-|\\+)\")\n",
    "french_stop_words = set(stopwords.words('french'))\n",
    "french_stop_words_no_accent = [remove_accents(x) for x in french_stop_words]\n",
    "def tokenize_spacy(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizer basé sur spacy\n",
    "    \"\"\"\n",
    "    global spacynlp\n",
    "    if spacynlp is None:\n",
    "        spacynlp = spacy.load(\"fr_core_news_sm\")\n",
    "        spacynlp.disable_pipes ('tagger', 'parser', 'ner')\n",
    "    s = sentence\n",
    "    t = [x.lemma_ for x in spacynlp(s)]\n",
    "    #t = [x.text for x in spacynlp(s) if not x.text in french_stop_words]\n",
    "    return t\n",
    "\n",
    "\n",
    "def evaluate_model(name, model, X_trn, X_tst, y_trn, y_tst):\n",
    "    \"\"\"\n",
    "    Entraine un modèle <model> nommé <name> et affiche son score\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    model.fit(X_trn, y_trn)\n",
    "    y_pred = model.predict(X_tst)\n",
    "    stop = time.time()\n",
    "    score = f1_score_w(y_tst, y_pred)\n",
    "    print(f\"{name:<15} weighted-F1-score = {round(score,5)} ({round(stop-start,2)}s)\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_tfclf_step_by_step(name, clf):\n",
    "    \"\"\"\n",
    "    Entraine le model <clf> nommé <name> avec des tailles croissantes d'échantillons\n",
    "    et affiche une synthèse à la fin\n",
    "    \"\"\"\n",
    "    def display_progress(df, nb):\n",
    "        r = df.loc[nb]\n",
    "        print(f\"nb={nb} w-f1-score={r.score} ({int(r.vocalen)} mots, {r.time} sec)\")\n",
    "    \n",
    "    X0 = read_X(\"X_train_update.csv\")\n",
    "    y0 = pd.read_csv(\"Y_train_CVw08PX.csv\").drop(\"Unnamed: 0\", axis=1)[\"prdtypecode\"]\n",
    "    test_size = 0.20\n",
    "    X, y = shuffle(X_text(X0), y0, random_state=51)\n",
    "    filename = name + \".pkl\"\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_pickle(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame({'nb':[], 'score':[], 'vocalen':[], 'time': []})\n",
    "\n",
    "    for nb in range(4000, len(X), 8000):\n",
    "        if nb in df.index:\n",
    "            display_progress(df, nb)\n",
    "            continue\n",
    "        X_trn, X_tst, y_trn, y_tst = train_test_split(X[:nb], y[:nb], shuffle=True, random_state=51)\n",
    "        now = datetime.datetime.now().strftime(\"%Hh%Mmn\")\n",
    "        print(f\"... Evaluation avec {nb} échantillons ({now}) ...\")\n",
    "        start = time.time()\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        y_pred = clf.predict(X_tst)\n",
    "        vocalen = len(clf[0].vocabulary_)\n",
    "        stop = time.time()\n",
    "        delta = round(stop-start,2)\n",
    "        score = round(f1_score_w(y_tst, y_pred), 5)\n",
    "        df.loc[nb] = [nb, score, vocalen, delta]\n",
    "        display_progress(df, nb)\n",
    "        df.to_pickle(filename)    \n",
    "\n",
    "    # Affichage\n",
    "    filename = name + \".pkl\"\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"File {filename} not found!\")\n",
    "        return\n",
    "    df = pd.read_pickle(filename)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    ax1 = plt.subplot(1,1,1)\n",
    "    ibest = df.score.sort_values().index[-1:]\n",
    "    bestnb = np.float(df.nb[ibest])\n",
    "    bestscore = np.float(df.score[ibest])\n",
    "    plt.plot(df.nb, df.score,c='b', label='weighted F1 score')\n",
    "    plt.plot(np.array([0, bestnb, bestnb], dtype=object),\n",
    "             np.array([bestscore, bestscore, 0], dtype=object))\n",
    "    plt.title(f\"Score = {bestscore} pour {int(bestnb)} échantillons\")\n",
    "    plt.xlim(4000, df.nb.max() + 1000)\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlabel(\"Nombre d'échantillons\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-chapter",
   "metadata": {},
   "source": [
    "## 6. Resultats obtenus\n",
    "\n",
    "Le meilleur classificateur et ses résultats (weighted F1 score) pour des échantillons de tailles croissantes, suivi d'une évaluation sur le jeu complet (en utilisant 20% d'échantillon pour les tests) et affichage du rapport de classification ainsi que de la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "individual-chrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb=4000 w-f1-score=0.69037 (38828 mots, 16.1 sec)\n",
      "nb=12000 w-f1-score=0.77259 (97274 mots, 23.63 sec)\n",
      "nb=20000 w-f1-score=0.80088 (147041 mots, 36.48 sec)\n",
      "nb=28000 w-f1-score=0.80738 (193450 mots, 48.02 sec)\n",
      "nb=36000 w-f1-score=0.82238 (238859 mots, 61.07 sec)\n",
      "nb=44000 w-f1-score=0.83046 (279268 mots, 75.73 sec)\n",
      "nb=52000 w-f1-score=0.83586 (317898 mots, 97.79 sec)\n",
      "nb=60000 w-f1-score=0.84087 (355611 mots, 112.35 sec)\n",
      "nb=68000 w-f1-score=0.84643 (394333 mots, 127.37 sec)\n",
      "nb=76000 w-f1-score=0.84219 (425607 mots, 136.0 sec)\n",
      "nb=84000 w-f1-score=0.84828 (462003 mots, 152.96 sec)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Meilleur classifier\n",
    "#\n",
    "clf_linearsvc = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "                  tokenizer=tokenize_spacy,\n",
    "                      #strip_accents='unicode',\n",
    "                      #stop_words=french_stop_words_no_accent, # peut etre interessant parce que lisse la progression\n",
    "                  max_df=0.8,\n",
    "                  min_df=2,\n",
    "                  ngram_range=(1,2),\n",
    "                  use_idf=True,\n",
    "                  smooth_idf=True,\n",
    "                  sublinear_tf=False,\n",
    "                  binary=True,\n",
    "                  ),\n",
    "    LinearSVC(penalty=\"l2\", dual=True, C=0.8, tol=1e-5, max_iter=4000),\n",
    ")\n",
    "evaluate_tfclf_step_by_step(\"clf_linearsvc_learning\", clf_linearsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "artificial-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.65      0.62      0.63       649\n",
      "          40       0.81      0.71      0.76       482\n",
      "          50       0.81      0.86      0.83       352\n",
      "          60       0.99      0.87      0.92       169\n",
      "        1140       0.78      0.84      0.80       549\n",
      "        1160       0.94      0.96      0.95       822\n",
      "        1180       0.85      0.67      0.75       164\n",
      "        1280       0.74      0.66      0.70       982\n",
      "        1281       0.71      0.61      0.65       386\n",
      "        1300       0.87      0.94      0.90       997\n",
      "        1301       0.97      0.93      0.95       159\n",
      "        1302       0.86      0.85      0.86       465\n",
      "        1320       0.89      0.84      0.86       640\n",
      "        1560       0.83      0.86      0.84      1018\n",
      "        1920       0.91      0.93      0.92       864\n",
      "        1940       0.91      0.94      0.93       162\n",
      "        2060       0.84      0.82      0.83      1018\n",
      "        2220       0.90      0.85      0.88       153\n",
      "        2280       0.85      0.90      0.87       963\n",
      "        2403       0.76      0.81      0.78       922\n",
      "        2462       0.84      0.81      0.82       275\n",
      "        2522       0.92      0.96      0.94       958\n",
      "        2582       0.83      0.77      0.80       527\n",
      "        2583       0.96      0.99      0.98      2073\n",
      "        2585       0.86      0.83      0.84       493\n",
      "        2705       0.76      0.79      0.78       587\n",
      "        2905       0.99      0.99      0.99       155\n",
      "\n",
      "    accuracy                           0.85     16984\n",
      "   macro avg       0.85      0.84      0.84     16984\n",
      "weighted avg       0.85      0.85      0.85     16984\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>10</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>1140</th>\n",
       "      <th>1160</th>\n",
       "      <th>1180</th>\n",
       "      <th>1280</th>\n",
       "      <th>1281</th>\n",
       "      <th>1300</th>\n",
       "      <th>...</th>\n",
       "      <th>2220</th>\n",
       "      <th>2280</th>\n",
       "      <th>2403</th>\n",
       "      <th>2462</th>\n",
       "      <th>2522</th>\n",
       "      <th>2582</th>\n",
       "      <th>2583</th>\n",
       "      <th>2585</th>\n",
       "      <th>2705</th>\n",
       "      <th>2905</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prdtypecode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>404</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>37</td>\n",
       "      <td>343</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>459</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>791</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>652</td>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>934</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>864</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>406</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2054</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        10    40    50    60    1140  1160  1180  1280  1281  1300  ...  \\\n",
       "prdtypecode                                                              ...   \n",
       "10            404    12     0     0     1     3     1     6     1     2  ...   \n",
       "40             37   343    23     0    10     4     4    12     3     1  ...   \n",
       "50              3    15   302     2     5     0     0     2     0     3  ...   \n",
       "60              1     1     9   147     1     0     0     0     2     0  ...   \n",
       "1140            1     8     3     0   459     7     3    24     5     3  ...   \n",
       "1160            5     3     1     0     1   791     2     0     4     0  ...   \n",
       "1180            3     2     0     0    11     2   110     7    12     2  ...   \n",
       "1280            8     4     4     0    56     8     2   652    41   112  ...   \n",
       "1281            9    11     1     0    11     6     4    78   234     2  ...   \n",
       "1300            2     2     0     0     7     0     2    31     2   934  ...   \n",
       "1301            0     0     0     0     0     0     0     1     1     1  ...   \n",
       "1302            2     2     1     0     1     3     0    24     6     0  ...   \n",
       "1320            5     2     0     0     3     1     1    27     1     0  ...   \n",
       "1560            1     0     1     0     0     0     0     3     1     3  ...   \n",
       "1920            1     0     2     0     0     0     0     1     0     0  ...   \n",
       "1940            0     0     0     0     0     0     0     1     0     1  ...   \n",
       "2060            3     1     2     0     5     0     0     7     2     1  ...   \n",
       "2220            0     1     0     0     1     0     0     0     0     1  ...   \n",
       "2280           19     2     1     0     5     3     0     1     0     2  ...   \n",
       "2403           46     3     0     0     6     6     1     2     3     4  ...   \n",
       "2462            1     9    21     0     5     2     0     1     5     0  ...   \n",
       "2522            4     0     1     0     3     1     0     1     2     0  ...   \n",
       "2582            0     0     0     0     0     0     0     2     0     0  ...   \n",
       "2583            2     0     0     0     0     0     0     0     2     1  ...   \n",
       "2585            1     1     1     0     0     0     0     1     0     1  ...   \n",
       "2705           68     2     0     0     1     3     0     0     4     1  ...   \n",
       "2905            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "col_0        2220  2280  2403  2462  2522  2582  2583  2585  2705  2905  \n",
       "prdtypecode                                                              \n",
       "10              4    44    82     1     2     1     5     0    70     0  \n",
       "40              1     4     9    13     0     0     0     0    14     1  \n",
       "50              0     0     1    12     0     0     1     0     1     0  \n",
       "60              0     0     0     7     0     0     0     0     1     0  \n",
       "1140            0     6     7     1     5     0     1     0     7     0  \n",
       "1160            0     5     5     1     1     0     1     0     0     0  \n",
       "1180            0     0     4     0     1     0     1     0     1     0  \n",
       "1280            2     6     6     5     9     4     5     5     2     0  \n",
       "1281            0     2     5     2     1     0     1     0     8     0  \n",
       "1300            0     6     3     0     2     0     3     3     0     0  \n",
       "1301            0     0     2     0     1     0     1     0     1     0  \n",
       "1302            0     0     1     0     3     1    15     1     0     0  \n",
       "1320            1     0     1     0     3     2     5     1     2     0  \n",
       "1560            0     0     3     0    12    30     3    12     0     0  \n",
       "1920            0     0     0     0     2     2     0     0     1     0  \n",
       "1940            0     0     2     0     0     0     1     1     0     0  \n",
       "2060            1     2     5     1    15    15     6    11     0     0  \n",
       "2220          130     0     0     0     1     2     1     3     0     0  \n",
       "2280            0   864    58     0     3     0     0     0     5     0  \n",
       "2403            0    66   743     1    10     0     0     0    26     0  \n",
       "2462            0     0     6   223     0     1     1     0     0     0  \n",
       "2522            0     1     7     0   919     1     1     5     3     0  \n",
       "2582            4     0     0     0     5   406    10    20     1     0  \n",
       "2583            0     0     0     0     0     4  2054     3     0     0  \n",
       "2585            1     1     1     0     4    19    18   408     0     0  \n",
       "2705            0    12    25     0     0     0     0     0   466     0  \n",
       "2905            0     0     0     0     0     0     0     0     1   154  \n",
       "\n",
       "[27 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Evaluation sur tous les échantillons\n",
    "#\n",
    "X_train = read_X(\"X_train_update.csv\")\n",
    "y_train = pd.read_csv(\n",
    "        \"Y_train_CVw08PX.csv\").drop(\"Unnamed: 0\", axis=1)[\"prdtypecode\"]\n",
    "\n",
    "# Split train / test\n",
    "X, y = X_text(X_train), y_train\n",
    "X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=51)\n",
    "\n",
    "clf_linearsvc.fit(X_trn, y_trn)\n",
    "y_pred = clf_linearsvc.predict(X_tst)\n",
    "\n",
    "print(classification_report(y_tst, y_pred))\n",
    "pd.crosstab(y_tst, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-croatia",
   "metadata": {},
   "source": [
    "## Annexe: Essais divers\n",
    "\n",
    "Les cellules suivantes sont des reliquats des essais faits. Elle sont là juste pour information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Classifiers principaux\n",
    "#\n",
    "\n",
    "# Classificateur knn\n",
    "clf_knn = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "                  #strip_accents='ascii',\n",
    "                  stop_words=french_stop_words,\n",
    "                  max_df=0.8,\n",
    "                  min_df=1,\n",
    "                  ngram_range=(1,1),\n",
    "                  use_idf=False,\n",
    "                  smooth_idf=False,\n",
    "                  sublinear_tf=False,\n",
    "                  binary=False,\n",
    "                  #max_features=10000,\n",
    "                  ),\n",
    "    KNeighborsClassifier(5, metric='minkowski')\n",
    "    )\n",
    "# evaluate_model(\"KNeighbors\",clf_knn, X_trn, X_tst, y_trn, y_tst)\n",
    "# KNeighbors      weighted-F1-score = 0.64587 (3.94s)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# Multi Layer Perceptron\n",
    "clf_mlp = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "                  #strip_accents='ascii',\n",
    "                  #stop_words=french_stop_words,\n",
    "                  max_df=0.7,\n",
    "                  min_df=2,\n",
    "                  ngram_range=(1,2),\n",
    "                  use_idf=True,\n",
    "                  smooth_idf=False,\n",
    "                  sublinear_tf=True,\n",
    "                  binary=False,\n",
    "                  #max_features=10000,\n",
    "                  ),\n",
    "  MLPClassifier(hidden_layer_sizes=40, max_iter=120)\n",
    ")\n",
    "# evaluate_model(\"MLPClassifier\", clf_mlp, X_trn, X_tst, y_trn, y_tst)\n",
    "# MLPClassifier   weighted-F1-score = 0.77926 (1466.85s) => layer_sizes=40, max_iter=40 (non convergé)\n",
    "# MLPClassifier   weighted-F1-score = 0.77997 (2699.99s) => layer_sizes=40, max_iter=40 (non convergé)\n",
    "# MLPClassifier   weighted-F1-score = 0.74501 (1872.38s) => layer_sizes=(30,20), max_iter=120\n",
    "# MLPClassifier   weighted-F1-score = 0.81148 (1544.0s)maxbb=40000 layers=100 iter=100 # not converged\n",
    "# MLPClassifier   weighted-F1-score = 0.81063 (383.84s) maxbb=40000 layers=40 iter=60\n",
    "# MLPClassifier   weighted-F1-score = 0.80983 (567.91s) maxbb=40000 layers=60 iter=60 # not converge\n",
    "# MLPClassifier   weighted-F1-score = 0.78536 (476.94s) maxbb=40000 layers=(40,30) iter=80\n",
    "# MLPClassifier   weighted-F1-score = 0.77534 (210.9s)  maxbb=40000 layers=(20,20) iter=60\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# Régression logistique\n",
    "clf_lr = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "                  #strip_accents='ascii',\n",
    "                  #stop_words=french_stop_words,\n",
    "                  max_df=0.7,\n",
    "                  min_df=2,\n",
    "                  ngram_range=(1,2),\n",
    "                  use_idf=True,\n",
    "                  smooth_idf=False,\n",
    "                  sublinear_tf=True,\n",
    "                  binary=False,\n",
    "                  #max_features=10000,\n",
    "                  ),\n",
    "     LogisticRegression(class_weight='balanced',\n",
    "                            max_iter=300)\n",
    "    )\n",
    "# evaluate_model(\"LogisticRegession\", clf_lr, X_trn, X_tst, y_trn, y_tst)\n",
    "# LogisticRegession weighted-F1-score = 0.77083 (109.36s)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# LinearSVC\n",
    "clf_linearsvc = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "       strip_accents='ascii',\n",
    "                  stop_words=french_stop_words_no_accent,\n",
    "                  max_df=0.8,\n",
    "                  min_df=3,\n",
    "                  ngram_range=(1,2),\n",
    "                  use_idf=True,\n",
    "                  smooth_idf=True,\n",
    "                  sublinear_tf=False,\n",
    "                  binary=True,\n",
    "                  #max_features=2000,\n",
    "                  ),\n",
    "    LinearSVC(penalty=\"l1\", dual=False,\n",
    "                              tol=1e-4)\n",
    ")\n",
    "# evaluate_model(\"LinearSVC\", clf_linearsvc, X_trn, X_tst, y_trn, y_tst)\n",
    "# LinearSVC       weighted-F1-score = 0.78634 (9.95s)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# SVC\n",
    "clf_svc = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "       strip_accents='ascii',\n",
    "                  stop_words=french_stop_words_no_accent,\n",
    "                  max_df=0.8,\n",
    "                  min_df=3,\n",
    "                  ngram_range=(1,2),\n",
    "                  use_idf=True,\n",
    "                  smooth_idf=True,\n",
    "                  sublinear_tf=False,\n",
    "                  binary=True,\n",
    "                  #max_features=2000,\n",
    "                  ),\n",
    "    SVC(C=8,\n",
    "        kernel='linear',\n",
    "        decision_function_shape='ovo')\n",
    ")\n",
    "# evaluate_model(\"SVC\", clf_svc, X_trn, X_tst, y_trn, y_tst)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# SVC weighted-F1-score = 0.78578 (337.33s) max_df=0.8 min_df=1 ngram_range=(1,2)\n",
    "# SVC weighted-F1-score = 0.78878 (270.47s) max_df=0.7 min_df=2 ngram_range=(1,2)\n",
    "# SVC weighted-F1-score = 0.78878 (238.35s) max_df=0.8 min_df=2 ngram_range=(1,2)\n",
    "# SVC weighted-F1-score = 0.78716 (279.16s) max_df=0.8 min_df=3 ngram_range=(1,3)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# SVC weighted-F1-score = 0.78957 (204.13s) max_df=0.8 min_df=3 ngram_range=(1,2) <-----\n",
    "# SVC weighted-F1-score = 0.78886 (214.84s) max_df=0.8 min_df=3 ngram_range=(1,2) sublinear_tf=True\n",
    "# SVC weighted-F1-score = 0.78699 (149.17s) max_df=0.8 min_df=3 ngram_range=(1,2) stop\n",
    "# ---------------------------------------------------------------------------------\n",
    "# SVC weighted-F1-score = 0.78787 (247.04s) max_df=0.8 min_df=3 ngram_range=(1,2) bin\n",
    "# SVC weighted-F1-score = 0.79075 (180.35s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop\n",
    "# SVC weighted-F1-score = 0.79244 (190.06s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop strip_accent\n",
    "# SVC weighted-F1-score = 0.79267 (179.23s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop_no-acc strip_accent\n",
    "# SVC weighted-F1-score = 0.79208 (181.83s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop_no-acc strip_accent C=12\n",
    "# SVC weighted-F1-score = 0.79118 (180.95s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop_no-acc strip_accent C=6\n",
    "# SVC weighted-F1-score = 0.79293 (182.64s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop_no-acc strip_accent C=8 <--\n",
    "# SVC weighted-F1-score = 0.79184 (174.71s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop_no-acc strip_accent C=8 balanced\n",
    "# SVC weighted-F1-score = 0.79293 (198.12s) max_df=0.8 min_df=3 ngram_range=(1,2) bin stop_no-acc strip_accent C=8 'ovo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "latin-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Méthodes Ensemble\n",
    "#\n",
    "\n",
    "clf_voting_1 = VotingClassifier(estimators=[('knn', clf_knn), ('lr', clf_lr), ('svc', clf_svc)],\n",
    "                        voting='hard')\n",
    "#evaluate_model(\"Voting 1\", clf_voting_1, X_trn, X_tst, y_trn, y_tst)\n",
    "#Voting 1        weighted-F1-score = 0.78345 (308.47s)\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "clf_voting_2 = VotingClassifier(estimators=[('knn', clf_knn), ('lr', clf_lr), ('svc', clf_svc)],\n",
    "                        voting='hard', weights=[1,2,2])\n",
    "#evaluate_model(\"Voting 2\", clf_voting_2, X_trn, X_tst, y_trn, y_tst)\n",
    "# Voting 2        weighted-F1-score = 0.78854 (295.45s)\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "clf_stacking_1 = StackingClassifier(estimators=[('knn', clf_knn), ('lr', clf_lr), ('svc', clf_svc)],\n",
    "                                 final_estimator=LogisticRegression())\n",
    "#evaluate_model(\"Stacking 1\", clf_stacking_1, X_trn, X_tst, y_trn, y_tst)\n",
    "# Stacking 1      weighted-F1-score = 0.76282 (1630.94s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "square-privacy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Essai réduction de dimension\n",
    "#\n",
    "clf_redim_svc = make_pipeline(\n",
    "    TfidfVectorizer(analyzer='word',\n",
    "                  #strip_accents='ascii',\n",
    "                  #tokenizer=tokenize_spacy,\n",
    "                  #stop_words=french_stop_words_no_accent,\n",
    "                  max_df=0.8,\n",
    "                  min_df=2,\n",
    "                  ngram_range=(1,2),\n",
    "                  use_idf=True,\n",
    "                  smooth_idf=True,\n",
    "                  sublinear_tf=False,\n",
    "                  binary=True,\n",
    "                  ),\n",
    "   SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                              tol=1e-4, max_iter=1500)),\n",
    "    SVC(C=8,\n",
    "        kernel='linear',\n",
    "        decision_function_shape='ovo')\n",
    ")\n",
    "\n",
    "\n",
    "evaluate_tfclf_step_by_step(\"clf_redim_svc_learning\", clf_redim_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
