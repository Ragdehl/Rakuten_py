{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DEEPLEARNING IMAGES & TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Edgar\\\\Documents\\\\Rakuten\\\\images\\\\image_train'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import os #Miscellaneous operating system interfaces\n",
    "#https://docs.python.org/3/library/os.html\n",
    "#get current working directory\n",
    "path = os.getcwd() + '\\\\images\\\\image_train'\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données textuelles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv(r'C:\\Users\\Edgar\\Documents\\Rakuten\\X_train\\X_train_lemma-FR_stop_words-FR_no_num-FR_remove_accents-FR_no_special-FR_lemma-EN_stop_words-EN_stop_words-DE_lemma-DE_steem-FR_steem-EN_steem-DE.csv',index_col =0)\n",
    "df_y = pd.read_csv(r'C:\\Users\\Edgar\\Documents\\Rakuten\\Y_train_CVw08PX.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84911</th>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84912</th>\n",
       "      <td>2583</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84913</th>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84914</th>\n",
       "      <td>1560</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84915</th>\n",
       "      <td>2522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84916 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prdtypecode  label\n",
       "0               10      0\n",
       "1             2280      1\n",
       "2               50      2\n",
       "3             1280      3\n",
       "4             2705      4\n",
       "...            ...    ...\n",
       "84911           40     18\n",
       "84912         2583     12\n",
       "84913         2280      1\n",
       "84914         1560      7\n",
       "84915         2522      5\n",
       "\n",
       "[84916 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y['label'] = df_y['prdtypecode'].replace(df_y.prdtypecode.unique(), [*range(len(df_y.prdtypecode.unique()))])\n",
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de mots par texte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.rename(columns={'0':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKQAAAE+CAYAAACz5shSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3defxdVX3v//cnCZMoggVRiL34s1xv0U4/qZd7rb2t/n4mJEySoNgfQqv90SJOvbZWa21tFYt1qgxJmMMohIQMBmhFFBFFMQgyiUABScj0hZB5/n7X/WOtT/bn7JzvNyfD2d8hr+fjcR5nnz2uvfbaa+/92WvvYyklAQAAAAAAAE0ZNdgJAAAAAAAAwN6FgBQAAAAAAAAaRUAKAAAAAAAAjSIgBQAAAAAAgEYRkAIAAAAAAECjCEgBAAAAAACgUWMGOwHdcuihh6ajjjpqsJMBAAAAAAAwYtx///0vpJQO2935jNiA1FFHHaUFCxYMdjIAAAAAAABGDDP71Z6YD4/sAQAAAAAAoFEEpAAAAAAAANAoAlIAAAAAAABoFAEpAAAAAAAANIqAFAAAAAAAABpFQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaNReF5DqmXrNYCcBAAAAAABgr7bXBaQAAAAAAAAwuAhIAQAAAAAAoFEEpAAAAAAAANAoAlIAAAAAAABoFAEpAAAAAAAANGqvCkjxD3sAAAAAAACDb68KSAEAAAAAAGDwEZACAAAAAABAowhIAQAAAAAAoFEEpAAAAAAAANAoAlIAAAAAAABoFAEpAAAAAAAANIqAFAAAAAAAABpFQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRXQ9ImdloM3vAzOaX368yszvM7MnyfUgY99Nm9pSZ/dLMxoX+bzGzh8uwC8zMup1uAAAAAAAAdEcTLaQ+JukX4fenJN2ZUjpa0p3lt8zsGEmnS3qTpPGSppjZ6DLNVElnSzq6fMY3kG4AAAAAAAB0QVcDUmY2VtJESZeH3idLurp0Xy3plND/xpTSppTSM5KekvRWM3utpINSSvemlJKka8I0AAAAAAAAGGa63ULq3yR9UlJf6Hd4SmmJJJXvV5f+R0paGMZbVPodWbrr/QEAAAAAADAMdS0gZWYnSFqeUrq/00na9EsD9G+3zLPNbIGZLejp6elwsQAAAAAAAGhSN1tIvU3SSWb2rKQbJb3DzK6TtKw8hqfyvbyMv0jS68L0YyUtLv3Htum/nZTSpSmlY1NKxx522GEDJq5n6tUDDgcAAAAAAEB3dC0glVL6dEppbErpKOWXlX83pXSGpHmSziqjnSVpbumeJ+l0M9vPzF6v/PLy+8pjfWvM7Ljy73pnhmkAAAAAAAAwzIwZhGWeL2mGmX1Q0nOSTpOklNKjZjZD0mOStko6N6XUW6Y5R9J0SQdIur18AAAAAAAAMAw1EpBKKd0l6a7S/aKkd/Yz3nmSzmvTf4GkN3cvhQAAAAAAAGhKt/9lDwAAAAAAAGhBQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADSKgBQAAAAAAAAaRUAKAAAAAAAAjSIgBQAAAAAAgEYRkAIAAAAAAECjCEgBAAAAAACgUQSkAAAAAAAA0CgCUgAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGkVACgAAAAAAAI0iIAUAAAAAAIBGEZACAAAAAABAowhIAQAAAAAAoFEEpAAAAAAAANAoAlIAAAAAAABoFAEpAAAAAAAANIqAFAAAAAAAABpFQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADRqrw5I9UydPthJAAAAAAAA2Ovs1QEpAAAAAAAANI+AFAAAAAAAABpFQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADSKgBQAAAAAAAAaRUAKAAAAAAAAjSIgBQAAAAAAgEYRkAIAAAAAAECjCEgBAAAAAACgUQSkAAAAAAAA0CgCUgAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGtW1gJSZ7W9m95nZz83sUTP7p9L/VWZ2h5k9Wb4PCdN82syeMrNfmtm40P8tZvZwGXaBmVm30g0AAAAAAIDu6mYLqU2S3pFS+h1JvytpvJkdJ+lTku5MKR0t6c7yW2Z2jKTTJb1J0nhJU8xsdJnXVElnSzq6fMZ3Md0AAAAAAADooq4FpFK2tvzcp3ySpJMlXV36Xy3plNJ9sqQbU0qbUkrPSHpK0lvN7LWSDkop3ZtSSpKuCdMAAAAAAABgmOnqO6TMbLSZPShpuaQ7Uko/kXR4SmmJJJXvV5fRj5S0MEy+qPQ7snTX+7db3tlmtsDMFvT09OzZlQEAAAAAAMAe0dWAVEqpN6X0u5LGKrd2evMAo7d7L1QaoH+75V2aUjo2pXTsYYcdtvMJBgAAAAAAQNc18i97KaWVku5SfvfTsvIYnsr38jLaIkmvC5ONlbS49B/bpj8AAAAAAACGoW7+y95hZnZw6T5A0v8j6XFJ8ySdVUY7S9Lc0j1P0ulmtp+ZvV755eX3lcf61pjZceXf9c4M0wAAAAAAAGCYGdPFeb9W0tXln/JGSZqRUppvZvdKmmFmH5T0nKTTJCml9KiZzZD0mKStks5NKfWWeZ0jabqkAyTdXj4AAAAAAAAYhroWkEopPSTp99r0f1HSO/uZ5jxJ57Xpv0DSQO+fAgAAAAAAwDDRyDukAAAAAAAAAEdACgAAAAAAAI3aKwJSPVOvHewkAAAAAAAAoNgrAlIAAAAAAAAYOghIAQAAAAAAoFEEpAAAAAAAANAoAlIAAAAAAABoFAEpAAAAAAAANIqAFAAAAAAAABpFQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADSKgJSknqnTBzsJAAAAAAAAew0CUgAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGkVACgAAAAAAAI0iIAUAAAAAAIBGEZACAAAAAABAowhIAQAAAAAAoFEdBaTM7M5O+gEAAAAAAAA7MmaggWa2v6SXSTrUzA6RZGXQQZKO6HLaAAAAAAAAMAINGJCS9BeSPq4cfLpfVUBqtaSLu5guAAAAAAAAjFADBqRSSt+Q9A0z+0hK6cKG0gQAAAAAAIARbEctpCRJKaULzex/SjoqTpNSuqZL6QIAAAAAAMAI1VFAysyulfQGSQ9K6i29kyQCUgAAAAAAANgpHQWkJB0r6ZiUUupmYgAAAAAAADDyjepwvEckvaabCQEAAAAAAMDeodMWUodKeszM7pO0yXumlE7qSqoAAAAAAAAwYnUakPpcNxMBAAAAAACAvUen/7L3/W4nBAAAAAAAAHuHTv9lb43yv+pJ0r6S9pG0LqV0ULcSBgAAAAAAgJGp0xZSr4i/zewUSW/tSooAAAAAAAAwonX6L3stUkpzJL1jD6cFAAAAAAAAe4FOH9k7NfwcJelYVY/wAQAAAAAAAB3r9F/2TgzdWyU9K+nkPZ4aAAAAAAAAjHidvkPqz7qdEAAAAAAAAOwdOnqHlJmNNbPZZrbczJaZ2SwzG9vtxAEAAAAAAGDk6fSl5ldJmifpCElHSvpW6QcAAAAAAADslE4DUoellK5KKW0tn+mSDutiugAAAAAAADBCdRqQesHMzjCz0eVzhqQXu5kwAAAAAAAAjEydBqQ+IOk9kpZKWiJpsiRedA4AAAAAAICd1tG/7En6vKSzUkovSZKZvUrSV5QDVQAAAAAAAEDHOm0h9dsejJKklNIKSb/XnSQBAAAAAABgJOs0IDXKzA7xH6WFVKetq4aFnqlXqWcqfxwIAAAAAADQbZ0Glb4q6UdmNlNSUn6f1HldSxUAAAAAAABGrI5aSKWUrpE0SdIyST2STk0pXTvQNGb2OjP7npn9wsweNbOPlf6vMrM7zOzJ8h1bXn3azJ4ys1+a2bjQ/y1m9nAZdoGZ2a6sLAAAAAAAAAZfp4/sKaX0WErpopTShSmlxzqYZKukT6SUflPScZLONbNjJH1K0p0ppaMl3Vl+qww7XdKbJI2XNMXMRpd5TZV0tqSjy2d8p+kGAAAAAADA0NJxQGpnpZSWpJR+VrrXSPqFpCMlnSzp6jLa1ZJOKd0nS7oxpbQppfSMpKckvdXMXivpoJTSvSmlJOmaMA0AAAAAAACGma4FpCIzO0r5X/l+IunwlNISKQetJL26jHakpIVhskWl35Glu94fAAAAAAAAw1DXA1Jm9nJJsyR9PKW0eqBR2/RLA/Rvt6yzzWyBmS3o6enZ+cQCAAAAAACg67oakDKzfZSDUdenlG4pvZeVx/BUvpeX/oskvS5MPlbS4tJ/bJv+20kpXZpSOjaldOxhhx2251YEAAAAAAAAe0zXAlLln/CukPSLlNLXwqB5ks4q3WdJmhv6n25m+5nZ65VfXn5feaxvjZkdV+Z5ZpgGAAAAAAAAw8yYLs77bZLeL+lhM3uw9Ps7SedLmmFmH5T0nKTTJCml9KiZzZD0mPI/9J2bUuot050jabqkAyTdXj4AAAAAAAAYhroWkEop3aP273+SpHf2M815ks5r03+BpDfvudQBAAAAAABgsDTyL3sAAAAAAACAIyAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADSKgBQAAAAAAAAaRUAKAAAAAAAAjSIgBQAAAAAAgEYRkAIAAAAAAECjCEgBAAAAAACgUQSkAAAAAAAA0CgCUgAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGkVACgAAAAAAAI0iIAUAAAAAAIBGEZACAAAAAABAowhIAQAAAAAAoFEEpAAAAAAAANAoAlI1PdOuHOwkAAAAAAAAjGgEpAAAAAAAANAoAlIAAAAAAABoFAGpNnqmXcmjewAAAAAAAF1CQAoAAAAAAACNIiAFAAAAAACARhGQAgAAAAAAQKMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADSKgBQAAAAAAAAaRUAKAAAAAAAAjSIgBQAAAAAAgEYRkAIAAAAAAECjCEgBAAAAAACgUQSkAAAAAAAA0CgCUgAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGkVACgAAAAAAAI0iIAUAAAAAAIBGEZAaQM+0KwY7CQAAAAAAACMOASkAAAAAAAA0ioAUAAAAAAAAGkVAqgM90y4f7CQAAAAAAACMGASkAAAAAAAA0CgCUgAAAAAAAGgUASkAAAAAAAA0qmsBKTO70syWm9kjod+rzOwOM3uyfB8Shn3azJ4ys1+a2bjQ/y1m9nAZdoGZWbfSDAAAAAAAgO7rZgup6ZLG1/p9StKdKaWjJd1ZfsvMjpF0uqQ3lWmmmNnoMs1USWdLOrp86vMEAAAAAADAMNK1gFRK6W5JK2q9T5Z0dem+WtIpof+NKaVNKaVnJD0l6a1m9lpJB6WU7k0pJUnXhGkAAAAAAAAwDDX9DqnDU0pLJKl8v7r0P1LSwjDeotLvyNJd7w8AAAAAAIBhaqi81Lzde6HSAP3bz8TsbDNbYGYLenp69ljiAAAAAAAAsOeMaXh5y8zstSmlJeVxvOWl/yJJrwvjjZW0uPQf26Z/WymlSyVdKknHHnts6pl63Z5MOwAAAAAAAPaApltIzZN0Vuk+S9Lc0P90M9vPzF6v/PLy+8pjfWvM7Ljy73pnhmkGRc+0ywZz8QAAAAAAAMNe11pImdk3Jf2RpEPNbJGkf5R0vqQZZvZBSc9JOk2SUkqPmtkMSY9J2irp3JRSb5nVOcr/2HeApNvLBwAAAAAAAMNU1wJSKaX39TPonf2Mf56k89r0XyDpzXswaQAAAAAAABhEQ+Wl5gAAAAAAANhLEJDqEO+OAgAAAAAA2DMISAEAAAAAAKBRBKQAAAAAAADQKAJSAAAAAAAAaBQBKQAAAAAAADSKgNRu6Jl2yWAnAQAAAAAAYNghILULeqZdOthJAAAAAAAAGLYISAEAAAAAAKBRBKS6oGfalMFOAgAAAAAAwJBFQAoAAAAAAACNIiAFAAAAAACARo0Z7ASMJDyqBwAAAAAAsGO0kNpDeqZNHewkAAAAAAAADAu0kNpNPdOmDXYSAAAAAAAAhhVaSAEAAAAAAKBRBKS6qGfaxVo+7aLBTgYAAAAAAMCQQkCqIcunXTjYSQAAAAAAABgSCEgBAAAAAACgUQSkAAAAAAAA0CgCUgAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGkVAqkHLp12g5dMuGOxkAAAAAAAADCoCUgAAAAAAAGgUAalhaunUL5Tvfx7klAAAAAAAAOycMYOdgL3R8mnf0Kv/8mO7NO3Sqeft4dQAAAAAAAA0ixZSI8DSqf802EkAAAAAAADoGAGpIWjZ1C8PdhIAAAAAAAC6hoDUIFk+7etaPu3rLf2WTf3KgNMsm/rFbiYJAAAAAACgEbxDaohbNvVLkvo6GnfplM/pNR/6XFfTAwAAAAAAsLtoIQUMou9dPrHl93cvn6jv1voBAAAAADDSEJAaopZN/dddmm7plH/YwynpzHMXvGdb968uOGXAcf/zwpO7nRwAAAAAADCEEZAaZMunfU3Lp31Vy6d9dY/Od8mUz+7R+XXiuQtO1XMXnNp22NMXDhykGml+cNlE/eCy1pZO379s11o+fefyCXsiSQAAAAAADBkEpPZSi6f8zW7PY+GFZ+xwnGdCa6n/7DAo9fjF3WtB9bNpJ+r+8unEjy85IX8uPUH3ls+uuHuAYNT3Lp+43aN7d5bf3wn977h8gu4gOAUAAAAAGAEISI1gS6Z8RkumfKajcRdf/LFt3c9ffK6ev/jc3Vr2sxecomcHeHTvqYtO1lMX7V7g6eEpJ+nhKSftcLwHpp2on5VPf356SR523yXVOD+5pH3w6Uc7CEr94LKBh/fXUmpn3x317Ssm6NtXEKACAAAAAAw/BKTQ4vmLP9K2/6KL/rx8f0ALLzxrW//nLnyfnrvwfbu8vCcvOllPlE+0M62kHpraPij14A5aQS3oZ3gMSg1kR4Epqf+WUXft4uN7AAAAAACMBGMGOwHoviVT/k6v/dAXd3q65y86R0l9XUhRe7+8+GS98dy52/V/bMpJOuZD8/RoaA2V+pnHz6eepN85Z95OLXdBhwGogfzw0hOqNNluzw4AAAAAgBGNgNReYsmUT0mSkvp0xIfyP/gtvvgTOuLcPfsy9T3tFxefvEsBngenntRIYOiHl56gt509v/sLqomP6v1H6B73wdsaTwsAAAAAADuLR/agxRf/1WAnYY/o79E9AAAAAAAwtBCQAgAAAAAAQKMISAEjyL+Hx/du5x/4AAAAAABDFAEpYASKwajbrpig28rvW684frCSBAAAAADANrzUHNjL3HplDkrFfypMkk78wO2Dkh4AAAAAwN6HFlIAWsy7klZUAAAAAIDuIiAFoK25Vx6/7dOJWVeN39Y986rxmhl+RzP66V93w/RxumH6uI7GBQAAAAAMLwSkAGzzrQGCT3OuPF5zrjxes8s4s0Ng6ZZaMMrdHLr7C0Td2Cbo1C4QdX3od21t+DXTx+kaglcAAAAAMGwQkAKwQ3P6CVTd0kFrp5uvGt8SmIpu6mD66/sJNNWDUnXTr37Xtu+rSrckXXn1u3Rl+A0AAAAAaB4BKQCNaxeI+ub0cds+/bmuzbDYMurq6e/S9PJppx6Y2lOmXrdzrbMuuJ7WXAAAAAD2bgSkAOy1rrjmXbrimnfp8mt2LkA07dpxmnZtZ9NcdN04XbSTAas94fwbCXoBAAAAGLqGTUDKzMab2S/N7Ckz+9RgpwfAyHP5NeN0WQhOXVqCTpeG4NMl/QSivJXUlOvG6eLSfXEIRF10/ThdWD4utpT6xg2dB5C+8s3Wcf/1m+P0r98cpy/tRhDqn2aM0z/NGLwg1jm3tLaa+/PZ4/Xns3O/P509Xn9aus+YM15nzKnGfe+c1ulOmjteJ83t7MX5AAAAAAbPsAhImdloSRdLOl7SMZLeZ2bHDDTN1p4VTSQNwAh1Wa3V1CXXjtsuGNVpK6mBfCMEpf6tBKW+fsO4bZ+v3TBOX/1m9XFfLt1frgWnzr9x3LbWUf9y4zj9SwhSnXfTOH3hpur3528ap8/f1Dr950pQ6h9njNc/zMiBnc/OGK+/vzl3f+bm8fq78vn0zeP1qZn54z45c7z+Ovz+37M6Dw795S3bj/uB2VW/M0Pw6U/mdD7f4+edVHXPnVy+39vx9NvNb+6HdnlaAAAAANmwCEhJequkp1JKT6eUNku6UdLJg5wmABgWvtim5VQMTP3zTbsfWPvbmdsHiD4R+v3VrPH6WPl8dNZ4ffiW/Dm3TRDq7Nk718JpcmkR9e7QMmrivPEaP2+Cxs+bsK3f8fPe3TLd8XPfV77P0PFzz9Txc89sO//j556t4+f+xfb953y49vvj5fNXkqQJcz6xU+sxYc5nyvff79R026af/fldmm53TLzl640vc9uyZ12iibMuGbTlAwAAYPeMGewEdOhISQvD70WS/vsgpQUAMEIdP/dPVd2rGaXbT768NvwcSVb9nvORbePG/m7CnL/Wbad8RRPm/I0k022n/KsmzPnbMK7Vun26z+q2Uz6vCbP/oTbfatzb3v2PmjD7n0v3Z/N0s7+g297995ow+7zaNNU8bnv3pzVh9vllur/VhNlfKt2f1MTZX64mS63LvfXUT2jiLV+TJN166v9uCUZNvOXf2qTRp/uoJt5yQen+iCbecmE/6yTdeuq5mnjLlNL9odJtuvXUczTxlqnbpUnKgalbJ/1FCU6Zbp10tibOurR0//+aOOuy/tM26YOaOOsKmaT5kz6oE2ZdKUmaP+kDkqQTZl21bez5k/6s9Juu+ZP+VCfMmi7JNH/SWaX/NSHvqmXMn/x+nTDzWs2f/P483szr8vwmn6ETZl6n+ZPP2DbZCTNvqJY3+U90wswbNH/yn5Rh39T8ye9T3Qkzb9y2XvMnv7f0u6ks+z06YeaMMuw9ZdjN29I4/7TTSr+Zmj85tx48ceYsfWvyJJ04c9a2+X5r8qnblnfizNn61uTW4O6JM+dIMn1rcr5XeNLMedulUzLNm3xiS5+TZs7XvMknlO5bw5imuZNzMPnkmbdr7uTjt33nfv+uuZPbB65PnvltSdLcyfmPK06ZeYfmTP5/txvvlJl3as7kd7adh3v3rLs0e9If6d2zvr+t3+xJ/ysM/4FmT3r7gPNo59RZP9Ytk47raNxJsxZo1qRjd3oZknTarIclSTdP+q3y+xFJppsnvWm7cd8z6/HSZZox6Y0tw957y1O66dTf2KU0YPDcdtMLkqQJ7z10kFMCAP2zlNKOxxpkZnaapHEppT8vv98v6a0ppY/Uxjtb0tnl55slPSLpUEkvlG910L0z4w6X6YZy2sgL1mm4pY11Gh5pIy9Yp+GWNtZpeKSNvGCdhlvaWKfhkTbygnUabmk7MKV0mHbTcHlkb5Gk14XfYyUtro+UUro0pXRsSulYSY+U7xf8u5PunRl3uEw3lNNGXrBOwy1trNPwSBt5wToNt7SxTsMjbeQF6zTc0sY6DY+0kRes0zBM224Ho6ThE5D6qaSjzez1ZravpNMltWsPDgAAAAAAgCFuWLxDKqW01cw+LOk/JI2WdGVK6dFBThYAAAAAAAB2wbAISElSSuk2SbftxCSX9vPdSffOjDtcphvKaWt6uqGctl2dbiinbVenG8pp29XphnLadnW6oZy2pqcbymnb1emGctp2dbqhnLZdnW4op21XpxvKaWt6uqGctl2dbiinbVenG8pp29XphnLadnW6oZy2pqcbymnb1emGctp2dbqhnLbdNixeag4AAAAAAICRY7i8QwoAAAAAAAAjxLB5ZK9TZra/pLsl7ae8fm+UtF7SEklvKKONrk22UdK+2j5AlyT1lf7WZpjVfquf8dr171RcjqelXX8Lv3vL8K3K+WDK67j/biy7vr47Uk9TEzyNKXSb+k97fdvs7rYCAABop79zkXhuF7t7VZ2v7uw5GBBRfgB00wblWMMrVMUANki6RtJH0w4eyRuJLaQ2SXpHSul3JF2lnCGPSfqxpL+U9B5JPWXcv5e0VtI+ku6QtFDSOkkrJD0vabWkW5Qztlc5o5+WdISkR0r//1AOeCVJ95Tu5cp/i7hW0sySpj5JLypvnOck3VvmuVLSD5SDR7MlbZG0StK7JC0tw1eW+W+UNKWM01Om6S3fS8r3Vkl3lXmsURWcWVzW+TtlPknS9SW9fZKml+7ny3LXlH59ZbozyzJ+XPJzS1nHB8v6LS/59aykv5L0S0mbVRXQ/5R0eFn+6pL+3jL/r5buxSXvN0i6pEyfSr6pjPvT0P1Q6X6h/O6T9MmSB1bSpTKPL4T8ean087zuK/PYXNJxd/mW8jb07f+iqiDlk6qCfn1lHdeGtD2rKsClkOcvlXmtKv23qAogbizdm8vwrWGcVPo9VPp7WlV+exnsU975N4ThW8o4a8vHx91cxt8a5rlJ0qKQP55/q8t0vn4+b6k1n309+8Jw386blct+Ui5fKunZUPr1Svp2mL8vNynvb6tCmnxb+D7Qq1w+fV1TGO955TLr6+dpW1db9vdCOlP4rAvL8fXxYQrT+Haqr/uLYfyYb2vVmpblYf22hnXZUoZLef/w5cZ1eTh0p/Dteba6lm4vq71lPlvDeFLejn2SPlyGe3nYWIZvCMu7R1Werw7D15f+S8N0vSGfNpXft6kqD1KV/0vUmp++Xltr331hngrjrpH0k7DO95Rhq8M63RC64zwvULVvLwjzXFW+14d1WZ163PUAAB0hSURBVBmmn1f6fVJV2dqiat9Zq2o7zA3ruqIM9zrAt0dcd19G3K+9Xo/549umrzbdlvB7XfneoNZ1931kZW06n/8LpfsBVWXSp+1TVX/7Puzz923dW/LAy5yXi5VlOU8r76uxfvZ18u30XVVl3/OnT/nYsqHkyerQv0dVHb21DPN6R5KeUlU3xzz2shDLYNxXFMb1sv9sSKcfW3slPV7GnRrSozDul0MerVO1jS9VVW+sLOuwOgx/scz7CeVjo2/z75Thsd6+UtWx0tcrhX5ra+vl5cWXtVmtdavPN56LSFVZ8LT4Otb3MT838LRsaNPtaYp1bTxmxWVIVRnz45svO9YZvcrl7IWQLp8+Hnv8WO3L8OHPlvE3q/XY59vbP76dfNkra+vvy253o9HXo91N0tWq6gmf3reTHx+eVy5Hvq193IVh3t5Pyvuzp2djbf6e5heUy1k8r3w2zN+309KQF65PrfVC/RgZy8fm0O3DpdZzpfpHqspMHPfxWh64jWG6e0O3f3veef0e9xk/VvmxM9ary8LvJ1SVbz+HkHK97/tRbxju5eVpVXWrH6sk6fPafp/cEObrxxBPZ1/t9yPh99qyHuuVz2V9v491z7+pOkf0a6YHVB0DvT6V8nldPF+V8vnM4pL+J8q8fBm+HtPC+J7eb2v7Y7t3+/Z5uLYs7/bjy+awvFg2HwvT+DnQ4rJ+W1TVwSrT+zlIr3L571XOt2VqPY6uLvPx83cvI368eFDSr9R6rHA+TVLruWes36Sc78vD8JWqzv1/FdLp0/5UuXxslnR/SK+fgyws6XhB1bnGJlXbNx4rfB/w+szPFXw94rEh7r/x/ML3xTVqLZu+rXtU1an/Hsb5Ufm+UtU+7mmtzy/u658JaYjnA55P/z2Mf1/5TqrKerzOiedinl4pXyspjCPl/SKeM8U0ef/FqrZvPB6s0PblMNaFMd/i9ZvPd30Yf1Nt/DhdnN/m2nibtP11nM/f/0zOYwG+zScon3OsVY6J3KZcvk4q/d8uaXybtLQYcQGplK01s7GSJipn6GhJfyjpCuULlP2VN/aNZTJTrjA3KBewlyln9CpJb1PeYKZysp1SWqK8QUaVeYxSLvD/RTm49Erliu95Sb+mKkp4oPJB4fmShtHKJz2/qVyQ/u+yrJcpF4oNypHGxWUeqyUdV9L2CuUWYF5gVpT+Y5QLwH4lHRvKtL+m1p3KlC+69ivL/J9lHq9SdYL2LlU7y5llPV9T1n0f5UL7mjLPQ5QrnLHKFcehyq3OnirL+GRKaXkZb2kZ7pXqAyVtv1Z+/0rS0WV56yW9XFVFGA8yv16W/XJVJ3V+AePbS8o7yShVgaeDy/TrVV0IHaxcEa2S9LoyXSppX1emX1vm6+ubSn6nMtxPOE3btw7zA+IBZfoxJQ2m1otDr4ReULV/egX/gqqKU6pO+jarukBOytu9JyzfKziviMeUfqPUeoLjFxh+0RlPeL2c+LrGAEKs+PxkOtYtni9J1bb0aTYqH9x9+gWqWrUp5Nf5yuXJ96WXq3V7vFTW209KvP+SsvwjlMvPvmF995P0izLuKEn/XL695ajnn1fysbWdV8T1i516a7tRyiftXh78BFXK+7+Pv6/yfu/LXq1qO6mk1efny99X1QH2tWp/9/N5tR7QPJDpgU0/oK8v6fF9xoMoT6g66K5UdcGzTNU2fFzVfvdcyItHVG0L7+fBtS2qDoR9aj2wex79uDat1HoyFy9s4sWG58lKVfXFBkkHafuTskPUenLoJ9q/W77XK7ey9f3DA21ezp9Urot9O+1b8uZB5e1nJR/2VdVi1cvM/1JVhg4s068p0/i+GNcnXszFC0fVxt23dI9SVV6l1vK2f+nerzbcv314UmuLYp/3WLW2sPY8Wax8bDBV+6KnOQaLvb72fPP9eovyxYapNUC0QdXJqF9AjVLrdr+rpHWUcr2RQhq8nvR6YUwt/Z5eL0+PhvXeqiovN4RleNrWhnmMLuvv6fN9zE/MD1frPjGmjHOsqrIQ691jVAX6DlSumw8My35R1cnjG8syN0j6H2W4n2tI+bj6yrBsL8OvCMsbE7pV6/Z0+/ReJx2o1rI1KoxnqurtOFylf9wGXrY8Xb6MmF9ryvR+PPNu3x4xuLwppMsv8E15e71SVf3iF3VSFUiSqn29HiyapbyNfX5uVRjP90Mvb1Kuj3yf8mPF+jAPT7end3Rtet/v9w/TxMCmKZ9beZ6vrqW9T1VdFevV+jHM98tRof8W5br9MOXjlOfbq8PyfbtvUN6u9euLWEaiuA/7Nm03Xpw+Hotjnea8XB0Shseg435h3KPaLM+PvaPL+F4m482/GJx1S1XVU36zU2UaP3/6uaoyHYMfvpxFqo4Tfm6YlM9LfZ19vqPVGohzq7V9WdsnDI83w0aV+XhgxMuZn6NLeX+RpC+qyueVqur3l4XpfF/0G4T7KAdSfP9+sSwvSZqkqp718vJ9VdtjlVrrYed1YCxjfp5+YFmmn+tJ1THpkFo+SLn+9HLi4/nyPA+2lmFby/p7Hng58zrF6+pYvkYpB4QOLevi+6ovY3SZz1pV53SbVR0bfNzNytdIfhzyNLwk6ciwPFOu648pab5R0m8rl8EVqs6pD1I+j16v6lxlqXId4XWQ52/cv1eU7o1l+pgP3h2vBzz9fn6+r1oDiX7zc6Xy9n5J+Tp9U5iHJL1e1bFWqm6i9IVxfH9aKekvVJXD0WU5ppyPi5SDKCrj/G4Y18t6vB7zdNSD54eH4Z5XY9RaZnvDcE9nDNTVg0ajS/p9Hj7NRlXXsV6f+ycGpOo3huo6aSXpdW2sb6XccEfK+5gfI9ZKOkX5uv9g5QD/AeVzp/L2/n4ZZ2AppRH3UbVB16u6E7BOOdL6gKqLqhWqWmBMV27V80jJ6GdVtQiIB+2tkn4o6WthHn6RtFb5oO0tmLaoit564YgVfgrda9VayPq7ExTn4dOukDQjDL9f2x9cYjS1r8084wG23kIkjhfvrNVPoGNLnvqwTaou6OJB9rPKlY9XSg8pH7z8wnlFmL6e7jj/rW2GtUt77LdC1cl8f3cpYv6srPWrXyjG9d6o9un08WN67w75tl6tF27xzoPfPd8c5rNZ1YWzb5uv19IWv+ufGJDy5azvZ9zV2n79452K2CKik2W3G9ZfuW9XJmMe97f9ff6b1Hqnfq2qVm2e9uvD8E39zK+/dA+0nstrw2J3XN8dleGBlhXzIm4D375xn+tR1Wpro6q7eDEtfhH/kLavH/yusJeZR9RaR9bXJW67dvthf+Vtk7Zf3y2qAhXt6pn+ynd/n3U7GN5fHu+obC+spdmn93zeqhy4ivv2QGkfaB/qdJ3iMjbsxPz21KdeX3a6vfrbX5r4xHK8M9ug23k40LYdSundlXTH8ev1sPdvV369xYDf6GjXosbrtdXaft/z6fw4uiRMt0jbr0ec90Z1nt+x3oppiPXF1jbL668stsvDndlP6vX+jrbX6to4HnD139/vYLv7p79zzR1NXz//arIsD5S3naSlv3OBbqdxMOuDuOwdHZOHyqe+j9UDAf2NuzPnce3m0cQxrr8y2O4cZ2fn198yPJjbq+3z1lsPbVJ+muY5bd9a7MUBlh0/A23DOD+/XonTvaSBr5EH+1M/5tT7xW6/wbaz2y6uf7th3r0yjLNV0jPlt7ey85b2NyjffJ2/o9jNiGshVRyvnAlHKGfSE8oR68Mk/aNyBHSd8t3cl5VpemvzOFg5Kvj7yoELj8auUM7kjys3ifTIsEesP1X67at8J8RbT80r4yXlR4OeKfP0gNXoMt7q8vsy5Y38M0lXh2V8V1Xk9O7y/UrlCL9HQ8eW7y+qChYsUfU4w6LS74Gw7muUKwKfb6+k9ylXAn3KF0/eksTvBPr6eDnyljAxL58s332le9/y8bs6n5T0ZlV3Cv+rcusCj2T7uu+jfHe43jRVJZ/8xPXfy/dm5RMjKW83v2PkaZGqVk6+Dt49Rq3NGut3dn29B4o0x7szSa13sXpr3950NIVxTPnu9hjlVjxSLrN+Zz8pb5t9yu8lqu6c+V3wp1VV/n4R7IHP2KzWmzcvVXVHa12Zf0xrvAtyq6oI+gOhOz6a5Ovud6f9IiI2Q/c0eaXmBy0PtHka491E53ehUm14XLdU5rdP+STlgMyBZZpYZk9UtS94PvnBsv7YSSyDHuzy9YmPK2xRrndiWemvO5avWP42he5U+1ZZlt993KzqzpkflJKqem6Z8p26A1XdkZOqcrJKVaubTZLepNYLJalqIdKnvG3fWPr9TFV++R20jarumMV9cKlyXvnNAt8ufsDzO2m+fjGfDi7jxO3v235jmOalMJ1fUPpBNTbpT2p95MC3nQ9zfte6np7eMK4/6jFWVZ56/vndV3+U+eCST4+rNeDuzdZ9f/OWPVLro5JLynfMM6m6W11Pf0xzvIMb7zzH8eu/4zJiPkvVfhRbGS1U6yOx/ojsupKWZcrrnlQ9muV3YKVcf/m+/byqdfebFGtUBUc9eOo3FuJjY/64n7ci7lVuwewtsuKjJL6+3gLUQr/4mPQVtXE9iOB1T2zyvln5Zlefqkf9/fFYn0es/72FqtSaz17ufB9TyLdRqm46xcd4/DGILaqCy+vDOL5N/W5wTIcvJwaMYxA11kvxjndfmF5tuqN2+1qsZ+uth3w+Y0I/D/QepCof/HjkLZd92/r2ifuIP6IRW1JJ1d3/jcp3wj1v/JG1+r7tdcvaMGyRqostX17c97zs1esTPxbcFfr7PGJA11tQ+Lr5enrLWN/eLua3twQbpe23g59LxDzuU2vrw41hXM/XXuUnBTw98aLIj/FxvvuEYfHxx+fUmo6YNql1v2x3fKx3S61lNA6Px4FYTr21b/2Gq9fVXs/4uPHxY6n1nG+ZqvojvoIjtuD0G5OxJddiVfWev65io6o6ws+npNbtHFtVxDrGl+036qXWGyZrVW2jR1Qd0+qPxPqyXczDeO7yRPn2OsNbqfgylpX5eSA4rrfUWifHm7MLQ3r8lR7+u67eAs/11UesjRuHe+sWL5OmfA3Xbr5xX46vKnAvhe5YJuN1hs9vRT/jxuXFVtLt1klthntLxnp64zloXN7aWv96nra7FrLaON7a0POyfrPBzxMPV27xtY/y9Z+XqUNUXcdI1Y143x4xT2Kd7suPrUX9GLGfWs8TD1Bry1Aply8fviT09zrAxWNHPJbF/vXHSP147b89nzfVvn1+cfvEpybidaxvY2/1Fpfry45M27e0j9suvhbCy/wm5XP4pPwapHtVxR3+UrlRTI/ydeJ+yk9/1evj7Q12a6YutZD6F+UTgWeVK93Nyhv6c8rBoBdL/6OUC1ifpC8pnzT6xYG3GlikqsLeqhy08ROSH5Xxl5dhzymfQHiF6s9YvqTqILxW1bO0LykHmLxF0HPls6l8+/t+YsucHbXc6PSzUjk490JI+1dKupaqepeW383zR3j8hMiDQOtCP3/O2A8i8QTXL8L8QPQLVRco9yhffHiA7hOqWqfFFjw+/01lu/ljN37A9BMyvziIAYObQ1q+oFwGtiqXCQ/ELFduYrhG7U8647o8G/LS82LhANspnkj2qXoPxRblQF1fSZOf7MQWPfEdPt4MfGPZPt6KbGPo7xcmfuGWwvz849vdW8j4RbAHX/yiaU+UtfjZpKqFju8nnnY/MWkX2fdxfDxPs+dLLGv1O1Sx9Vef8ntcUll2PJFeGeZXT7OP4/Oot3jrb30Xh7zsVfXOtV7l8uvvLvOAd/2Cw08AY4u5eAd9vVrLZ72svhj6+/vrepUPFPG9Af7+ilW1eXnafbv4Rb8HAHwcr+Ni3s9VVZaeVPVs+ipVJ5JeHyzdQT7uysfz0Vuqfjek/Xsh7UvVmndx2vp2WaLt8ztO6xcdKUzbW5bt43w3LGepWreXl79492ugslafzrs9mPyiqtYgm1VdAPgj4fGdEV6efJlel3s58bo27lN9YdmxnG9V3p+89au3RvYAkAef/QZMn6r35nk9t06trUYfU1XGvAzFi9y5ZTv73TqvX+er9Ti8XlUAck+VOV8HD7avUVW3bVUub54vy0Pa/eN1QK+qd5V4K52+8Duus9d1vk36yry9jl+qKkC3MQxvV4a21pbjZTmW7a1h+bG8bVV+LMTrpdvUWob58GniE4+TSa3vrEqqznniY7RxeP0Y4MdOL8sedPqOqrIez4d9PhuV9/8N4bNF+Zw31l/x+NqnfDN1S/msUHWO80O11o/1c7NdrcPuCenx5T0Y8mWVqnfR+juT/Dji0y3RwK2H6udtd5e0PxjGv0mt51gr1FrHxG3aruVgzIsflW8/DnudHMtIPR8Gyj9fV79+6W89/TzK0+jDnlbrdc/ulvGYT6tDd7tx6+nrb5/xYWsHmFf8xGOOl1efTz1Y21sbr36jN6bBt73n+TPK5WujqsdDn1JVpn6m6vyhnkY/Z4hlz8vOOrWWqVhWY6Df0xbLV/0Jp3gj0W++1Y+ZL4X+a8J8n1HVCMWvCeLNHy+7vcrvw15V8sOfNvIbvknSN5WDQhuVX3viaW23/du1Su2vVZ+fj/k6+etVfDm9kv5OOabh15u/L+mjJb2PSjpL+b1Sl+x1LaTM7DBJX0opjZX0FuUWNQ8qt1Y6SfkuWnyG1d/d4dHGw5WjjCuUM/kPVO0kq5Tf1eIRz9cpH0S8EC1U9Szq02VZFykHH/wRoUeUD4ybyrKPUD7QjVbeaK9RjmxeVZb/K+UDYFI+QF6vqnC9W9U7JL6tqoI6X/mC849VvcTyMlXvgNlYlh3fnzNf+T1Rpnxi/7BypNN3oGvVehfQ74otK3mxWdWz2f+p6qWaz6qqqPxiWiXP/A6MKT+3LOWD0+8rVza3qjqp7i3z9+UcXJbhLba85dB1qiosb021Uq2R42+rau1wXNlO7ijl92nFi1HnlZWn3yskv+PjLRqScquhdi/3VRnfn1PuLcv0Yf6umYWqXiDnLdlWKd+1tbIsfz+Ypz+pivgvUhXlX6VcNvz9Jr6cPlX/LpnKsF5VwVBvvZdUtV7xNL8z5MsDqvLWX+rpJ399ar2bp7Icf/+Tv//L7/zfoeq9Xn7yI7W+x8bvZPu6JFXPMvuBJZ44eAsClW6/o+bvJ/H+3orQH7dVmT4u2+cZ78jE90vE1hkpjOfvDJur6s7F8rL+/s6ZPlVBGj+Yx2e4U8lL32c3q3rW21t/+Lr7gWT/MH2vqnd7/LqqO1Vry3xeUBVwiu8Z8TtJD0n6DVXvEPtvZdhjZR1WKtezUt4//F0OpnznaauqlmqblcvtaOUy4+WmV9XJb7yb5C9A9gvseODfovwnCPGE0ceNd7bGhnzztC9X9RJeP2mK8zZVdzStNk8f11+cLuWTjHhcPaDki++3W5RbEKj0f7Tkuy/DD/ax5Vr9jrR/r1Pru2+Whe6DS7efMPndSX+vzRrl7faZkFZvHenly8uv54MvU6ryzMu9142jwvSblN954e9H27ekw4PfC1WV5/XKxwB/l8lBqgI7ByiX7/9axv2Oqn3X6+Fe5fre32d0SEnnKOVjuFS9Q2yLqvcWSvkufixvknS5qnLm6ydVL2T/SBg/Pv7lrWpSWR/fjn5e8bSqus0vdOOd91HKJ93e3RO647HT72iuVXXuYqrerbJU+f0+Xq/sp+p9evGGjVRtX9/WXpePCvOVqgsGX1d/UXuSNE7Vtv/D0m9fVUG1h1VdmMcXzPqy1qhqTd1b0i/lbeov8fYbP/EiKikH/h5StQ39OOA31Z5Q9eL6+EJuv/v8gqrWMH6BLVV/SOOvfvDl/21I90uqbsq9pNaT96XKfzDidfLPtX05O19VPRJbHvg6n6Jqu8dt5/NZquq8b7PyeZOUz60WqnrB80Ztv+zvqqpLfhz6ex5761Vfz3hnfUMZ7vtObCX8K+Vzy3hRGC9CpdZju29Pt075Zqnvf/FPVnxd16jaBx4vefN5Vedi/g4eqfX9oabqvUt+HPaXUcfHNT3NCvPx9xK9SdV7l/zPEWIrncdU1fdrlY/BK5Tfi2rK1wz7qWoh7Bfb/u4Zn/c+JU/frOo46zdd/RwhSfpWWW4MjHk5ia2tnlQVZIvpGaXq3ZlHhXx5qqQhHlsUhm9Rrm9GqfUx8dgqy5+s8OuFN5T0vb4Mf175Ok2q6sB4Ph7fw+XDpaoceB3qx6HfLMPjMTi2pvQAhtT6Xjk/fj2j1nLuN2viuZCXjdVqfcl2fPeo58XD2v4deltUtaKL7yPz+fi0vWX6ePz3gJSpOv+NwR0vEz5vt7E2D6l6X6XKdPuH5cb5xn3V5+X56+/4iuf2/oRDfAeuv5PNW6a+qOpm3E/DOh1Q5rFauRwcqHy99sqSlu+o9V1kfozxbennh/4ElOf7w6rO4/2dwr7Pe724QdVx1seNf+6yKfT3fo+FfIrXwp6vfaqubfvU+vTC4WX94rsU43vw+kp+SNJvKdcpB6t6Akuqjv0/Vn5n2Gjl+klqvW6JrfJiGfGy1hOGx6Dk/WV9vBWZl41RJU1J0rnK+X2gqn38ncr5uEz5XV1jla99BmRp4H/hG3bM7LeVm/mNVvWY3hjlDN9fOaBUv8gcLmJF5RXiq8qwTaoKr+/cq5XXeR/lnfMItW9auTPLjtPH5pD1+caL8fi9VVXebyrpW6vWE3kf30+q/cDvj1l1qk8Dv7i/XboBAEB37Opxd0fH86HOT7ZXqXrs2IP0Hgyu8xtw9ZteO7vcdudqO9oO/Z3X+SPwfjFoar3gjtOtVb4I9QvA+nl3J2WB8zSMVPXro8Gyq3XLULGr+bdJrX8gEP8ga08tYySr55XfXImBvY3KDUU+nHYQcBpxASkAAAAAAAAMbcP5bhMAAAAAAACGIQJSAAAAAAAAaBQBKQAAAAAAADSKgBQAAAAAAAAaRUAKAAAAAAAAjSIgBQAAAAAAgEYRkAIAAGiQmX3czF42CMv9IzOb3/RyAQAA2iEgBQAA0KyPS+p6QMrMRnd7GQAAALuKgBQAAECNmZ1pZg+Z2c/N7Foz+y9mdmfpd6eZ/XoZb7qZTQ7TrS3ff2Rmd5nZTDN73Myut+yjko6Q9D0z+14/y36PmX2tdH/MzJ4u3W8ws3tK9zvN7AEze9jMrjSz/Ur/Z83sH8p4p5nZ+LL8eySd2r0cAwAA2DkEpAAAAAIze5Okz0h6R0rpdyR9TNJFkq5JKf22pOslXdDBrH5PuTXUMZL+L0lvSyldIGmxpD9OKf1xP9PdLentpfvtkl40syMl/YGkH5jZ/pKmS3pvSum3JI2RdE6YfmNK6Q8kzZF0maQTy3xe00GaAQAAGkFACgAAoNU7JM1MKb0gSSmlFZL+h6QbyvBrlYNDO3JfSmlRSqlP0oOSjupk4SmlpZJebmavkPS6stw/VA4q/UDSGyU9k1J6okxydRnubirf/62M92RKKUm6rpPlAwAANIGAFAAAQCuTlHYwjg/fqnI+ZWYmad8wzqbQ3avckqlT90r6M0m/VA5CvV05KPbDkr6BrGuTTgAAgCGFgBQAAECrOyW9x8x+TZLM7FWSfiTp9DL8/5N0T+l+VtJbSvfJkvbpYP5rJL1iB+PcLemvy/cDkv5Y0qaU0ipJj0s6ysx+o4z7fknfbzOPxyW93szeUH6/r4O0AQAANGJn7tQBAACMeCmlR83sPEnfN7Ne5YDQRyVdaWZ/I6lHufWSlN/RNNfM7lMOZK1rN8+aSyXdbmZLBniP1A+UH9e7O6XUa2YLlQNMSiltNLM/k3SzmY2R9FNJ09qsx0YzO1vSrWb2gnIQ7c2d5AEAAEC3WX6lAAAAAAAAANAMHtkDAAAAAABAo3hkDwAAYJCY2U8k7Vfr/f6U0sODkR4AAICm8MgeAAAAAAAAGsUjewAAAAAAAGgUASkAAAAAAAA0ioAUAAAAAAAAGkVACgAAAAAAAI0iIAUAAAAAAIBG/R8u7zv6TGV51wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "df_X[\"count_word\"] = df_X.text.apply(lambda x : len(x.split(' ')))\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=(20,5))\n",
    "\n",
    "sns.countplot(df_X[\"count_word\"],ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter des séquences trop longues, le seuil maximum d'une phrase sera considéré à 40:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_X = df_X[df_X.count_word<=40]\n",
    "\n",
    "#df_X[\"count_word\"] = df_X.text.apply(lambda x : len(x.split(' ')))\n",
    "#fig, ax = pyplot.subplots(figsize=(20,5))\n",
    "\n",
    "#sns.countplot(df_X[\"count_word\"],ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separer les données en train & text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60735</th>\n",
       "      <td>cart postal typo aim kiub cart postal tendanc ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>garcon jeu plateau avoir propo agit un jeu car...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55855</th>\n",
       "      <td>royaum anim ab asc nan</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42138</th>\n",
       "      <td>piscin jeu adress x</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>unit stat european union auditor indep regul nan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76233</th>\n",
       "      <td>piscin bou ballon gonflabl intex set complet p...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47141</th>\n",
       "      <td>pomp avoir chaleur pacfirst nov invert kw mono...</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42108</th>\n",
       "      <td>robocop play art kai figurin robocop cm avoir ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72085</th>\n",
       "      <td>urss avoir heur k nan</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12667</th>\n",
       "      <td>special edit bronz sensat barb doll sp...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  count_word\n",
       "60735  cart postal typo aim kiub cart postal tendanc ...          38\n",
       "9118   garcon jeu plateau avoir propo agit un jeu car...          61\n",
       "55855                            royaum anim ab asc nan            6\n",
       "42138                               piscin jeu adress x            5\n",
       "10948  unit stat european union auditor indep regul nan            9\n",
       "...                                                  ...         ...\n",
       "76233  piscin bou ballon gonflabl intex set complet p...          61\n",
       "47141  pomp avoir chaleur pacfirst nov invert kw mono...         178\n",
       "42108  robocop play art kai figurin robocop cm avoir ...          31\n",
       "72085                             urss avoir heur k nan            6\n",
       "12667          special edit bronz sensat barb doll sp...          21\n",
       "\n",
       "[33966 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importer la classe train_test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparer le jeu de données en données d'entraînement et données test \n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(df_X, df_y.prdtypecode,  train_size = 0.4, test_size=0.2,random_state=42)\n",
    "\n",
    "X_train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokeniser: texte -> sequence entier (index dans un dictionaire):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Définition du tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "# Mettre à jour le dictionnaire du tokenizer\n",
    "tokenizer.fit_on_texts(X_train_text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Transformer chaque review X_text_train en une séquence d'entiers à l'aide de la méthode texts_to_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train_text.text)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocker le dictionnaire de correspondance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des dictionnaires\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = tokenizer.index_word\n",
    "vocab_size = tokenizer.num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Transfomer la liste de sequence X_train en tableau numpy à l'aide de la fonction pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "X_train_txt = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
    "X_test_txt = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 121, 2575,  634, ...,    0,    0,    0],\n",
       "       [ 651,   32,  714, ...,    0,    0,    0],\n",
       "       [2643,  194,  413, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 876,  340, 5968, ...,    0,    0,    0],\n",
       "       [8793,   13,   35, ...,    0,    0,    0],\n",
       "       [ 291,  478, 3552, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperer les données images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_1263597046_product_3804725264.jpg\n",
      "C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_train\\image_1263597046_product_3804725264.jpg\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('X_train_update.csv',index_col=0)\n",
    "y = pd.read_csv('Y_train_CVw08PX.csv',index_col=0).squeeze().map(str)\n",
    "\n",
    "#Create a column with the name of the picture\n",
    "X['image_name'] = 'image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
    "X['image_path'] = path + r'\\image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
    "print(X['image_name'].loc[0])\n",
    "print(X['image_path'].loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatener X_train et les labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>image_1263597046_product_3804725264.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>image_1008141237_product_436067568.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>image_938777978_product_201115110.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>image_457047496_product_50418756.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>image_1077757786_product_278535884.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84911</th>\n",
       "      <td>The Sims [ Import Anglais ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206719094</td>\n",
       "      <td>941495734</td>\n",
       "      <td>image_941495734_product_206719094.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84912</th>\n",
       "      <td>Kit piscine acier NEVADA déco pierre Ø 3.50m x...</td>\n",
       "      <td>&lt;b&gt;Description complète :&lt;/b&gt;&lt;br /&gt;Kit piscine...</td>\n",
       "      <td>3065095706</td>\n",
       "      <td>1188462883</td>\n",
       "      <td>image_1188462883_product_3065095706.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84913</th>\n",
       "      <td>Journal Officiel De La Republique Francaise N°...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440707564</td>\n",
       "      <td>1009325617</td>\n",
       "      <td>image_1009325617_product_440707564.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84914</th>\n",
       "      <td>Table Basse Bois De Récupération Massif Base B...</td>\n",
       "      <td>&lt;p&gt;Cette table basse a un design unique et con...</td>\n",
       "      <td>3942400296</td>\n",
       "      <td>1267353403</td>\n",
       "      <td>image_1267353403_product_3942400296.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84915</th>\n",
       "      <td>Gomme De Collection 2 Gommes Pinguin Glace Ver...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57203227</td>\n",
       "      <td>684671297</td>\n",
       "      <td>image_684671297_product_57203227.jpg</td>\n",
       "      <td>C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84916 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             designation  \\\n",
       "0      Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1      Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2      Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3      Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                                   La Guerre Des Tuques   \n",
       "...                                                  ...   \n",
       "84911                        The Sims [ Import Anglais ]   \n",
       "84912  Kit piscine acier NEVADA déco pierre Ø 3.50m x...   \n",
       "84913  Journal Officiel De La Republique Francaise N°...   \n",
       "84914  Table Basse Bois De Récupération Massif Base B...   \n",
       "84915  Gomme De Collection 2 Gommes Pinguin Glace Ver...   \n",
       "\n",
       "                                             description   productid  \\\n",
       "0                                                    NaN  3804725264   \n",
       "1                                                    NaN   436067568   \n",
       "2      PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   \n",
       "3                                                    NaN    50418756   \n",
       "4      Luc a des id&eacute;es de grandeur. Il veut or...   278535884   \n",
       "...                                                  ...         ...   \n",
       "84911                                                NaN   206719094   \n",
       "84912  <b>Description complète :</b><br />Kit piscine...  3065095706   \n",
       "84913                                                NaN   440707564   \n",
       "84914  <p>Cette table basse a un design unique et con...  3942400296   \n",
       "84915                                                NaN    57203227   \n",
       "\n",
       "          imageid                               image_name  \\\n",
       "0      1263597046  image_1263597046_product_3804725264.jpg   \n",
       "1      1008141237   image_1008141237_product_436067568.jpg   \n",
       "2       938777978    image_938777978_product_201115110.jpg   \n",
       "3       457047496     image_457047496_product_50418756.jpg   \n",
       "4      1077757786   image_1077757786_product_278535884.jpg   \n",
       "...           ...                                      ...   \n",
       "84911   941495734    image_941495734_product_206719094.jpg   \n",
       "84912  1188462883  image_1188462883_product_3065095706.jpg   \n",
       "84913  1009325617   image_1009325617_product_440707564.jpg   \n",
       "84914  1267353403  image_1267353403_product_3942400296.jpg   \n",
       "84915   684671297     image_684671297_product_57203227.jpg   \n",
       "\n",
       "                                              image_path prdtypecode  \n",
       "0      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...          10  \n",
       "1      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2280  \n",
       "2      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...          50  \n",
       "3      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        1280  \n",
       "4      C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2705  \n",
       "...                                                  ...         ...  \n",
       "84911  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...          40  \n",
       "84912  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2583  \n",
       "84913  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2280  \n",
       "84914  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        1560  \n",
       "84915  C:\\Users\\Edgar\\Documents\\Rakuten\\images\\image_...        2522  \n",
       "\n",
       "[84916 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X,y],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois nous avons un dataset de la taille desirée on peut le séparer en train et test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, y_train, y_test = train_test_split(X[['image_name','prdtypecode']], X.prdtypecode, train_size = 0.4 ,test_size=0.2, random_state=42)\n",
    "#X_train_path, X_test_path, y_train, y_test = train_test_split(X.image_path, X.label, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60735</th>\n",
       "      <td>image_1208783386_product_2825941333.jpg</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>image_856119038_product_89102802.jpg</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55855</th>\n",
       "      <td>image_936925976_product_197015072.jpg</td>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42138</th>\n",
       "      <td>image_1166755995_product_2824252365.jpg</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>image_1017775450_product_418466190.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76233</th>\n",
       "      <td>image_1075701044_product_1351876762.jpg</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47141</th>\n",
       "      <td>image_1174586088_product_2940638611.jpg</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42108</th>\n",
       "      <td>image_984906419_product_290034883.jpg</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72085</th>\n",
       "      <td>image_901400003_product_62981761.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12667</th>\n",
       "      <td>image_1215506278_product_3470052832.jpg</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_name prdtypecode\n",
       "60735  image_1208783386_product_2825941333.jpg        1320\n",
       "9118      image_856119038_product_89102802.jpg        1281\n",
       "55855    image_936925976_product_197015072.jpg        2403\n",
       "42138  image_1166755995_product_2824252365.jpg        1302\n",
       "10948   image_1017775450_product_418466190.jpg          10\n",
       "...                                        ...         ...\n",
       "76233  image_1075701044_product_1351876762.jpg        2583\n",
       "47141  image_1174586088_product_2940638611.jpg        2583\n",
       "42108    image_984906419_product_290034883.jpg        1140\n",
       "72085     image_901400003_product_62981761.jpg          10\n",
       "12667  image_1215506278_product_3470052832.jpg        1280\n",
       "\n",
       "[33966 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33966 validated image filenames belonging to 27 classes.\n",
      "Found 16984 validated image filenames belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "#APPLY SOME TRANSFORMATIONS TO DATA\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "image_train_set = train_datagen.flow_from_dataframe(dataframe=X_train_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image_name\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                              class_mode =\"sparse\",\n",
    "                                              target_size = (224, 224),\n",
    "                                              batch_size = 32)\n",
    "\n",
    "image_test_set = test_datagen.flow_from_dataframe(dataframe=X_test_img,\n",
    "                                              directory=path,\n",
    "                                              x_col = \"image_name\",\n",
    "                                              y_col = \"prdtypecode\",\n",
    "                                              class_mode =\"sparse\",\n",
    "                                              target_size = (224, 224),\n",
    "                                              batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de notre jeu de données\n",
    "text_train_set = tf.data.Dataset.from_tensor_slices((X_train_txt, y_train.values))\n",
    "\n",
    "text_test_set = tf.data.Dataset.from_tensor_slices((X_test_txt, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la fonction load_image dans le pipeline des opérations. Séparer le résultat en lot de taille 32.\n",
    "text_train_set = text_train_set.map(lambda text, y: [text, y]).batch(32).repeat(-1)\n",
    "#dataset = dataset.map(lambda x, y: [load_image(x), y[:-1], y[1:]]).batch(16).repeat(-1)\n",
    "\n",
    "text_test_set = text_test_set.map(lambda text, y: [text, y]).batch(32).repeat(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition d'un générateur python\n",
    "def generator(image_set,text_set):\n",
    "    iter_text = iter(text_set)\n",
    "    iter_image = iter(image_set)\n",
    "    while True:\n",
    "        X_text, y_text = next(iter_text) #do not use this 'y_text' from text iterator!!! Tf does not recognise it and leads to bug during training\n",
    "        X_im, y = next(iter_image)\n",
    "        \n",
    "        #print('')\n",
    "        #print('X_im:',X_im.shape,'X_text:',X_text.shape,'y:',y.shape)\n",
    "        #print(y)\n",
    "        yield [X_im, X_text], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du générateur final.\n",
    "gen_train = generator(image_train_set,text_train_set)\n",
    "\n",
    "gen_test = generator(image_test_set,text_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELE POUR CLASSIFICATION DE TEXTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling2D, RNN, GRUCell, Dense,LSTM\n",
    "\n",
    "embedding_dim = 256\n",
    "voc_size_inp = len(tokenizer.word_counts)+1\n",
    "\n",
    "text_inputs = Input(shape=(None,), dtype='int32')\n",
    "embed = Embedding(voc_size_inp, embedding_dim)(text_inputs)\n",
    "gru = LSTM(512)(embed)\n",
    "#text_output = Dense(27, activation='softmax')(gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELE POUR CLASSIFICATION D'IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "base_model = VGG16(weights='imagenet',input_shape=(224, 224, 3),include_top=False)\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image')\n",
    "x = base_model(image_input)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "images = Dropout(0.2)(x)\n",
    "#x = Flatten()(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCATENATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Functional)              (None, 7, 7, 512)    14714688    image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           vgg16[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         525312      global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 256)    13705728    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 512)          1574912     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024)         0           dropout_7[0][0]                  \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          524800      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 27)           13851       dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,584,091\n",
      "Trainable params: 16,869,403\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/deep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "x = concatenate([images, gru], axis=-1)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(27, activation='softmax')(x)\n",
    "\n",
    "model = Model([image_input, text_inputs], output)\n",
    "\n",
    "unfreezed_layers = 0 #Nombre de couches a décongeler pour aplique le finetuning: Voir livre Deep Learning with python\n",
    "# Freezer les couches du VGG16\n",
    "for layer in base_model.layers[-unfreezed_layers:]: \n",
    "    layer.trainable = False\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         mode='min',\n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "filepath = cwd + '/out'\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath=filepath + '/concat_RNN_VGG16.hdf5', \n",
    "                                       monitor='val_loss',\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='min',\n",
    "                                       save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_im: (32, 224, 224, 3) X_text: (32, 500) y: (32,)\n",
      "[13.  4. 10. 25.  4.  1. 20. 10. 10. 18. 24. 11.  4. 18. 20. 11. 20. 10.\n",
      " 17.  0. 26. 18. 24.  0. 18.  0. 25.  9. 15. 15. 20. 11.]\n",
      "Epoch 1/10\n",
      "X_im: (32, 224, 224, 3) X_text: (32, 500) y: (32,)\n",
      "[ 5. 15. 23. 20. 13. 13. 16.  3. 22.  2. 10.  9.  1. 11. 22. 18.  6. 20.\n",
      "  9. 11.  9. 14. 17.  5. 16. 13. 19. 11. 20.  2. 20. 13.]\n",
      "   1/1061 [..............................] - ETA: 3:09:09 - loss: 3.2603 - accuracy: 0.0625X_im: (32, 224, 224, 3) X_text: (32, 500) y: (32,)\n",
      "[15.  8. 22. 20. 17. 20. 20. 10. 10. 25. 17. 13.  1. 16. 10.  6.  2. 21.\n",
      "  0.  6. 16.  0. 18.  7.  0. 16. 22. 20. 23. 11. 13. 24.]\n",
      "   2/1061 [..............................] - ETA: 2:28:55 - loss: 3.3050 - accuracy: 0.0938X_im: (32, 224, 224, 3) X_text: (32, 500) y: (32,)\n",
      "[ 5.  4. 21. 20. 13. 16. 15. 19. 25. 19. 10.  2. 16.  9. 10. 22.  6. 11.\n",
      " 11. 13. 20.  2. 24.  6. 10.  9. 20. 20. 20. 20. 20.  9.]\n",
      "   3/1061 [..............................] - ETA: 2:28:17 - loss: 3.2978 - accuracy: 0.0833X_im: (32, 224, 224, 3) X_text: (32, 500) y: (32,)\n",
      "[ 2.  4. 20. 24.  0. 13. 20. 16.  0. 23.  2.  6. 25. 11. 20. 18. 20. 21.\n",
      " 13. 13.  4. 18. 13. 16. 25.  2.  4.  9. 21.  6. 18. 16.]\n",
      "   4/1061 [..............................] - ETA: 2:28:42 - loss: 3.2566 - accuracy: 0.1016X_im: (32, 224, 224, 3) X_text: (32, 500) y: (32,)\n",
      "[ 0.  4. 24. 22.  8.  4. 16. 10. 18. 11. 13. 18. 23. 25. 10.  2.  5. 19.\n",
      "  1.  6.  9. 15.  3. 20.  4. 20. 19. 21.  2. 16.  0. 18.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-8248bf9f0c62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model.fit_generator(gen, steps_per_epoch=int(len(y_train.values)/16), validation_data = gentest, validation_steps = int(len(y_test.values)/16),epochs=10, workers=-1,callbacks=[early_stopping, checkpoint])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit_generator(gen, steps_per_epoch=int(len(y_train.values)/16), validation_data = gentest, validation_steps = int(len(y_test.values)/16),epochs=10, workers=-1,callbacks=[early_stopping, checkpoint])\n",
    "model.fit(gen_train, steps_per_epoch=int(len(y_train.values)/32), validation_data = gen_test, validation_steps = int(len(y_test.values)/32),epochs=10, workers=1)\n",
    "\n",
    "\n",
    "#https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/\n",
    "#So, we have learned the difference between Keras.fit and Keras.fit_generator functions used to train a deep learning neural network\n",
    "#.fit is used when the entire training dataset can fit into the memory and no data augmentation is applied.\n",
    "#.fit_generator is used when either we have a huge dataset to fit into our memory or when data augmentation needs to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokeniser: texte -> sequence entier (index dans un dictionaire):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Définition du tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "# Mettre à jour le dictionnaire du tokenizer\n",
    "tokenizer.fit_on_texts(X_train_text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Transformer chaque review X_text_train en une séquence d'entiers à l'aide de la méthode texts_to_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train_text.text)\n",
    "X_test = tokenizer.texts_to_sequences(X_test_text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocker le dictionnaire de correspondance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des dictionnaires\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = tokenizer.index_word\n",
    "vocab_size = tokenizer.num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Transfomer la liste de sequence X_train en tableau numpy à l'aide de la fonction pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
