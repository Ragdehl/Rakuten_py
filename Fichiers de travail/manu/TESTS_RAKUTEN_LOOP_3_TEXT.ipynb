{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TESTS RAKUTEN LOOP 3 TEXT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1pHuQaGw_mnLn4bdH_QMTdxNrjAcRBXF3",
      "authorship_tag": "ABX9TyOdzqUC219jZv0D4omiMqF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ragdehl/Rakuten_py/blob/main/manu/TESTS_RAKUTEN_LOOP_3_TEXT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKGkrEUY-8Jr"
      },
      "source": [
        "# LOOP 3 - TEST SIMPLE RNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M3QiPYh-2N0"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rce9msZ3-2ej"
      },
      "source": [
        "X = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/TRAINING DATASCIENTEST/PROJET DATASCIENTEST/Archivage datas projets RAKUTEN/X_train_update.csv',index_col =0)\n",
        "y = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/TRAINING DATASCIENTEST/PROJET DATASCIENTEST/Archivage datas projets RAKUTEN/Y_train_CVw08PX.csv',index_col=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLA0uM94-2pL"
      },
      "source": [
        "y['label'] = y['prdtypecode'].replace(y.prdtypecode.unique(), [*range(len(y.prdtypecode.unique()))]) ## permet de simplifier les N°  de classes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "g6x2QUwjBK0b",
        "outputId": "83a52d1c-e130-43d7-b2e2-c9e56b351fef"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>designation</th>\n",
              "      <th>description</th>\n",
              "      <th>productid</th>\n",
              "      <th>imageid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3804725264</td>\n",
              "      <td>1263597046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>436067568</td>\n",
              "      <td>1008141237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
              "      <td>201115110</td>\n",
              "      <td>938777978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50418756</td>\n",
              "      <td>457047496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La Guerre Des Tuques</td>\n",
              "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
              "      <td>278535884</td>\n",
              "      <td>1077757786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         designation  ...     imageid\n",
              "0  Olivia: Personalisiertes Notizbuch / 150 Seite...  ...  1263597046\n",
              "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...  ...  1008141237\n",
              "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...  ...   938777978\n",
              "3  Peluche Donald - Europe - Disneyland 2000 (Mar...  ...   457047496\n",
              "4                               La Guerre Des Tuques  ...  1077757786\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLKhCIEaCPjP"
      },
      "source": [
        "# réalisation de la jointure des 2 colonnes texte du dataframe\n",
        "headlines = []  #####\n",
        "for row in range(0,len(X.index)):\n",
        "    headlines.append(' '.join(str(x) for x in X.iloc[row,0:2]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLQ3hQ2FDscA"
      },
      "source": [
        "df = pd.DataFrame({'Features': headlines})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoh_FFzLEKby"
      },
      "source": [
        "# ajout colonne label\n",
        "df['label']=y['label']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNOEb6M2BEgm"
      },
      "source": [
        "# ajout colonne count_word\n",
        "df[\"count_word\"] = df['Features'].apply(lambda x : len(x.split(' ')))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "Q6XgMKjXEPL-",
        "outputId": "6c1301ea-c449-4d31-b4d8-2772b869685f"
      },
      "source": [
        "df.head(15)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>label</th>\n",
              "      <th>count_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Christof E: Bildungsprozessen Auf Der Spur nan</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Puzzle Scooby-Doo Avec Poster 2x35 Pieces nan</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...</td>\n",
              "      <td>6</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Eames Inspired Sxw Chair - Pink - Black The ti...</td>\n",
              "      <td>7</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Fauteuil Chesterfield Brenton 100% Cuir De Buf...</td>\n",
              "      <td>7</td>\n",
              "      <td>665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Peaceable Kingdom Wheres Bear? The Hide And Fi...</td>\n",
              "      <td>8</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Paire De Voilages Imprimés Fantaisie Paire de ...</td>\n",
              "      <td>9</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Matelas Mémoire De Forme 180x200 X 20 Cm Très ...</td>\n",
              "      <td>7</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Features  label  count_word\n",
              "0   Olivia: Personalisiertes Notizbuch / 150 Seite...      0          15\n",
              "1   Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...      1          40\n",
              "2   Grand Stylet Ergonomique Bleu Gamepad Nintendo...      2         121\n",
              "3   Peluche Donald - Europe - Disneyland 2000 (Mar...      3          11\n",
              "4   La Guerre Des Tuques Luc a des id&eacute;es de...      4          38\n",
              "5   Afrique Contemporaine N° 212 Hiver 2004 - Doss...      1          12\n",
              "6      Christof E: Bildungsprozessen Auf Der Spur nan      0           7\n",
              "7   Conquérant Sept Cahier Couverture Polypro 240 ...      5          32\n",
              "8       Puzzle Scooby-Doo Avec Poster 2x35 Pieces nan      3           7\n",
              "9   Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...      6         313\n",
              "10  Eames Inspired Sxw Chair - Pink - Black The ti...      7         102\n",
              "11  Fauteuil Chesterfield Brenton 100% Cuir De Buf...      7         665\n",
              "12  Peaceable Kingdom Wheres Bear? The Hide And Fi...      8         194\n",
              "13  Paire De Voilages Imprimés Fantaisie Paire de ...      9          84\n",
              "14  Matelas Mémoire De Forme 180x200 X 20 Cm Très ...      7         319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2i287kRFsVC",
        "outputId": "19c43923-a075-4a63-d07a-dec8b15efc02"
      },
      "source": [
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  nltk.download('punkt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "B1RA-vO-FpEX",
        "outputId": "0ae02c15-363b-4c70-fbc7-1095a04ba9f4"
      },
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!]+\", \" \", w)\n",
        "    w = re.sub(r'\\b\\w{0,2}\\b', '', w)\n",
        "\n",
        "    # remove stopword\n",
        "    mots = word_tokenize(w.strip())\n",
        "    mots = [mot for mot in mots if mot not in stop_words]\n",
        "    return ' '.join(mots).strip()\n",
        "\n",
        "df.Features = df.Features.apply(lambda x :preprocess_sentence(x))\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Features</th>\n",
              "      <th>label</th>\n",
              "      <th>count_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>olivia personalisiertes notizbuch seiten punkt...</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>journal des arts art son marche salon art asia...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>peluche donald europe disneyland marionnette d...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>guerre des tuques luc des eacute grandeur . ve...</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Features  label  count_word\n",
              "0  olivia personalisiertes notizbuch seiten punkt...      0          15\n",
              "1  journal des arts art son marche salon art asia...      1          40\n",
              "2  grand stylet ergonomique bleu gamepad nintendo...      2         121\n",
              "3  peluche donald europe disneyland marionnette d...      3          11\n",
              "4  guerre des tuques luc des eacute grandeur . ve...      4          38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gneXDzdGUyt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_text_train, X_text_test, y_train, y_test = train_test_split(df.Features, df.label, test_size=0.3, random_state=1234)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LFxLrxeGtDQ",
        "outputId": "f80b49c0-4c0a-469d-9ad4-116da29e0940"
      },
      "source": [
        "X_text_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65547    carte garbage pail kids les crados card topps ...\n",
              "76168    helit planchette subdiviision pour bac fiches ...\n",
              "42338                         siege auto marque runner nan\n",
              "5412             lot magazines bandes dessinees suivre nan\n",
              "80800    housse protection silicone avec couverture cas...\n",
              "                               ...                        \n",
              "32399                                      physiophile nan\n",
              "82584    film solaire piscine ronde bleu film solaire p...\n",
              "60620                    decalcomanies jabo superscale nan\n",
              "34086    eva yoga pilates cork bloc mousse brique exten...\n",
              "58067    chaise salle manger grise chaise salle manger ...\n",
              "Name: Features, Length: 59441, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVMPVj9XG8gu"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Définition du tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "# Mettre à jour le dictionnaire du tokenizer\n",
        "tokenizer.fit_on_texts(X_text_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "valbpOC2HNeF"
      },
      "source": [
        "# Définition des dictionnaires\n",
        "word2idx = tokenizer.word_index\n",
        "idx2word = tokenizer.index_word\n",
        "vocab_size = tokenizer.num_words"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KreOWhQHRpG"
      },
      "source": [
        "# Transformation en séquences de nombres entier\n",
        "X_train = tokenizer.texts_to_sequences(X_text_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_text_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWcxyOTfHzhz"
      },
      "source": [
        "# Transformation en tableau numpy \n",
        "maxlen = 500\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen, padding='post')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MapUxYvqMcxA"
      },
      "source": [
        "# LOOP 3-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCS32p4UIIcS",
        "outputId": "92a02ca4-722b-4992-db2a-96d348d60456"
      },
      "source": [
        "# Modèle RNN simple\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, RNN, GRUCell, Dropout\n",
        "embedding_dim = 200 \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, embedding_dim))\n",
        "model.add(RNN(GRUCell(128), return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(27, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "rnn_2 (RNN)                  (None, None, 128)         126720    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 27)                6939      \n",
            "=================================================================\n",
            "Total params: 2,166,683\n",
            "Trainable params: 2,166,683\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsieNrVCIswn"
      },
      "source": [
        "# implementation du callback checkpoint\n",
        "from tensorflow.keras import callbacks"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cro3bG9I2jG"
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "filepath = cwd\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath = filepath, monitor = 'val_loss', save_best_only = True, save_weights_only = False,\n",
        "                                       mode = 'min', save_freq = 'epoch')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYEjckETIuCe"
      },
      "source": [
        "lr_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=2, mode='min')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgzWPo7nJIK7",
        "outputId": "aab1469d-b278-43ac-cc63-2cbabf45e663"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "opt = Adam(lr=0.0007)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mJnvp26IbvC"
      },
      "source": [
        "model.compile(optimizer= opt, \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxf2s3gFJc-z",
        "outputId": "3dd193db-0a0a-4a54-c446-4f0675fd046b"
      },
      "source": [
        "history2 = model.fit(X_train, y_train.values,\n",
        "    batch_size = 64,\n",
        "    epochs=10,\n",
        "    validation_data = [X_test, y_test.values],\n",
        "    callbacks = [lr_plateau , checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "929/929 [==============================] - 1066s 1s/step - loss: 2.0864 - accuracy: 0.3605 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "INFO:tensorflow:Assets written to: /content/assets\n",
            "Epoch 2/10\n",
            "929/929 [==============================] - 1078s 1s/step - loss: 1.1322 - accuracy: 0.6485 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 6.99999975040555e-05.\n",
            "Epoch 3/10\n",
            "929/929 [==============================] - 1075s 1s/step - loss: 0.8078 - accuracy: 0.7602 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.999999459367246e-06.\n",
            "Epoch 4/10\n",
            "929/929 [==============================] - 1063s 1s/step - loss: 0.7682 - accuracy: 0.7736 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.999999641266187e-07.\n",
            "Epoch 5/10\n",
            "929/929 [==============================] - 1065s 1s/step - loss: 0.7637 - accuracy: 0.7753 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.999999868639861e-08.\n",
            "Epoch 6/10\n",
            "902/929 [============================>.] - ETA: 29s - loss: 0.7624 - accuracy: 0.7757"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz03H6dBTB6K"
      },
      "source": [
        "# LOOP 3-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xas-wevXTE4V",
        "outputId": "6ae810ed-d4c8-4c90-bf34-acdce6472534"
      },
      "source": [
        "# Modèle RNN simple\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, RNN, GRUCell, Dropout\n",
        "embedding_dim = 200 \n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(10000, embedding_dim))\n",
        "model2.add(RNN(GRUCell(128), return_sequences=True))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(GlobalAveragePooling1D())\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dropout(0.35))\n",
        "model2.add(Dense(27, activation='softmax'))\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "rnn_1 (RNN)                  (None, None, 128)         126720    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 27)                6939      \n",
            "=================================================================\n",
            "Total params: 2,166,683\n",
            "Trainable params: 2,166,683\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os-OuOw0TvEr"
      },
      "source": [
        "model2.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrXqyfGOT_9L",
        "outputId": "67b57b00-f80c-4467-f3b6-d6edfd34d04f"
      },
      "source": [
        "history2 = model2.fit(X_train, y_train,\n",
        "    batch_size = 64,\n",
        "    epochs=3,\n",
        "    validation_data = (X_test, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "929/929 [==============================] - 1046s 1s/step - loss: 1.8447 - accuracy: 0.4325 - val_loss: 1.1283 - val_accuracy: 0.6522\n",
            "Epoch 2/3\n",
            "929/929 [==============================] - 1034s 1s/step - loss: 0.9209 - accuracy: 0.7272 - val_loss: 0.8615 - val_accuracy: 0.7496\n",
            "Epoch 3/3\n",
            "929/929 [==============================] - 1035s 1s/step - loss: 0.6827 - accuracy: 0.7982 - val_loss: 0.7950 - val_accuracy: 0.7684\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}