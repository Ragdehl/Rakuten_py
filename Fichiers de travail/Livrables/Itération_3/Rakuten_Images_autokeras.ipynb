{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7b841a",
   "metadata": {},
   "source": [
    "Essais auto-ML avec **autokeras** sur les image: Inutilisable car beaucoup trop lent sur un simple PC, pas très verbeux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\image_classifier\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\image_classifier\\tuner0.json\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "image_block_1/b...|efficient         |vanilla           \n",
      "image_block_1/n...|True              |True              \n",
      "image_block_1/a...|True              |False             \n",
      "image_block_1/i...|True              |None              \n",
      "image_block_1/i...|False             |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/i...|0.1               |None              \n",
      "image_block_1/i...|0                 |None              \n",
      "image_block_1/e...|True              |None              \n",
      "image_block_1/e...|b7                |None              \n",
      "image_block_1/e...|True              |None              \n",
      "image_block_1/e...|True              |None              \n",
      "classification_...|global_avg        |flatten           \n",
      "classification_...|0                 |0.5               \n",
      "optimizer         |adam              |adam              \n",
      "learning_rate     |2e-05             |0.001             \n",
      "\n",
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "# a voir: pyCaret, Azure\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import autokeras as ak\n",
    "import kerastuner\n",
    "\n",
    "def f1_score_w(y_true, y_pred, **kwargs):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "def image_path(row, subdir=\"image_train\"):\n",
    "    \"\"\" Construction du chemin d'un fichier image \"\"\"\n",
    "    f = \"image_%d_product_%d.jpg\" % (row.imageid, row.productid) \n",
    "    return os.path.join(os.getcwd(), \"images\", subdir, f)\n",
    "\n",
    "\n",
    "def dataset_generator(imagepaths, targets, nb):\n",
    "    \"\"\" Fonction génératrice de paires (X, y) \"\"\"\n",
    "    for i in range(nb):\n",
    "        f = imagepaths[i].decode('utf-8')\n",
    "        img = mpimg.imread(f)\n",
    "        y = targets[i].reshape(1)\n",
    "        yield img, y\n",
    "\n",
    "\n",
    "def get_dataset(nb=-1, batch_size=16):\n",
    "    \"\"\" Dataset de nb échantillons \"\"\"\n",
    "    imagepaths = list(pd.read_csv(\"X_train_update.csv\")[:nb].apply(image_path, axis=1))\n",
    "    prdtypes = list(pd.read_csv(\"Y_train_CVw08PX.csv\")[\"prdtypecode\"][:nb])\n",
    "    uniqprdtypes = sorted(list(set(prdtypes)))\n",
    "    prdtype_to_int = {u:i for i, u in enumerate(uniqprdtypes) }                \n",
    "    targets = np.array([prdtype_to_int[p] for p in prdtypes])\n",
    "    dataset = tf.data.Dataset.from_generator(dataset_generator, args=[imagepaths, targets, len(imagepaths)],\n",
    "                                             output_types=(tf.int32, tf.int32),\n",
    "                                             output_shapes=([500, 500, 3], [1,]))\n",
    "    #dataset = dataset.shuffle(buffer_size=100000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = get_dataset(4000)\n",
    "#iterator = iter(dataset)\n",
    "#next_element = iterator.get_next()\n",
    "\n",
    "# overwitting=False => créé un ./image_classifier et repart de là\n",
    "clf = ak.ImageClassifier(max_trials=10,\n",
    "#                         objective=kerastuner.Objective('val_f1_score_w', direction='max'),\n",
    "#                         metrics=[f1_score_w],\n",
    "                         seed=123)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(dataset, epochs=4, validation_split=0.15, verbose=2)\n",
    "print(f\"Executé en {int(time()-t0)} secondes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11533b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
