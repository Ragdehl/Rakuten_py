{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LOOP 3 IMAGES WITH EFFICIENT NET 25 06 2021.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ragdehl/Rakuten_py/blob/main/Livrables/It%C3%A9ration_3/LOOP_3_IMAGES_WITH_EFFICIENT_NET_25_06_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or0V6M7V-n8E"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob"
      ],
      "id": "or0V6M7V-n8E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDHFg18O-n8H"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "id": "FDHFg18O-n8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOOJODmb-n8H"
      },
      "source": [
        "X = pd.read_csv('X_train_update.csv',index_col=0)\n",
        "y = pd.read_csv('Y_train_CVw08PX.csv',index_col=0)"
      ],
      "id": "iOOJODmb-n8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBhCttTi-n8I"
      },
      "source": [
        "import os #Miscellaneous operating system interfaces\n",
        "#https://docs.python.org/3/library/os.html\n",
        "\n",
        "#get current working directory\n",
        "current_path = os.getcwd() \n",
        "\n",
        "#Training images path\n",
        "images_path = current_path + r'/images2/image_train/'\n",
        "\n",
        "#List with the name of all training images\n",
        "images_list = os.listdir(images_path)"
      ],
      "id": "nBhCttTi-n8I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApjWMNyp-n8I",
        "outputId": "9732d847-0f7c-416b-e211-2f8a0b838514"
      },
      "source": [
        "#Create a column with the name of the picture\n",
        "X['image name'] = 'image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
        "X['image name']"
      ],
      "id": "ApjWMNyp-n8I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        image_1263597046_product_3804725264.jpg\n",
              "1         image_1008141237_product_436067568.jpg\n",
              "2          image_938777978_product_201115110.jpg\n",
              "3           image_457047496_product_50418756.jpg\n",
              "4         image_1077757786_product_278535884.jpg\n",
              "                          ...                   \n",
              "84911      image_941495734_product_206719094.jpg\n",
              "84912    image_1188462883_product_3065095706.jpg\n",
              "84913     image_1009325617_product_440707564.jpg\n",
              "84914    image_1267353403_product_3942400296.jpg\n",
              "84915       image_684671297_product_57203227.jpg\n",
              "Name: image name, Length: 84916, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cFPZfE7-n8J"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
        "\n",
        "X_val = X_train.iloc[:1600,:]\n",
        "y_val = y_train.iloc[:1600,:]\n",
        "\n",
        "X_train = X_train.iloc[:14400,:]\n",
        "y_train = y_train.iloc[:14400:,:]\n",
        "\n",
        "X_test = X_test.iloc[:4000,:]\n",
        "y_test = y_test.iloc[:4000,:]"
      ],
      "id": "-cFPZfE7-n8J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pEjM1hm-n8K"
      },
      "source": [
        "X_train[\"class\"] = y_train\n",
        "X_test[\"class\"] = y_test\n",
        "X_val[\"class\"] = y_val"
      ],
      "id": "0pEjM1hm-n8K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHHivywF-n8K"
      },
      "source": [
        "train_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range = 10, width_shift_range = 0.15, height_shift_range = 0.15,zoom_range = 1.1, horizontal_flip = True)\n",
        "val_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range = 10, width_shift_range = 0.15, height_shift_range = 0.15,zoom_range = 1.1,horizontal_flip = True)\n",
        "test_data_generator = ImageDataGenerator(rescale = 1./255)"
      ],
      "id": "lHHivywF-n8K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCYbxVDA-n8L",
        "outputId": "cb52f214-ee32-41bc-967b-ef7a3b326e66"
      },
      "source": [
        "batch_size = 32\n",
        "path = images_path\n",
        "X_train[\"class\"] = X_train[\"class\"].astype(str)\n",
        "X_test[\"class\"] = X_test[\"class\"].astype(str)\n",
        "X_val[\"class\"] = X_val[\"class\"].astype(str)\n",
        "\n",
        "train_generator = train_data_generator.flow_from_dataframe(dataframe=X_train,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)\n",
        "\n",
        "\n",
        "val_generator = val_data_generator.flow_from_dataframe(dataframe=X_val,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)\n",
        "\n",
        "test_generator = test_data_generator.flow_from_dataframe(dataframe=X_test,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)"
      ],
      "id": "nCYbxVDA-n8L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14400 validated image filenames belonging to 27 classes.\n",
            "Found 1600 validated image filenames belonging to 27 classes.\n",
            "Found 4000 validated image filenames belonging to 27 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgdQG1pc-n8L"
      },
      "source": [
        ""
      ],
      "id": "MgdQG1pc-n8L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAScJc6J-n8L",
        "outputId": "5896aa5b-2ede-40fa-eaea-eee30780ddc1"
      },
      "source": [
        "pip install -U efficientnet"
      ],
      "id": "XAScJc6J-n8L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from efficientnet) (0.17.2)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: h5py in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.2)\n",
            "Requirement already satisfied: six in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (1.6.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (3.4.0)\n",
            "Requirement already satisfied: networkx>=2.0 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (2.5)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (8.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (2020.10.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXTXn3qd-n8M"
      },
      "source": [
        "import efficientnet.keras as efn\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout,Dense, Flatten, GlobalAveragePooling2D"
      ],
      "id": "iXTXn3qd-n8M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO_vIlPQ-n8M"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "opt = Adam(lr=0.0001)"
      ],
      "id": "gO_vIlPQ-n8M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYgw8GRH-n8M",
        "outputId": "76081538-d42a-43cd-edd2-b68c9a0fa4c6"
      },
      "source": [
        "base_model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "n_class = 27\n",
        "model = Sequential()\n",
        "model.add(efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_class, activation=\"sigmoid\"))\n",
        "    \n",
        "# Compiling the model\n",
        "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "id": "DYgw8GRH-n8M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 62720)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              64226304  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 27)                27675     \n",
            "=================================================================\n",
            "Total params: 68,303,543\n",
            "Trainable params: 68,261,527\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy9iCOYd-n8M",
        "outputId": "b0af9450-f8a8-4a0e-f69f-b6b6a5d5a3de"
      },
      "source": [
        "model.fit_generator(train_generator, \n",
        "                                epochs = 2,\n",
        "                                steps_per_epoch = len(X_train)//batch_size,\n",
        "                                validation_data = val_generator,\n",
        "                                validation_steps = len(X_val)//batch_size)"
      ],
      "id": "Yy9iCOYd-n8M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-8a011b2255bb>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/2\n",
            "450/450 [==============================] - 1639s 4s/step - loss: 2.9782 - accuracy: 0.1742 - val_loss: 2.5216 - val_accuracy: 0.2862\n",
            "Epoch 2/2\n",
            "450/450 [==============================] - 1611s 4s/step - loss: 2.5967 - accuracy: 0.2812 - val_loss: 2.1837 - val_accuracy: 0.3569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1fcb33ee580>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODi_57sO-n8N"
      },
      "source": [
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True"
      ],
      "id": "ODi_57sO-n8N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbCALKPk-n8N",
        "outputId": "979ccd7b-5ba4-453b-9bbe-92276bbc225a"
      },
      "source": [
        "model.compile(optimizer= opt , loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist_unfreeze = model.fit_generator(generator=train_generator, \n",
        "                                epochs = 2,\n",
        "                                steps_per_epoch = len(X_train)//batch_size,\n",
        "                                validation_data=test_generator,\n",
        "                                validation_steps=len(X_val)//batch_size\n",
        "                                )"
      ],
      "id": "BbCALKPk-n8N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "450/450 [==============================] - 1622s 4s/step - loss: 2.3926 - accuracy: 0.3294 - val_loss: 1.8585 - val_accuracy: 0.4688\n",
            "Epoch 2/2\n",
            "450/450 [==============================] - 1678s 4s/step - loss: 2.2835 - accuracy: 0.3477 - val_loss: 1.8688 - val_accuracy: 0.4856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTTVHY8U-n8N",
        "outputId": "9bca8608-be1a-4766-8233-a0f838971f97"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(hist_unfreeze.history).plot(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0.2, 0.6) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "id": "OTTVHY8U-n8N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAGovT9H-n8O"
      },
      "source": [
        "## loop 2 with callbacks + augmentation nombre données (avec passage en batch de 64)"
      ],
      "id": "nAGovT9H-n8O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fAPRUH1-n8O"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
        "X_val = X_train.iloc[:4800,:] #\n",
        "y_val = y_train.iloc[:4800,:]\n",
        "X_train = X_train.iloc[:43200,:] #\n",
        "y_train = y_train.iloc[:43200,:]\n",
        "X_test = X_test.iloc[:12000,:] #\n",
        "y_test = y_test.iloc[:12000,:]"
      ],
      "id": "2fAPRUH1-n8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEHIMA_4-n8O"
      },
      "source": [
        "X_train[\"class\"] = y_train\n",
        "X_test[\"class\"] = y_test\n",
        "X_val[\"class\"] = y_val"
      ],
      "id": "pEHIMA_4-n8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScQa0KAT-n8O"
      },
      "source": [
        "train_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range = 10, width_shift_range = 0.15, height_shift_range = 0.12,zoom_range = 1.1, horizontal_flip = True)\n",
        "val_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range = 10, width_shift_range = 0.15, height_shift_range = 0.12,zoom_range = 1.1,horizontal_flip = True)\n",
        "test_data_generator = ImageDataGenerator(rescale = 1./255)"
      ],
      "id": "ScQa0KAT-n8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeyGueZr-n8O",
        "outputId": "017facf6-6912-4d01-e109-c2be2cdc8f99"
      },
      "source": [
        "batch_size = 64 #\n",
        "path = images_path\n",
        "X_train[\"class\"] = X_train[\"class\"].astype(str)\n",
        "X_test[\"class\"] = X_test[\"class\"].astype(str)\n",
        "X_val[\"class\"] = X_val[\"class\"].astype(str)\n",
        "\n",
        "train_generator = train_data_generator.flow_from_dataframe(dataframe=X_train,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)\n",
        "\n",
        "\n",
        "val_generator = val_data_generator.flow_from_dataframe(dataframe=X_val,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)\n",
        "\n",
        "test_generator = test_data_generator.flow_from_dataframe(dataframe=X_test,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)"
      ],
      "id": "aeyGueZr-n8O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 43200 validated image filenames belonging to 27 classes.\n",
            "Found 4800 validated image filenames belonging to 27 classes.\n",
            "Found 12000 validated image filenames belonging to 27 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOkM75C3-n8P"
      },
      "source": [
        "opt2 = Adam(lr=0.1)"
      ],
      "id": "vOkM75C3-n8P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQInAV1P-n8P",
        "outputId": "4776f40e-eb06-4540-dc09-e73be261d39c"
      },
      "source": [
        "base_model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "n_class = 27\n",
        "model2 = Sequential()\n",
        "model2.add(efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet'))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(1024, activation=\"relu\"))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(n_class, activation=\"sigmoid\"))\n",
        "    \n",
        "# Compiling the model\n",
        "model2.compile(optimizer=opt2,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "id": "pQInAV1P-n8P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 62720)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              64226304  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 27)                27675     \n",
            "=================================================================\n",
            "Total params: 68,303,543\n",
            "Trainable params: 68,261,527\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmoqBAHa-n8P"
      },
      "source": [
        "# implementation du callback checkpoint\n",
        "from tensorflow.keras import callbacks\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "filepath = cwd\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath = filepath, monitor = 'val_loss', save_best_only = True, save_weights_only = False,\n",
        "                                       mode = 'min', save_freq = 'epoch')"
      ],
      "id": "YmoqBAHa-n8P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yVZTx0B-n8P"
      },
      "source": [
        "# diminution du learning rate toutes les epochs\n",
        "def decreasinglrUpdate(epoch,learning_rate):\n",
        "    if epoch % 1 == 0:\n",
        "        return learning_rate * 0.3\n",
        "    else: \n",
        "        return learning_rate\n",
        "    \n",
        "lrScheduler = callbacks.LearningRateScheduler(schedule = decreasinglrUpdate,\n",
        "                                              verbose = 1)"
      ],
      "id": "1yVZTx0B-n8P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqDyKJEX-n8P",
        "outputId": "8834efa4-c7ef-4621-81c2-dcafdb1bf940"
      },
      "source": [
        "# Training the model for 10 epochs\n",
        "history2 = model2.fit_generator(train_generator, \n",
        "                                epochs = 7,\n",
        "                                steps_per_epoch = len(X_train)//batch_size,\n",
        "                                validation_data = val_generator,\n",
        "                                validation_steps = len(X_val)//batch_size,\n",
        "                                callbacks = [lrScheduler, checkpoint])"
      ],
      "id": "oqDyKJEX-n8P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.030000000447034835.\n",
            "Epoch 1/7\n",
            "675/675 [==============================] - ETA: 0s - loss: 14.5100 - accuracy: 0.0391WARNING:tensorflow:From C:\\Users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From C:\\Users\\utilisateur\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\utilisateur\\Documents\\projet_rakuten\\assets\n",
            "675/675 [==============================] - 4961s 7s/step - loss: 14.5100 - accuracy: 0.0391 - val_loss: 14.6776 - val_accuracy: 0.0360\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.009000000357627868.\n",
            "Epoch 2/7\n",
            "675/675 [==============================] - ETA: 0s - loss: 14.5701 - accuracy: 0.0388INFO:tensorflow:Assets written to: C:\\Users\\utilisateur\\Documents\\projet_rakuten\\assets\n",
            "675/675 [==============================] - 4884s 7s/step - loss: 14.5701 - accuracy: 0.0388 - val_loss: 14.6099 - val_accuracy: 0.0360\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.002700000163167715.\n",
            "Epoch 3/7\n",
            "675/675 [==============================] - ETA: 0s - loss: 14.5268 - accuracy: 0.0388INFO:tensorflow:Assets written to: C:\\Users\\utilisateur\\Documents\\projet_rakuten\\assets\n",
            "675/675 [==============================] - 4838s 7s/step - loss: 14.5268 - accuracy: 0.0388 - val_loss: 14.6096 - val_accuracy: 0.0360\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0008100000210106373.\n",
            "Epoch 4/7\n",
            " 33/675 [>.............................] - ETA: 1:14:19 - loss: 14.5771 - accuracy: 0.0417"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-35-5f2a8dd44997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training the model for 10 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history2 = model2.fit_generator(train_generator, \n\u001b[0m\u001b[0;32m      3\u001b[0m                                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \"\"\"\n\u001b[0;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS4JsYh_-n8Q"
      },
      "source": [
        "# resultats particulièrement mauvais sans amélioration -> arrêt "
      ],
      "id": "zS4JsYh_-n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3DEOoI-n8Q"
      },
      "source": [
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True"
      ],
      "id": "0-3DEOoI-n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-8cMf23-n8Q"
      },
      "source": [
        "model2.compile(optimizer= opt , loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist_unfreeze2 = model2.fit_generator(generator=train_generator, \n",
        "                                epochs = 5,\n",
        "                                steps_per_epoch = len(X_train)//batch_size,\n",
        "                                validation_data=test_generator,\n",
        "                                validation_steps=len(X_val)//batch_size\n",
        "                                )"
      ],
      "id": "X-8cMf23-n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXIIcPAy-n8Q"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(history.hist_unfreeze2).plot(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "id": "eXIIcPAy-n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soMa6STr-n8Q"
      },
      "source": [
        "## loop 3 with callbacks + augmentation nombre données (on repart en batch de 32 )\n",
        "## learning rate fixe"
      ],
      "id": "soMa6STr-n8Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCdshkHT-n8Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
        "\n",
        "X_val = X_train.iloc[:3200,:]\n",
        "y_val = y_train.iloc[:3200,:]\n",
        "\n",
        "X_train = X_train.iloc[:28800,:]\n",
        "y_train = y_train.iloc[:28800:,:]\n",
        "\n",
        "X_test = X_test.iloc[:8000,:]\n",
        "y_test = y_test.iloc[:8000,:]"
      ],
      "id": "hCdshkHT-n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnFic-h--n8Q"
      },
      "source": [
        "X_train[\"class\"] = y_train\n",
        "X_test[\"class\"] = y_test\n",
        "X_val[\"class\"] = y_val"
      ],
      "id": "FnFic-h--n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWJ2Wiy-n8Q"
      },
      "source": [
        "train_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range = 10, width_shift_range = 0.1, height_shift_range = 0.15,zoom_range = 1.1, horizontal_flip = True)\n",
        "val_data_generator = ImageDataGenerator(rescale = 1./255, rotation_range = 10, width_shift_range = 0.1, height_shift_range = 0.15,zoom_range = 1.1,horizontal_flip = True)\n",
        "test_data_generator = ImageDataGenerator(rescale = 1./255)"
      ],
      "id": "-HWJ2Wiy-n8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZPmXUWM-n8Q",
        "outputId": "e639f3d2-8479-4442-d53b-1d95473d33af"
      },
      "source": [
        "batch_size = 32\n",
        "path = images_path\n",
        "X_train[\"class\"] = X_train[\"class\"].astype(str)\n",
        "X_test[\"class\"] = X_test[\"class\"].astype(str)\n",
        "X_val[\"class\"] = X_val[\"class\"].astype(str)\n",
        "\n",
        "train_generator = train_data_generator.flow_from_dataframe(dataframe=X_train,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)\n",
        "\n",
        "\n",
        "val_generator = val_data_generator.flow_from_dataframe(dataframe=X_val,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)\n",
        "\n",
        "test_generator = test_data_generator.flow_from_dataframe(dataframe=X_test,\n",
        "                                                          directory=path,\n",
        "                                                           x_col = \"image name\",\n",
        "                                                           y_col = \"class\",\n",
        "                                                           class_mode =\"sparse\",\n",
        "                                                          target_size = (224, 224), \n",
        "                                                          batch_size = batch_size)"
      ],
      "id": "BZPmXUWM-n8Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28800 validated image filenames belonging to 27 classes.\n",
            "Found 3200 validated image filenames belonging to 27 classes.\n",
            "Found 8000 validated image filenames belonging to 27 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBw7RHO9-n8R"
      },
      "source": [
        "opt3 = Adam(lr=0.0001)"
      ],
      "id": "FBw7RHO9-n8R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEE1gFMK-n8R",
        "outputId": "817b726a-b9fb-47d2-dc2e-afb7c67fbf5e"
      },
      "source": [
        "base_model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "n_class = 27\n",
        "model3 = Sequential()\n",
        "model3.add(efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet'))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(1024, activation=\"relu\"))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(n_class, activation=\"sigmoid\"))\n",
        "    \n",
        "# Compiling the model\n",
        "model3.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "id": "cEE1gFMK-n8R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 62720)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              64226304  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 27)                27675     \n",
            "=================================================================\n",
            "Total params: 68,303,543\n",
            "Trainable params: 68,261,527\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZtG_aKo-n8R"
      },
      "source": [
        "# implementation du callback checkpoint\n",
        "from tensorflow.keras import callbacks\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "filepath = cwd\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath = filepath, monitor = 'val_loss', save_best_only = True, save_weights_only = False,\n",
        "                                       mode = 'min', save_freq = 'epoch')"
      ],
      "id": "mZtG_aKo-n8R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81sfCioU-n8R"
      },
      "source": [
        "lr_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=2, mode='min')"
      ],
      "id": "81sfCioU-n8R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XtUGbBk-n8R",
        "outputId": "17231cc4-c0bd-44cc-88c3-8a011d394a62"
      },
      "source": [
        "# Training the model for 3 epochs\n",
        "history3 = model3.fit_generator(train_generator, \n",
        "                                epochs = 3,\n",
        "                                steps_per_epoch = len(X_train)//batch_size,\n",
        "                                validation_data = val_generator,\n",
        "                                validation_steps = len(X_val)//batch_size,\n",
        "                                callbacks = [lr_plateau , checkpoint])"
      ],
      "id": "0XtUGbBk-n8R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "900/900 [==============================] - ETA: 0s - loss: 3.1619 - accuracy: 0.0974INFO:tensorflow:Assets written to: C:\\Users\\utilisateur\\Documents\\projet_rakuten\\assets\n",
            "900/900 [==============================] - 3369s 4s/step - loss: 3.1619 - accuracy: 0.0974 - val_loss: 2.8459 - val_accuracy: 0.1728\n",
            "Epoch 2/3\n",
            "900/900 [==============================] - ETA: 0s - loss: 2.7323 - accuracy: 0.2122INFO:tensorflow:Assets written to: C:\\Users\\utilisateur\\Documents\\projet_rakuten\\assets\n",
            "900/900 [==============================] - 4129s 5s/step - loss: 2.7323 - accuracy: 0.2122 - val_loss: 2.3597 - val_accuracy: 0.3300\n",
            "Epoch 3/3\n",
            "900/900 [==============================] - ETA: 0s - loss: 2.4262 - accuracy: 0.3099INFO:tensorflow:Assets written to: C:\\Users\\utilisateur\\Documents\\projet_rakuten\\assets\n",
            "900/900 [==============================] - 4154s 5s/step - loss: 2.4262 - accuracy: 0.3099 - val_loss: 2.0863 - val_accuracy: 0.3837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTKuXVWB-n8R"
      },
      "source": [
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True"
      ],
      "id": "XTKuXVWB-n8R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZXu3U5Q-n8R",
        "outputId": "ddf5e6fb-60a4-40d3-fa90-de2c15bbf0b2"
      },
      "source": [
        "model3.compile(optimizer= opt , loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "hist_unfreeze3 = model3.fit_generator(generator=train_generator, \n",
        "                                epochs = 3,\n",
        "                                steps_per_epoch = len(X_train)//batch_size,\n",
        "                                validation_data=test_generator,\n",
        "                                validation_steps=len(X_val)//batch_size\n",
        "                                )"
      ],
      "id": "5ZXu3U5Q-n8R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "900/900 [==============================] - 3672s 4s/step - loss: 2.2580 - accuracy: 0.3553 - val_loss: 1.8056 - val_accuracy: 0.4775\n",
            "Epoch 2/3\n",
            "900/900 [==============================] - 3648s 4s/step - loss: 2.1416 - accuracy: 0.3816 - val_loss: 1.7165 - val_accuracy: 0.5200\n",
            "Epoch 3/3\n",
            "900/900 [==============================] - 5692s 6s/step - loss: 2.0611 - accuracy: 0.4059 - val_loss: 1.6005 - val_accuracy: 0.5391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2wWQrr_-n8R",
        "outputId": "2210633d-62d9-436c-cce0-e547d1410d79"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(hist_unfreeze3.history).plot(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0.2, 0.6) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "id": "e2wWQrr_-n8R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHWCAYAAACFXRQ+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAABAA0lEQVR4nO3de3ycdZ33//cnk0zS5tRzeqQJClagLYdQTlJSkALeQEWLVFlE7gUe6AIrPnQRT8u94K6Kh5+7sna73qiscBd+ICs/rbCyEiouaKlbKMfK3aSQtvREmyY9ZJKZz++PmU5mrkyaudokk8Pr+Xjk0Znr+l7XXNeHMH3z5Xt9v+buAgAAANCtqNAXAAAAAAw1hGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAAC8grJZnaxmb1hZm+a2Rd7adNgZuvM7BUzeybMsQAAAMBQYn3Nk2xmEUkbJF0oqUXSGkkfd/dXM9qMk/Rfki5297fMbIq7b8/nWAAAAGCoyacneYGkN919o7vHJK2UtCTQ5hOSfu7ub0mSu28PcSwAAAAwpOQTkmdIejvjfUtqW6bjJY03s0YzW2tmnwxxLAAAADCkFOfRxnJsC47RKJZ0mqQLJI2R9JyZPZ/nsckPMbtR0o2SNGbMmNNmzZqVx6X1r0QioaIinmXMF/UKh3qFQ73CoV7hUK/wqFk41CucQtVrw4YNO919cq59+YTkFkmZiXWmpC052ux0932S9pnZaknz8zxWkuTuKyStkKT6+np/4YUX8ri0/tXY2KiGhoZB/9zhinqFQ73CoV7hUK9wqFd41Cwc6hVOoeplZpt625dPZF8j6TgzqzOzqKRlkh4PtPmFpHPNrNjMxko6Q9JreR4LAAAADCl99iS7e5eZ3SzpSUkRSfe5+ytmdlNq/3J3f83MnpD0kqSEpB+5+8uSlOvYAboXAAAAoF/kM9xC7r5K0qrAtuWB9/dIuiefYwEAAIChLK+QPBR0dnaqpaVFBw8eHLDPqK6u1muvvTZg5x9JysrKZJbruUwAAIDhb9iE5JaWFlVWVqq2tnbAwllbW5sqKysH5Nwjibtr165dKi8vL/SlAAAADIhhMzfJwYMHNXHiRHovhwAz08SJExWJRAp9KQAAAANi2IRkSQTkIYR/FgAAYCQbViG50CoqKgp9CQAAABgEhGQAAAAggJB8BNxdX/jCF3TSSSdp7ty5euihhyRJW7du1cKFC3XyySfrpJNO0u9+9zvF43F96lOfSrf93ve+V+CrBwAAQF+GzewWmf7X//eKXt2yt1/PecL0Kn2u4Zi82v785z/XunXr9OKLL2rnzp06/fTTtXDhQj344IO66KKL9OUvf1nxeFz79+/XunXrtHnzZr388suSpD179vTrdQMAAKD/0ZN8BJ599ll9/OMfVyQSUU1Njc477zytWbNGp59+un784x/rzjvv1Pr161VZWaljjz1WGzdu1C233KInnnhCVVVVhb58AAAA9GFY9iT/7WUnDsh529ra8mrn7jm3L1y4UKtXr9avfvUrXXPNNfrCF76gT37yk3rxxRf15JNP6t5779XDDz+s++67rz8vGwAAAP2MnuQjsHDhQj300EOKx+PasWOHVq9erQULFmjTpk2aMmWKbrjhBv3lX/6l/vSnP2nnzp1KJBL66Ec/qrvuukt/+tOfCn35AAAA6MOw7EkutCuuuELPPfec5s+fLzPTt771LU2dOlU//elPdc8996ikpEQVFRW6//77tXnzZl133XVKJBKSpH/4h38o8NUDAACgL4TkENrb2yUlF9K45557dM8992Ttv/baa3Xttdf2OI7eYwAAgOGF4RYAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIHmK6uroKfQkAAACjHiE5hA9/+MM67bTTdOKJJ2rFihWSpCeeeEKnnnqq5s+frwsuuEBSctGR6667TnPnztW8efP06KOPSpIqKirS53rkkUf0qU99SpL0qU99Sp/73Oe0aNEi3X777frjH/+os88+W6eccorOPvtsvfHGG5KkeDyuz3/+8+nz/tM//ZP+8z//U1dccUX6vL/5zW/0kY98ZDDKAQAAMGINzxX3fv1F6Z31/XvOqXOlD3z5sE3uu+8+TZgwQQcOHNDpp5+uJUuW6IYbbtDq1atVV1end999V5J01113qbq6WuvXJ69x9+7dfX78hg0b9NRTTykSiWjv3r1avXq1iouL9dRTT+lLX/qSHn30Ua1YsUJNTU367//+bxUXF+vdd9/V+PHj9Vd/9VfasWOHJk+erB//+Me67rrrjr4eAAAAo9jwDMkF8o//+I967LHHJElvv/22VqxYoYULF6qurk6SNGHCBEnSU089pZUrV6aPGz9+fJ/nvvLKKxWJRCRJra2tuvbaa/XnP/9ZZqbOzs70eW+66SYVFxdnfd4111yjn/3sZ7ruuuv03HPP6f777++nOwYAABidhmdIvuQbA3PetrZedzU2Nuqpp57Sc889p7Fjx6qhoUHz589PD4XI5O4ysx7bM7cdPHgwa195eXn69Ve/+lUtWrRIjz32mJqbm9XQ0HDY81533XW67LLLVFZWpiuvvDIdogEAAHBkGJOcp9bWVo0fP15jx47V66+/rueff14dHR165pln1NTUJEnp4RaLFy/WD37wg/Sxh4Zb1NTU6LXXXlMikUj3SPf2WTNmzJAk/eQnP0lvX7x4sZYvX55+uO/Q502fPl3Tp0/X3XffnR7nDAAAgCNHSM7TxRdfrK6uLs2bN09f/epXdeaZZ2ry5MlasWKFPvKRj2j+/Pm66qqrJElf+cpXtHv3bp100kmaP3++nn76aUnSN77xDV166aU6//zzNW3atF4/62/+5m90xx136JxzzlE8Hk9vv/7663XMMcdo3rx5mj9/vh588MH0vquvvlqzZs3SCSecMEAVAAAAGD34//J5Ki0t1a9//euc+y655JKs9xUVFfrpT3/ao93SpUu1dOnSHtsze4sl6ayzztKGDRvS7++66y5JUnFxsb773e/qu9/9bo9zPPvss7rhhhv6vA8AAAD0jZA8Apx22mkqLy/Xd77znUJfCgAAwIhASB4B1q5dW+hLAAAAGFEYkwwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIXmAVFRU9LqvublZJ5100iBeDQAAAMIgJAMAAAABw3Ke5G/+8Zt6/d3X+/WccybM0Wfe/5le999+++2aPXu2PvOZZJs777xTZqbVq1dr9+7d6uzs1N13360lS5aE+tyDBw/q05/+tF544YX0inqLFi3SK6+8ouuuu06xWEyJREKPPvqopk+fro997GNqaWlRPB7XV7/61fRS2AAAAOg/wzIkF8KyZcv02c9+Nh2SH374YT3xxBO67bbbVFVVpZ07d+rMM8/U5ZdfLjPL+7z33nuvJGn9+vV6/fXXtXjxYm3YsEHLly/XX//1X+vqq69WLBZTPB7XqlWrNH36dP3qV7+SJLW2tvb/jQIAAGB4huTbF9w+IOdta2vrdd8pp5yi7du3a8uWLdqxY4fGjx+vadOm6bbbbtPq1atVVFSkzZs3a9u2bZo6dWren/nss8/qlltukSTNmTNHs2fP1oYNG3TWWWfp61//ulpaWvSRj3xExx13nObOnavPf/7zuv3223XppZfq3HPPPep7BgAAQE+MSQ5h6dKleuSRR/TQQw9p2bJleuCBB7Rjxw6tXbtW69atU01NjQ4ePBjqnO6ec/snPvEJPf744xozZowuuugi/fa3v9Xxxx+vtWvXau7cubrjjjv0d3/3d/1xWwAAAAgYlj3JhbJs2TLdcMMN2rlzp5555hk9/PDDmjJlikpKSvT0009r06ZNoc+5cOFCPfDAAzr//PO1YcMGvfXWW3rf+96njRs36thjj9Wtt96qjRs36qWXXtKcOXM0YcIE/cVf/IUqKir0k5/8pP9vEgAAAITkME488US1tbVpxowZmjZtmq6++mpddtllqq+v18knn6w5c+aEPudnPvMZ3XTTTZo7d66Ki4v1k5/8RKWlpXrooYf0s5/9TCUlJZo6daq+9rWvac2aNfrCF76goqIilZSU6Ic//OEA3CUAAAAIySGtX78+/XrSpEl67rnncrZrb2/v9Ry1tbV6+eWXJUllZWU5e4TvuOMO3XHHHVnbLrroIl100UVHcNUAAAAIgzHJAAAAQAA9yQNo/fr1uuaaa7K2lZaW6g9/+EOBrggAAAD5yCskm9nFkr4vKSLpR+7+jcD+Bkm/kNSU2vRzd/+71L5mSW2S4pK63L2+Py58OJg7d67WrVtX6MsAAABASH2GZDOLSLpX0oWSWiStMbPH3f3VQNPfufulvZxmkbvvPLpLBQAAAAZHPmOSF0h60903untM0kpJ4dZeBgAAAIYR620xi3QDs6WSLnb361Pvr5F0hrvfnNGmQdKjSvY0b5H0eXd/JbWvSdJuSS7pX9x9RS+fc6OkGyWppqbmtJUrV2btr66u1nvf+97wdxhCPB5XJBIZ0M8YSf785z9r7969hb6MYaO9vV0VFRWFvoxhg3qFQ73CoV7hUbNwqFc4harXokWL1vY2FDifMcmWY1swWf9J0mx3bzezD0n6d0nHpfad4+5bzGyKpN+Y2evuvrrHCZPheYUk1dfXe0NDQ9b+1157TZWVlXlc7pFra2sb8M8YScxMwX9O6F1jYyP1CoF6hUO9wqFe4VGzcKhXOEOxXvkMt2iRNCvj/Uwle4vT3H2vu7enXq+SVGJmk1Lvt6T+3C7pMSWHb4x4/NcjAADA8JVPSF4j6TgzqzOzqKRlkh7PbGBmU83MUq8XpM67y8zKzawytb1c0mJJL/fnDeDwurq6Cn0JAAAAw06fwy3cvcvMbpb0pJJTwN3n7q+Y2U2p/cslLZX0aTPrknRA0jJ3dzOrkfRYKj8XS3rQ3Z842ot+5+//Xh2vvX60p8lS+v45Kr/lll7333777Zo9e7Y+85nPSJLuvPNOmZlWr16t3bt3q7OzU3fffbeWLOn7mcb29nYtWbIk53H333+/vv3tb8vMNG/ePP3bv/2btm3bpptuukkbN26UJP3whz/U9OnTdemll6ZX7vv2t7+t9vZ23XnnnWpoaNDZZ5+t3//+97r88st1/PHH6+6771YsFtPEiRP1wAMPqKamRu3t7brlllv0wgsvyMz0t3/7t9qzZ49efvllfe9735Mk/eu//qtee+01ffe73z2q+gIAAAwnec2TnBpCsSqwbXnG6x9I+kGO4zZKmn+U1zgkLFu2TJ/97GfTIfnhhx/WE088odtuu01VVVXauXOnzjzzTF1++eVK/UdBr8rKyvTYY4/1OO7VV1/V17/+df3+97/XpEmT9O6770qSbr31Vp133nl67LHHFI/H1d7ert27dx/2M/bs2aNnnnlGkrR79249//zzMjP96Ec/0re+9S195zvf0V133aXq6ur0Utu7d+9WNBrVvHnz9K1vfUslJSX68Y9/rH/5l3852vIBAAAMK8Nyxb2pX/rSgJy3ra2t132nnHKKtm/fri1btmjHjh0aP368pk2bpttuu02rV69WUVGRNm/erG3btmnq1KmH/Rx315e+9KUex/32t7/V0qVLNWnSJEnShAkTJEm//e1vdf/990uSIpGIqqur+wzJV111Vfp1S0uLrrrqKm3dulWxWEx1dXWSpKeeekqZs4iMHz9eknT++efrl7/8pd7//vers7NTc+fOPexnAQAAjDTDMiQXytKlS/XII4/onXfe0bJly/TAAw9ox44dWrt2rUpKSlRbW6uDBw/2eZ7ejnP3PnuhDykuLlYikUi/D35ueXl5+vUtt9yiz33uc7r88svV2NioO++8U5J6/bzrr79ef//3f685c+bouuuuy+t6AAAARpJ8HtxDyrJly7Ry5Uo98sgjWrp0qVpbWzVlyhSVlJTo6aef1qZNm/I6T2/HXXDBBXr44Ye1a9cuSUoPt7jgggv0wx/+UFJyLue9e/eqpqZG27dv165du9TR0aFf/vKXh/28GTNmSJJ++tOfprcvXrxYP/hB9yiZQ73TZ5xxht5++209+OCD+vjHP55veQAAAEYMQnIIJ554otra2jRjxgxNmzZNV199tV544QXV19frgQce0Jw5c/I6T2/HnXjiifryl7+s8847T/Pnz9fnPvc5SdL3v/99Pf3005o7d65OO+00vfLKKyopKdHXvvY1nXHGGbr00ksP+9l33nmnrrzySp177rnpoRyS9JWvfEW7d+/WSSedpPnz5+vpp59O7/vYxz6mc845Jz0EAwAAYDRhuEVIhx5yk6RJkybpueeey9muvb2913Mc7rhrr71W1157bda2mpoa/eIXv+jR9tZbb9Wtt97aY3tjY2PW+yVLluScdaOioiKrZznTs88+q9tuu623WwAAABjRCMnIsmfPHi1YsEDz58/XBRdcUOjLAQAAw5zHYorv3at4a6virXsVb92jROb7vXsVra6ShtiKe4TkAbR+/Xpdc801WdtKS0v1hz/8oUBX1Ldx48Zpw4YNhb4MAAAwhHg8rkRbWx9ht1Xx1lYlWlPbUvv8wIHDnruoslLFF144SHeSP0LyAJo7d67WrVtX6MsAAACQu8v37+8OsHtau4Nt+n0y7CbSQTi5LdHWJrn3em4bM0aRqipFqqsVqapSyaxZKku9joyrVlF6X7Ui1cnXRVVVilRVySKRHkNFh4JhFZLDTJGGgeWH+RcFAAAMnEQslgqx2WE3kTF8IbmvVYk9rRnv90pdXb2fuLg4HXIjVVWKTJqo6LHHdm87FHarqhUZV50OxUXV1SqKRgevAINk2ITksrIy7dq1SxMnTiQoF5i7a9euXYrH44W+FAAAhiWPx5M9tFnDF3KH3axA3NoqP9yaDGYqqqzsDrbVVSqePi3Vgxvsxc0OuzZ2LBkrw7AJyTNnzlRLS4t27NgxYJ9x8OBBlZWVDdj5R5KysjLt27ev0JcBAEDBuLsS+/YlQ2xgrO7Y/16n7WvXZoTdPVljdROHWeVXkmzs2OzhC7OPSQ1fCIbd7teRqioVVVbKIpFBqsDINmxCcklJSXo55YHS2NioU045ZUA/YyTJd/EUAACGskRHh+J7WpXY2zPsBsfqBh9MUy//V7VS0q6SkqzhC8WTJyv63vcoUj2uOwBXV6koMFY3UlUlG4HDF4abYROSAQAAeuNdXYq3teUcq5sOtntzDGlobZV3dPR+YrOMh86SYTc6Y0Zq27hex+r+/qWXdN7ixQxfGMYIyQAAYEhwdyXa2xVv3Zvs1e1jrG7mg2mJwyziJUlFY8cme2xTYTdaW5vRg9v7WN2iykpZ0REsUPzGGwTkYY6QDAAA+lXi4MFUwG0N92BaW1uvwxckyUpKVDSuO9iWTKlR5Ljjeg+7h0JxZSXDFxAaIRkAAPTgXV3pIQuJva2KvvyyWtvaehmrm/1gmsdivZ+4qEiRysrusFtVpejMmSqqzpxHN/eDaVZWRu8sBg0hGQCAEcoTieTwhcwe28xwm14xLXOFtGTYTQRmMBovaUvG+6Ly8lSwTY7LLa07NmPRiO6xupGqqmTQPfS6ouLIhi8Ag4yQDADAEObu8vTwhdxjdXM+mLYnNXwhkej13BaNphaDSAbbkqlTVXb88dlhN9WL++Kbb6q+YVEy7FZWykpKBrEKwOAjJAMAMAi8szNjerH8xuoeCrve2dn7iYuKslY+i4wbp+gxxwSmFss9VrcoxNoAnYmESo8d2KlYgaGEkAwAQJ48kVCirS17KeA8H0xL7N9/2HMXVVQkhyOkxuqWvuc9OebR7TlWt6i8nOELwAAgJAMARhV3lzo61Ll1a8+e3cOO1U22kXuv57bS0qxgWzJ9usrmzMkY0lCdPb1YVZUi48Ylhy8U81cyMJTwbyQAYFjyWCx7dbTAAhFZMy7szQ67NZ2derO3E0ciGcMXqhSZMF7R2trsRSMyxuqmH0yrrgo1fAHA0EZIBgAUjMfj3cMXQj2Ytlfe1/CFysqssFs65bh0L2/zzl067pSTe4bd6urk8AWmGQNGPUIyAOCouLt8//4eSwHnNVa3re3wwxfKyrqXA66uVsnMmSo74YTex+qmgm5fwxdebWzU+IaGAagGgJGCkAwAkCQlYrHulc96HaubvRTwoW3q6ur9xMXF6ZAbqapSZNJERY89tntbZtjNHKtbXa2i0tLBKwAAZCAkA8AI4vG44nv3Zvfi7s0ddhOZYXjvXvmBA4c9d1FVVVawLZ4+Lb1iWvdY3WDYrVZR+ViGLwAYdgjJADCMeDyuzq1bFWtqUqypWbHmJnU0NWnin9/UGx0dyeELh2FjxmQPXzhmlsqqTsoxj+649PCFSHW1iiorZZHIIN0lABQeIRkAhqB4a6tiTU3qaG5OhuGmpuTPpk3yWCzdrqiyUtG6OnXW1Wry++YcNuwWVVerKBot4F0BwPBBSAaAAvHOTsXeflux5mQI7jjUO9zUpPi773Y3LC5WdOZMRevqVH7uuYrWzlZpXZ2idXWKTJwoM9OmxkadyoNoANBvCMkAMIDcXfFdu3qE4FhTk2ItLVI8nm4bmThR0bpaVV5wvqK1tYrW1SlaW6forJmykpIC3gUAjD6EZADoB4mDBxXbtCkdgNOBuLk5a5ywlZYqOnu2St/3PlVefLGidbXdvcJVVQW8AwBAJkIyAOTJEwl1vfNOjx7hjuYmdW3ZmtW2eNo0RWtnq/qyS5O9wakgXDJ9mqyoqEB3AADIFyEZAALi7e05e4Rjzc3ygwfT7YrGjlW0rk5jTz1N0Y929whHZ89W0dixBbwDAMDRIiQDGJW8q0udLS3ZvcLNzepoblJ8x87uhkVFKpk5U9G6WpWfcUa6RzhaV6viyZOZ/xcARihCMoARy90V3727+0G55mZ1HArEb78tdXam20bGjVO0rk4V5y7MGidcMmsW06YBwChESAYw7CU6OlIPzTWnp1M7NMdworU13c5KSlQy+xiVvudYVV5wQbpHOFpbq+Lx4wt4BwCAoYaQDGBYcHd1bduW0SPcPUyic/NmyT3dtnjKFEXr6lR1ycXJHuHUdGolM2awahwAIC+EZABDSmLfPnU0N6tszRrtWP9yevaIWPMm+f796XY2dqyitbM1Zt48VS9ZkjGvcK0iFeUFvAMAwEhASAYw6DweV+eWLT1nkGhqUtf27ZKkakk7zVQyY0ZyBon6ekVru8cKF9fU8NAcAGDAEJIBDJj4nj2B2SOSgbhz01vyjIfmiqqrVVpbq/KzzkrPHvHizh06Z+lSFZWWFvAOAACjFSEZwFHxWEyxt9/OuexyfM+e7obFxYrOmpWcQeK887rnFK6rU2T8+B69wvHGRgIyAKBgCMkA+uTu6tqxo8cqc7HmZnW2bJbi8XTbyKRJKq2tVeWFF6Znjyitq1PJzJmyYr5yAADDA39jAUhLHDiQnkIta6W5piYl9u1Lt7OyMkVnz1bZ+09Q1Yc+1N0rXFurSGVlAe8AAID+QUgGRhlPJNS5ZWvGAhvdi2x0bd2a1bZ4+jSV1tap+sMfzuoVLp46VVZUVKA7AABg4BGSgREqvndvd49wc3P3UIlNm+QdHel2RRUVydkjTq/P6hGOzp6tojFjCngHAAAUTl4h2cwulvR9SRFJP3L3bwT2N0j6haSm1Kafu/vf5XMsgCPnnZ2Kvd2S7A1uak7PHhFralZ8167uhpGIojNnKlpXp/JzzknNKZzsFY5MmsRUagAABPQZks0sIuleSRdKapG0xswed/dXA01/5+6XHuGxAHrh7orv2pVeZjnz4blYS4vU1ZVuG5kwITl7xKIGlR5aXKOuTtGZM2XRaOFuAgCAYSafnuQFkt50942SZGYrJS2RlE/QPZpjgVElcfCgYpve6h4n3NSkjlQgTrS1pdtZNKro7NkqPf54VS5erGhdnUrrkoE4Ul1dwDsAAGDkyCckz5D0dsb7Fkln5Gh3lpm9KGmLpM+7+yshjgVGBU8k1LVtW845hTu3bpXc022Lp05VtLZWVZf+j6w5hUumTZNFIgW8CwAARj7zjL+UczYwu1LSRe5+fer9NZIWuPstGW2qJCXcvd3MPiTp++5+XD7HZpzjRkk3SlJNTc1pK1eu7J87DKG9vV0VFRWD/rnDFfXqnR04oMj27Sp+Z5si27apeNs22dYtiu7cJYvF0u0SpaWK10xRV02N4jU1qT+nKj5lsrysrIB3UHj8foVDvcKhXuFRs3CoVziFqteiRYvWunt9rn359CS3SJqV8X6mkr3Fae6+N+P1KjP7ZzOblM+xGcetkLRCkurr672hoSGPS+tfjY2NKsTnDlejvV7e1aXOzZt79Ah3NDcpvmNnd8OiIpXMmKH28RM08dACG7XJXuHiKZN5aK4Xo/33KyzqFQ71Co+ahUO9whmK9conJK+RdJyZ1UnaLGmZpE9kNjCzqZK2ubub2QJJRZJ2SdrT17HAUNe1e3f3g3KHxgk3Nyv21ltSZ2e6XaS6OvnQ3AfOzV5p7phjVBSNqrGxUScPsS8AAACQW58h2d27zOxmSU8qOY3bfe7+ipndlNq/XNJSSZ82sy5JByQt8+Q4jpzHDtC9AEcsEYupc9OmHqvMxZqaFG9t7W5YUqLoMccoWleryvMXpXuEo3W1Kh4/vnA3AAAA+lVe8yS7+ypJqwLblme8/oGkH+R7LFAI7q6u7dszVpprTofizs2bpUQi3bZ48mRF6+pUefHF6R7haG2tSmbMkBWzBg8AACMdf9tjxEns29c9n3BGj3CsuVmJ/fvT7WzMGEVrazVm7kmqvuwyRetqUz3DtYrwsAUAAKMaIRnDksfj6tyyJR2CMx+e69q2rbuhmUqmT1e0rk7Vp57a3StcV6fimhpZUVHhbgIAAAxZhGQMafHW1qxFNdILbWx6S54xlVpRZWVyyeUzz8iaPSI6+xgVjfKp1AAAQHiEZBScx2KKtbRkzB7R3Ssc3727u2FxsaKzZilaW6vycxdm9QpHJkxgKjUAANBvCMkYFO6u+M6dOecU7mzZLMXj6baRiROTs0d88IKs2SOiM2fKSkoKeBcAAGC0ICSjXyUOHFBs06aeyy43NyvR3p5uZ6Wlis6erbI571fVJZd0L7tcW6tIVVUB7wAAAICQjCPgiYS6tm5V9NVX9e7bLelxwh3NzerasjWrbfG0aSqtq1X15ZeneoRTU6lNn8ZDcwAAYMgiJKNX8ba2nuOEm5sV27RJfvCgxkvaJqmovFzRujqNPa1e0aXdcwpHZ89W0dixhb4NAACA0AjJo5x3dqYemuseFpEcK9ys+M6d3Q0jEZXMnKHS2jqVn3WWorW1erW1VQuu+LCKJ0/moTkAADCiEJJHAXdX/N13e6wyF2tqUuztt6WurnTbyPjxitbVqeK8hYrWds8eEZ01SxaNZp23s7FRJVOmDPbtAAAADDhC8giS6OhQrHlT1ipzHc3JQJzYuzfdzkpKFK2drdL3vleVH/xgevaI0ro6RcaNK9wNAAAADBGE5GHG3dX1zjs9e4SbmtS5ZYvknm5bXFOjaG2tqj6UMXtEXZ1Kpk+XRSIFvAsAAIChjZA8RMXb92X1CMeaU6vONTfLDxxIt7OxYxWtna0x8+er+sMf7u4Vrq1VUXl5Ae8AAABg+CIkF5DH4+rcvLnnnMJNTerasaO7oZlKZsxIziBxen1Wr3DxlCk8NAcAANDPCMmDoGv37ozZI7oDcedbb8k7O9PtiqqrVVpbq/JzzskaJ1xyzDEqKi0t4B0AAACMLoTkfpKIxdT51ls9eoRjzc2K79nT3bCkRNFZsxStq1PlooasBTYi48fTKwwAADAEEJJDcHd1bd+R7hE+NJ9wrKlZnS0tUiKRbhuZPEmltXWqXLw4FYJnJ3uFZ86UFVN2AACAoYy0lkNi//7s2SOauxfaSOzbl25nZWWK1taq7MQTVH3p/0iuMneoV7iysoB3AAAAgKNBSE7ZuXy5xj3xhP585/9S1zvvdO8wU8m0aYrW1an6iitSQTg5Vrh46lRZUVHhLhoAAAADgpCcEmtqUtGBgxq74PSs2SOis2erqKys0JcHAACAQURITpn+zW9qQ2Oj5jU0FPpSAAAAUGCMFQAAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABCQV0g2s4vN7A0ze9PMvniYdqebWdzMlmZsazaz9Wa2zsxe6I+LBgAAAAZScV8NzCwi6V5JF0pqkbTGzB5391dztPumpCdznGaRu+/sh+sFAAAABlw+PckLJL3p7hvdPSZppaQlOdrdIulRSdv78foAAACAQZdPSJ4h6e2M9y2pbWlmNkPSFZKW5zjeJf2Hma01sxuP9EIBAACAwWLufvgGZldKusjdr0+9v0bSAne/JaPN/yvpO+7+vJn9RNIv3f2R1L7p7r7FzKZI+o2kW9x9dY7PuVHSjZJUU1Nz2sqVK/vlBsNob29XRUXFoH/ucEW9wqFe4VCvcKhXONQrPGoWDvUKp1D1WrRo0Vp3r8+1r88xyUr2HM/KeD9T0pZAm3pJK81MkiZJ+pCZdbn7v7v7Fkly9+1m9piSwzd6hGR3XyFphSTV19d7Q0NDHpfWvxobG1WIzx2uqFc41Csc6hUO9QqHeoVHzcKhXuEMxXrlM9xijaTjzKzOzKKSlkl6PLOBu9e5e62710p6RNJn3P3fzazczColyczKJS2W9HK/3gEAAADQz/rsSXb3LjO7WclZKyKS7nP3V8zsptT+XOOQD6mR9Fiqh7lY0oPu/sTRXzYAAAAwcPIZbiF3XyVpVWBbznDs7p/KeL1R0vyjuD4AAABg0LHiHgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAooLfQEAAAAYodylg63Svp3Svh29/OzU1LLTJDUU+mqzEJIBAACQv66YtH+n1L69z/CrfTukeCz3ecaMl8onS+WT5RYZ3HvIAyEZAABgNHOXDu5Jhtr27T1D7r5AGD7Ymvs8kVKpYopUPkmqqJFqTkq+Lp+SCsOT0qFY5ZOkSEn60G2NjXr/4Nxt3gjJAAAAI01XR3bYPWz43SklOnOfZ8yEVPCdLE2dmxFyJ2cH3vLJUmmlZDa49zmA8grJZnaxpO9Likj6kbt/o5d2p0t6XtJV7v5ImGMBAADQi0Qi1du7I4/wu0Pq2Jv7PMVlqZ7dSVLVDGna/F6C72Rp7EQpMnr7U/u8czOLSLpX0oWSWiStMbPH3f3VHO2+KenJsMcCAACMOp0HcgfcrPCb2r5/p5ToynESS4bZQz260+Z3D3nIFXyj5SOqt3cg5fOfBwskvenuGyXJzFZKWiIpGHRvkfSopNOP4FgAAIDhLZGQDuyW9u3QuN0vSS/vyg6/7YFe4Fhb7vOUlHeH3OqZ0vSTu4c8ZI3tnSKNnSAVDb2H3kYCc/fDNzBbKulid78+9f4aSWe4+80ZbWZIelDS+ZL+t6Rfuvsj+RybcY4bJd0oSTU1NaetXLmyP+4vlPb2dlVUVAz65w5X1Csc6hUO9QqHeoVDvcIbrTUrincoGtujks5WRWOtKuncE/izVdHYodd7ZUr0OIerSJ0llYpFx6mzpDrjz+zXnSXjFItWKxEpK8CdFlahfr8WLVq01t3rc+3Lpyc5V598MFn/P5Jud/e4ZXfh53NscqP7CkkrJKm+vt4bGhryuLT+1djYqEJ87nBFvcKhXuFQr3CoVzjUK7wRU7NEXNr/bo6pyrb3HPbQvkPq3Jf7PNGK7pkbppyk4MwN697copPPuVAqnywbM17Rooiig3unw8pQ/P3KJyS3SJqV8X6mpC2BNvWSVqYC8iRJHzKzrjyPBQAAOHKxffnP2bt/l+Q9e3tlkYygO0kaX9dz2rKKQw+0TZKiYw97SXt2NUpThtqkZggjn5C8RtJxZlYnabOkZZI+kdnA3esOvTaznyg53OLfzay4r2MBAACyxLukA6ne3nzCb+f+3OcpreoOuROOlWad0XNc76GxvmXjpKKiQb1NDG19hmR37zKzm5WctSIi6T53f8XMbkrtXx722P65dAAAMCy4S7H27B7dw4Xf/e8q5+jMouLsgDvxvb3P2Vs+WSoZfWN70X/ymvzO3VdJWhXYljMcu/un+joWAAAMc/HO5NCF4HCGHuE3Nd6362Du85RWdw9jmHScNPvs3hesoLcXg2j0zhANAAC6uUsdbbmHM7Rv1wnNr0pN93RvP/Bu7vMUlXSH2oop0uT3BR5qy5zDd5JUXDq49wnkiZAMAMBIFe/MsQTxYRasiHfkPk/ZOFVYuTRmdjL01p3bc2jDofBbVs1iFRgRCMkAAAwX7tLB1kDYPUz4Pbgn93ki0ewe3SkndA956LFYxUSpOKo/DsEpuoCBREgGAKCQujoyQm5mr2+OpYr37ZDisdznGTOhO+TWnNhz2rLMAFxaRW8v0AdCMgAA/ck92YPbnmNsb67we7A193kipd3Tk1VMlWrmBqYtyxjqMHaiFCkZ1NsERjpCMgAAfek8KO0/NHtDHuE30ZXjJCaNzejtnTqvlzl7U6+jFfT2AgVESAYAjD6e6Lk0ca/hd6fUsTf3eYrHdA9nqJohTTu559CGQ73BYyZIEf7aBYYL/m0FAIwMnQfynrP3vPYd0jO5liYuSg5dOBRwp5/S+5y9FVOkaPng3yeAQUFIBgAMTYmEdGB3xlCGPsJvrC33eUrKu3t7x82SZpyit3bu1+wTTg9MYTY5ORyiKDK49wlgSCIkAwAGT2x/jnG8vYTf/TuTwyKCrEgae2gM72RpfH3PacvS7yfl7O1tamzU7DMbBv5+AQxbhGQAwJFLxHuO7e0xrjcj/Hbuy32eaGV3yJ1QJ806PfecveWTpTHjWZoYwIAjJAMAsnW055ijt5cFK/bvkuQ9z2GR7JA7q67ntGXlk7oXtCgZM+i3CQCHQ0gGgJEu3iUdeLfnEsS9hd/O/bnPU1qd0dt7rDTrjO6ZG4Jje8vG0dsLYFgjJAPAcNTVkQy97dul9m2atuV30jNrcg952P+ucvb2FhVnB9uJxwXm680Iv2MnSSVlg36bAFAohGQAGCoSiVSP77bUTzIAq21bz20H92Qd+j5J2iCprLp7/O6k46XZ5+RYrCL1vmwci1UAQC8IyQAw0DrausNtZtDNep3qFfZ4z+NLxkoVNcmfKXOkY89Lht1D2yqm6LmX/q/O+uDlUnF08O8PAEYgQjIAHImuWGrWhmDQzRF+c83oUFSc7O2tmCJVTE0uUZwRerP+LK3o83I6NrQSkAGgHxGSAeAQ9+TiFbl6fNsC2w68m/scY8Z3B9yZ9blDb0VNcoliHmwDgCGLkAxg5Ivty3+4Q6Kz5/HFZd3hduJ7pNlnd4feyqnd4bd8slRcOvj3BwDod4RkAMNTvCvHcIdcQx+2516u2Iq6H2SrqJGmnJi7x7diilRayQNuADDKEJIBDB3uyVkb2rdr3O6XpPU7e5/pobdFLMqquwPu9JN7H+4wdqJUFBnkGwQADBeEZAADr/NA1py+an8nd49v+zYpHpMknSxJL6aOj5R2h9zxtdKsBbl7fCumsHIbAKBfEJIBHJlEPLU0cR7DHTpac5zAknP1Hgq4k47PCr3r3tyqkz9wUXJbWTXDHQAAg4qQDKCbu9Sxt4/Qu617eWNP9DxHtLI77E49qZce35rkCm6R3r+C9uxqlCYfP3D3CgDAYRCSgdEgsIRx9k8g/HYd7Hl8UUl3wK2aKU0/tffhDtHywb8/AAD6GSEZGK4OLWHc9k7fC1oEljBOGzuxO+Aec1buHt+KmuTcvwx3AACMIoRkYChxl2Lt/beE8eT3SXULe5/TN1Iy+PcIAMAwQEgGBkNXTKUHd0qb/9RLj29GCO7c3/N4i3QPZ6ioOeoljAEAwOERkoEjFVzCuC3XON/uJYzPkqTnA+fIWsL4dJYwBgBgiCAkA0GxfX2P8T2CJYzf2LJH7zv13OyH3FjCGACAIYmQjNEh7yWMtyXHBAf1WML4hMBDbn0vYby1sVHvm9Mw8PcKAACOGiEZw1fGEsbZyxbnWM2ttyWMS6u7wy5LGAMAgBRCMoaezgP5reKWsYRxlkhUqpjKEsYAAOCIEZIxOAZ4CeOs3t+ycczpCwAAjgohGUfOXTrYmjv0tgXe79/Z9xLGNSdK7zk/Yz7f/JcwBgAA6E+kDvSUtYRx76u5nbv3HemZHMMdioq7A271DGkGSxgDAIDhhZA8WiQSyYfXDjerQ8gljDfv7tAx76/vGYDLxjGnLwAAGNYIycNZvksYt21LTn8Wdgnj4J+BJYw3NjbqmLMbBudeAQAABhEheSjqivUyp2+OXuC8ljCem3s+X5YwBgAAyImQPFgSiewljA83w8OBd3Ofo2wcSxgDAAAMAkLy0RqgJYxzPuTGEsYAAACDgpCcS69LGOcIv6GXMA4sZdzLEsYAAAAoHELyIav+RvWvPCH9cV9+SxhPO7k79FZOZQljAACAEYSQfEhxVAfLalRReyJLGAMAAIxyhORDFt+tl6ONamhoKPSVAAAAoMDymgLBzC42szfM7E0z+2KO/UvM7CUzW2dmL5jZBzL2NZvZ+kP7+vPiAQAAgIHQZ0+ymUUk3SvpQkktktaY2ePu/mpGs/+U9Li7u5nNk/SwpDkZ+xe5+85+vG4AAABgwOTTk7xA0pvuvtHdY5JWSlqS2cDd29390JNu5cr51BsAAAAwPOQTkmdIejvjfUtqWxYzu8LMXpf0K0n/M2OXS/oPM1trZjcezcUCAAAAg8G6O4B7aWB2paSL3P361PtrJC1w91t6ab9Q0tfc/YOp99PdfYuZTZH0G0m3uPvqHMfdKOlGSaqpqTlt5cqVR3FbR6a9vV0VFSzTnC/qFQ71Cod6hUO9wqFe4VGzcKhXOIWq16JFi9a6e32uffnMbtEiaVbG+5mStvTW2N1Xm9l7zGySu+909y2p7dvN7DElh2/0CMnuvkLSCkmqr6/3Qswy0djI7BZhUK9wqFc41Csc6hUO9QqPmoVDvcIZivXKZ7jFGknHmVmdmUUlLZP0eGYDM3uvWXLZODM7VVJU0i4zKzezytT2ckmLJb3cnzcAAAAA9Lc+e5LdvcvMbpb0pKSIpPvc/RUzuym1f7mkj0r6pJl1Sjog6arUTBc1kh5L5ediSQ+6+xMDdC8AAABAv8hrMRF3XyVpVWDb8ozX35T0zRzHbZQ0/yivEQAAABhUeS0mAgAAAIwmhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQkFdINrOLzewNM3vTzL6YY/8SM3vJzNaZ2Qtm9oF8jwUAAACGmj5DsplFJN0r6RJJJ0j6uJmdEGj2n5Lmu/vJkv6npB+FOBYAAAAYUvLpSV4g6U133+juMUkrJS3JbODu7e7uqbflkjzfYwEAAIChJp+QPEPS2xnvW1LbspjZFWb2uqRfKdmbnPexAAAAwFBi3R3AvTQwu1LSRe5+fer9NZIWuPstvbRfKOlr7v7BMMea2Y2SbpSkmpqa01auXHkUt3Vk2tvbVVFRMeifO1xRr3CoVzjUKxzqFQ71Co+ahUO9wilUvRYtWrTW3etz7SvO4/gWSbMy3s+UtKW3xu6+2szeY2aTwhzr7iskrZCk+vp6b2hoyOPS+ldjY6MK8bnDFfUKh3qFQ73CoV7hUK/wqFk41CucoVivfIZbrJF0nJnVmVlU0jJJj2c2MLP3mpmlXp8qKSppVz7HAgAAAENNnz3J7t5lZjdLelJSRNJ97v6Kmd2U2r9c0kclfdLMOiUdkHRV6kG+nMcO0L0AAAAA/SKf4RZy91WSVgW2Lc94/U1J38z3WAAAAGAoY8U9AAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEBAXiHZzC42szfM7E0z+2KO/Veb2Uupn/8ys/kZ+5rNbL2ZrTOzF/rz4gEAAICBUNxXAzOLSLpX0oWSWiStMbPH3f3VjGZNks5z991mdomkFZLOyNi/yN139uN1AwAAAAMmn57kBZLedPeN7h6TtFLSkswG7v5f7r479fZ5STP79zIBAACAwWPufvgGZkslXezu16feXyPpDHe/uZf2n5c0J6N9k6TdklzSv7j7il6Ou1HSjZJUU1Nz2sqVK4/sjo5Ce3u7KioqBv1zhyvqFQ71Cod6hUO9wqFe4VGzcKhXOIWq16JFi9a6e32ufX0Ot5BkObblTNZmtkjSX0r6QMbmc9x9i5lNkfQbM3vd3Vf3OGEyPK+QpPr6em9oaMjj0vpXY2OjCvG5wxX1Cod6hUO9wqFe4VCv8KhZONQrnKFYr3yGW7RImpXxfqakLcFGZjZP0o8kLXH3XYe2u/uW1J/bJT2m5PANAAAAYMjKJySvkXScmdWZWVTSMkmPZzYws2Mk/VzSNe6+IWN7uZlVHnotabGkl/vr4gEAAICB0OdwC3fvMrObJT0pKSLpPnd/xcxuSu1fLulrkiZK+mczk6Su1PiOGkmPpbYVS3rQ3Z8YkDsBAAAA+kk+Y5Ll7qskrQpsW57x+npJ1+c4bqOk+cHtAAAAwFDGinsAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABBCSAQAAgABCMgAAABBASAYAAAACCMkAAABAACEZAAAACCAkAwAAAAGEZAAAACCAkAwAAAAEEJIBAACAAEIyAAAAEEBIBgAAAAIIyQAAAEAAIRkAAAAIICQDAAAAAYRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAggJAMAAAABhGQAAAAggJAMAAAABOQVks3sYjN7w8zeNLMv5th/tZm9lPr5LzObn++xAAAAwFDTZ0g2s4ikeyVdIukESR83sxMCzZoknefu8yTdJWlFiGMBAACAISWfnuQFkt50943uHpO0UtKSzAbu/l/uvjv19nlJM/M9FgAAABhq8gnJMyS9nfG+JbWtN38p6ddHeCwAAABQcMV5tLEc2zxnQ7NFSobkDxzBsTdKujH1tt3M3sjj2vrbJEk7C/C5wxX1Cod6hUO9wqFe4VCv8KhZONQrnELVa3ZvO/IJyS2SZmW8nylpS7CRmc2T9CNJl7j7rjDHSpK7r1BqLHOhmNkL7l5fyGsYTqhXONQrHOoVDvUKh3qFR83CoV7hDMV65TPcYo2k48yszsyikpZJejyzgZkdI+nnkq5x9w1hjgUAAACGmj57kt29y8xulvSkpIik+9z9FTO7KbV/uaSvSZoo6Z/NTJK63L2+t2MH6F4AAACAfpHPcAu5+ypJqwLblme8vl7S9fkeO4QVdLjHMES9wqFe4VCvcKhXONQrPGoWDvUKZ8jVy9xzPkcHAAAAjFosSw0AAAAEjIqQnMey2mZm/5ja/5KZnZrvsSPVUS5F3mxm681snZm9MLhXXhh51KvBzFpTNVlnZl/L99iRKI96fSGjVi+bWdzMJqT2jarfLzO7z8y2m9nLvezn+ytDHvXiuytDHvXiuysgj5rx/ZViZrPM7Gkze83MXjGzv87RZuh+h7n7iP5R8oHB/yvpWElRSS9KOiHQ5kNKLoBiks6U9Id8jx2JP3nW7GxJ41OvLzlUs9T7ZkmTCn0fQ6xeDZJ+eSTHjrSfsPcs6TJJvx3Fv18LJZ0q6eVe9vP9Fa5efHeFqxffXSFrFmg72r+/pkk6NfW6UtKG4ZTBRkNPcj5LYy+RdL8nPS9pnJlNy/PYkeholiIfjY7m92Q0/o6FveePS/o/g3JlQ5C7r5b07mGa8P2Voa968d2VLY/fr96Myt8vKXTNRvv311Z3/1PqdZuk19Rz5eUh+x02GkJyPktj99ZmtC6rfTRLkUvJVRX/w8zWWnIlxZEu33qdZWYvmtmvzezEkMeOJHnfs5mNlXSxpEczNo+236++8P115Eb7d1e++O46Anx/ZTOzWkmnSPpDYNeQ/Q7Lawq4YS6fpbF7a5P3stojzNEsRS5J57j7FjObIuk3ZvZ66r+8R6p86vUnSbPdvd3MPiTp3yUdl+exI02Ye75M0u/dPbPXZrT9fvWF768jwHdX3vjuOnJ8f6WYWYWS/7HwWXffG9yd45Ah8R02GnqS81kau7c2eS+rPcKEXYp8iXcvRS5335L6c7ukx5T8XyYjWZ/1cve97t6eer1KUomZTcrn2BEozD0vU+B/VY7C36++8P0VEt9d+eO766jw/SXJzEqUDMgPuPvPczQZst9hoyEk57M09uOSPpl6wvJMSa3uvjXPY0eiI16K3MzKzazy0GtJiyXlfAJ4BMmnXlPNkstRmtkCJf/d25XPsSNQXvdsZtWSzpP0i4xto/H3qy98f4XAd1c4fHcdGb6/klK/O/9b0mvu/t1emg3Z77ARP9zC81tWe5WST1e+KWm/pOsOd2wBbmNQ5VmznEuRS6qR9FhqW7GkB939iQLcxqDJs15LJX3azLokHZC0zJOP746637E86yVJV0j6D3ffl3H4qPv9MrP/o+QMA5PMrEXS30oqkfj+yiWPevHdlSGPevHdFZBHzSS+vw45R9I1ktab2brUti9JOkYa+t9hrLgHAAAABIyG4RYAAABAKIRkAAAAIICQDAAAAAQQkgEAAIAAQjIAAAAQQEgGAAAAAgjJAAAAQAAhGQAAAAj4/wF96jwgHaGy7gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}