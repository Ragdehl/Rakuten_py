{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie sur les images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif à dépasser : weighted F1-score = 0.5534 (Resnet)\n",
    "avec CNN/Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\barry\\\\OneDrive - CSTBGroup\\\\image_ds\\\\images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer les données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_train_update.csv',index_col=0)\n",
    "y = pd.read_csv('Y_train_CVw08PX.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\barry\\\\OneDrive - CSTBGroup\\\\image_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Miscellaneous operating system interfaces\n",
    "#https://docs.python.org/3/library/os.html\n",
    "\n",
    "#get current working directory\n",
    "current_path = os.getcwd() \n",
    "\n",
    "#Training images path\n",
    "images_path = current_path + r'/images/image_train - Old/'\n",
    "\n",
    "#List with the name of all training images\n",
    "images_list = os.listdir(images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Géneration nom des images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        image_1263597046_product_3804725264.jpg\n",
       "1         image_1008141237_product_436067568.jpg\n",
       "2          image_938777978_product_201115110.jpg\n",
       "3           image_457047496_product_50418756.jpg\n",
       "4         image_1077757786_product_278535884.jpg\n",
       "                          ...                   \n",
       "84911      image_941495734_product_206719094.jpg\n",
       "84912    image_1188462883_product_3065095706.jpg\n",
       "84913     image_1009325617_product_440707564.jpg\n",
       "84914    image_1267353403_product_3942400296.jpg\n",
       "84915       image_684671297_product_57203227.jpg\n",
       "Name: image name, Length: 84916, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a column with the name of the picture\n",
    "X['image name'] = 'image_' + X['imageid'].map(str) + '_product_' + X['productid'].map(str) + '.jpg'\n",
    "X['image name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition des images dans les échantillons train, validation et test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 123)\n",
    "\n",
    "X_val = X_train.iloc[:2400,:]\n",
    "y_val = y_train.iloc[:2400,:]\n",
    "\n",
    "X_train = X_train.iloc[:21600,:]\n",
    "y_train = y_train.iloc[:21600:,:]\n",
    "\n",
    "X_test = X_test.iloc[:6000,:]\n",
    "y_test = y_test.iloc[:6000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"class\"] = y_train\n",
    "X_test[\"class\"] = y_test\n",
    "X_val[\"class\"] = y_val\n",
    "\n",
    "X_train[\"class\"] = X_train[\"class\"].astype('str')\n",
    "X_test[\"class\"] = X_test[\"class\"].astype('str')\n",
    "X_val[\"class\"] = X_val[\"class\"].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualité de la répartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "trainy = pd.DataFrame(y_train.value_counts(), columns = ['Nombre_images_train'])\n",
    "testy = pd.DataFrame(y_test.value_counts(), columns = ['Nombre_images_test'])\n",
    "train_test = trainy.merge(testy, right_index = True, left_index = True)\n",
    "train_test['y'] = train_test.index\n",
    "yval = []\n",
    "for i in train_test['y']:\n",
    "    yval.append(i[0])\n",
    "train_test['y'] = yval\n",
    "train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rescale = 1./255, \n",
    "        preprocessing_function = preprocess_input,  # data augmentation\n",
    "        rotation_range = 10,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        zoom_range = 1.1,\n",
    "        horizontal_flip = True\n",
    "        )\n",
    "\n",
    "val_data_generator = ImageDataGenerator(rescale = 1./255, \n",
    "        preprocessing_function = preprocess_input,  # data augmentation\n",
    "        rotation_range = 10,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1,\n",
    "        zoom_range = 1.1,\n",
    "        horizontal_flip = True\n",
    "        )\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale = 1./255, \n",
    "    preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21600 validated image filenames belonging to 27 classes.\n",
      "Found 2400 validated image filenames belonging to 27 classes.\n",
      "Found 6000 validated image filenames belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "path = os.chdir('C:\\\\Users\\\\barry\\\\OneDrive - CSTBGroup\\\\image_ds\\\\images\\\\image_train')\n",
    "X_train[\"class\"] = X_train[\"class\"].astype(str)\n",
    "X_test[\"class\"] = X_test[\"class\"].astype(str)\n",
    "X_val[\"class\"] = X_val[\"class\"].astype(str)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_dataframe(dataframe=X_train,\n",
    "                                                          directory=path,\n",
    "                                                           x_col = \"image name\",\n",
    "                                                           y_col = \"class\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                          target_size = (150,150), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "\n",
    "val_generator = val_data_generator.flow_from_dataframe(dataframe=X_val,\n",
    "                                                          directory=path,\n",
    "                                                           x_col = \"image name\",\n",
    "                                                           y_col = \"class\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                           target_size = (150, 150), \n",
    "                                                          batch_size = batch_size)\n",
    "\n",
    "test_generator = test_data_generator.flow_from_dataframe(dataframe=X_test,\n",
    "                                                          directory=path,\n",
    "                                                           x_col = \"image name\",\n",
    "                                                           y_col = \"class\",\n",
    "                                                           class_mode =\"sparse\",\n",
    "                                                           target_size = (150, 150), \n",
    "                                                          batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import layers\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(8**4, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(27, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barry\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "675/675 [==============================] - 1043s 2s/step - loss: 3.0212 - acc: 0.1325 - val_loss: 2.8496 - val_acc: 0.1675\n",
      "Epoch 2/2\n",
      "675/675 [==============================] - 1133s 2s/step - loss: 2.8766 - acc: 0.1686 - val_loss: 2.7997 - val_acc: 0.1879\n"
     ]
    }
   ],
   "source": [
    "epoch = 2\n",
    "\n",
    "inc_history = model.fit_generator(train_generator, \n",
    "                                epochs = epoch,\n",
    "                                steps_per_epoch = len(X_train)//batch_size,\n",
    "                                validation_data = val_generator,\n",
    "                                validation_steps = len(X_val)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement X derniers layers freezed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 3\n",
    "for layer in base_model.layers[-X:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "675/675 [==============================] - 1213s 2s/step - loss: 2.8331 - acc: 0.1848 - val_loss: 2.7777 - val_acc: 0.1825\n",
      "Epoch 2/2\n",
      "675/675 [==============================] - 1154s 2s/step - loss: 2.7909 - acc: 0.1972 - val_loss: 2.7388 - val_acc: 0.2208\n"
     ]
    }
   ],
   "source": [
    "inc_history_defreeze = model.fit(train_generator, \n",
    "                                epochs = epoch,\n",
    "                                steps_per_epoch = len(X_train)//batch_size,\n",
    "                                validation_data = val_generator,\n",
    "                                validation_steps = len(X_val)//batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barry\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 143s 739ms/step\n"
     ]
    }
   ],
   "source": [
    "y_inception_pred_2 = model.predict_generator(test_generator, verbose = 1)\n",
    "y_inception_pred_2 = y_inception_pred_2.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1_score : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19981439633302944"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_generator.classes, y_inception_pred_2, average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_epoch = []\n",
    "liste_score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2   3   4   5    6   7   8   9   ...  17  18  19   20  21  22  \\\n",
      "0   27   0   30   0   4   0    5   0   0   0  ...   0   0   0   13   0  34   \n",
      "1    2   1   11   0  21   0   29   0   0   0  ...   0   1   0   59   2   5   \n",
      "2    5   0  149   0   2   0    3   0   0   0  ...   0   0   0   10   0  17   \n",
      "3    0   0    4   0   3   0    6   0   0   0  ...   0   0   0   12   0   2   \n",
      "4    3   0   14   0  49   0   65   0   2   2  ...   0   1   0   94   0   8   \n",
      "5    0   0   10   0  18   0   16   0   0   1  ...   0   1   0   25   1  10   \n",
      "6    0   0    7   0  12   0  170   0   0   1  ...   0   0   0   85   2   3   \n",
      "7    0   0    1   0   2   0    9   0   1   1  ...   0   1   0   30   1   1   \n",
      "8    1   0    3   0  13   0   64   0   1   3  ...   0   0   0   51   0   2   \n",
      "9    0   0    5   0  13   0   24   0   2   9  ...   0   1   0   79   0   2   \n",
      "10   1   0    8   0  12   0   37   0   0   3  ...   0   2   0   98   1   2   \n",
      "11   1   0   11   0   5   0   32   0   0   2  ...   0   2   0   44   0   0   \n",
      "12   1   0   12   0   0   0    2   0   0   0  ...   0   0   0   10   0   9   \n",
      "13   1   1   10   0  26   0   56   0   1   6  ...   0   2   0   93   0   5   \n",
      "14   0   0    2   0   5   0    8   0   2   0  ...   0   0   0   14   0   2   \n",
      "15   2   0   33   0   5   0    8   0   0   0  ...   0   0   0   13   0  15   \n",
      "16  11   0   42   0   2   0    6   0   0   0  ...   0   0   0   20   0  11   \n",
      "17   1   0   13   0   3   0   10   0   0   0  ...   1   0   0    8   0   6   \n",
      "18   7   1   10   0   6   0   24   0   1  12  ...   0  12   0  133   1  16   \n",
      "19   0   0    1   0   3   0   37   0   0   3  ...   0   0   0   65   1   2   \n",
      "20   1   1   19   0   5   0   65   0   2   4  ...   0   3   0  422   8  25   \n",
      "21   0   0    4   0   3   0   38   0   0   1  ...   0   1   0   66   3   2   \n",
      "22   5   0   25   0   3   0    7   0   0   0  ...   0   0   0   20   0  63   \n",
      "23   1   0   17   0   1   0    3   0   0   0  ...   0   0   0    1   0   9   \n",
      "24   1   0   12   0   3   0   15   0   0   0  ...   0   0   0   18   2  17   \n",
      "25   1   0    6   0   2   0   29   0   0   1  ...   0   0   0   40   2   1   \n",
      "26   0   0    4   0   2   0   15   0   0   0  ...   0   0   0   10   0   2   \n",
      "\n",
      "    23  24  25  26  \n",
      "0    0   9   0   0  \n",
      "1    1   9   3   0  \n",
      "2    0  14   0   0  \n",
      "3    0   1   0   0  \n",
      "4    0  10   4   0  \n",
      "5    0   8   0   0  \n",
      "6    0   5   6   0  \n",
      "7    0   0   1   0  \n",
      "8    0   3   2   0  \n",
      "9    0   2   0   0  \n",
      "10   0   2   4   0  \n",
      "11   0   5   3   0  \n",
      "12   0   4   0   0  \n",
      "13   0   3   4   0  \n",
      "14   0   1   1   0  \n",
      "15   1  18   0   0  \n",
      "16   0  11   0   0  \n",
      "17   0   4   0   0  \n",
      "18   0   8   4   0  \n",
      "19   0   0   3   0  \n",
      "20   0   6   4   0  \n",
      "21   0   1   3   0  \n",
      "22   0  10   1   0  \n",
      "23   1  13   0   0  \n",
      "24   0  34   1   0  \n",
      "25   0   6   1   0  \n",
      "26   0  13   3   1  \n",
      "\n",
      "[27 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(pd.DataFrame(confusion_matrix( test_generator.classes, y_inception_pred_2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
